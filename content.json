{"meta":{"title":"么么博客","subtitle":"","description":"程序猿个人随记","author":"Liji","url":"https://liji53.github.io","root":"/"},"pages":[],"posts":[{"title":"【Clang Static Analyzer】浮点变量与零比较检查(原创)","slug":"LLVM/llvm-floatCmpZero","date":"2022-07-02T09:19:31.000Z","updated":"2022-07-02T09:19:31.000Z","comments":true,"path":"2022/07/02/LLVM/llvm-floatCmpZero/","link":"","permalink":"https://liji53.github.io/2022/07/02/LLVM/llvm-floatCmpZero/","excerpt":"","text":"浮点变量与零比较检查 分析可行性 1.测试文件 2.确定回调函数 代码实现 1.回调函数实现 2.获取左值右值的符号值 3.检查符号值是否为0 4.提交错误报告 浮点变量与零比较检查在C/C++中，不可将浮点变量用”==”或”!=”与数字直接比较，而应该转化成”&gt;=”或”&lt;=”此形式进行比较。这条检查在CSA的已有检查规则中并不存在，因此我们自己来实现下。这里我们只给出实现类，但checker的注册、CMakelist的添加等，可以回看CSA安装和运行 分析可行性一般来说，要实现一个CSA checker，我们要分析这么一个过程： 确定检查的场景，即待check的文件，明确代码可能会以什么样的形式存在 根据上面的场景，确定checker什么时候进行检查，即checker的回调函数 确定是否存在上下文依赖，如资源类型的检查，就需要检查上下文状态 实现代码，在实现过程中，需要结合AST、Exploded graph来不断确认程序状态 当检查出问题之后，确定是否需要继续检查，还是停止检查，确定错误报告 1.测试文件下面是自测时用的代码，列举了常用的场景，但像”if(浮点变量)”和”if(0.0 == 浮点变量)”这种场景, 这篇文章暂时不考虑在内。 12345678910111213141516171819202122232425262728293031// 为了代码展示的简洁性，尽量把能一行展示的放在一起extern double fabs(double x);const double CNST_DOUBLE_ZERO = 0.00000001;struct compound &#123; double a; int b; &#125;;int func(float float_var, struct compound C)&#123; int i = 2, j = 0; int* x = &amp;j; int&amp; y = j; int** z = &amp;x; double k = 0.0; struct compound D = &#123;3.14, 0&#125;; // 需要检查出来的场景 if (float_var == 0) &#123;&#125; // == 操作符场景 if ((float_var) != (0)) &#123;&#125; // != 操作符场景 if (0 == float_var - 1) &#123;&#125; // float为BinaryOperator场景 if (j == float_var) &#123;&#125; // 变量场景 if (*x == float_var) &#123;&#125; // 指针场景 if (**z == float_var) &#123;&#125; // 二级指针场景 if (y == float_var) &#123;&#125; // 引用场景 if ((0 == k &amp;&amp; i - 2 == float_var) || fabs(float_var - 1) == 0) &#123;&#125; // 多层表达式的场景 if (0 == C.a || 0 == C.a - 1) &#123;&#125; // float是struct成员变量的场景 if (D.b == C.a) &#123;&#125; // 不要误报的场景 if (i == 0) &#123;&#125; if (CNST_DOUBLE_ZERO == float_var) &#123;&#125; if (-CNST_DOUBLE_ZERO &lt; float_var &lt; CNST_DOUBLE_ZERO) &#123;&#125; if (fabs(float_var - 4) &lt; CNST_DOUBLE_ZERO) &#123;&#125; return 1;&#125; 2.确定回调函数本次检查比较简单，我们只需要考虑”==”和”!=”这两种表达式，同时由于我们不关心表达式计算后的结果，而只关心表达式的左值和右值是否为0，因此我们的回调函数可以确定为check::PreStmt&lt;BinaryOperator&gt; 代码实现1.回调函数实现在回调函数中，我们首先要缩小检查范围，如本例我们只检查： “==”和”!=”的操作符 左值或右值是浮点数的。 左值或右值等于0的 12345678910111213141516171819202122232425262728293031class FloatCmpZeroChecker : public Checker&lt;check::PreStmt&lt;BinaryOperator&gt;&gt; &#123;public: // 注册回调BinaryOperator void checkPreStmt(const BinaryOperator *B, CheckerContext &amp;C) const &#123; // 过滤 非&quot;等于&quot;的操作符 BinaryOperator::Opcode Op = B-&gt;getOpcode(); if (Op != BO_EQ &amp;&amp; Op != BO_NE) &#123;return;&#125; // 左值或右值必须有一项是float或double类型 const auto *Rhs = B-&gt;getRHS(); const auto *Lhs = B-&gt;getLHS(); const ASTContext &amp;Ctx = C.getASTContext(); CanQualType CanRhsTy = Ctx.getCanonicalType(Rhs-&gt;getType()); CanQualType CanLhsTy = Ctx.getCanonicalType(Lhs-&gt;getType()); // 其实由于类型转化的存在，只有有一项是浮点类型，2者都将是浮点类型 if (!isFloatType(CanRhsTy, Ctx) &amp;&amp; !isFloatType(CanLhsTy, Ctx)) &#123; return; &#125; // 检查左值是否为0 if (Optional&lt;DefinedSVal&gt; L_DV = get_definedSVal(Lhs, C)) &#123; checkZero(L_DV, C); &#125; // 检查右值是否为0 if (Optional&lt;DefinedSVal&gt; R_DV = get_definedSVal(Rhs, C)) &#123; checkZero(R_DV, C); &#125; &#125; bool isFloatType(CanQualType CanTy, const ASTContext &amp;Ctx) const &#123; return Ctx.FloatTy == CanTy || Ctx.DoubleTy == CanTy || Ctx.LongDoubleTy == CanTy; &#125;&#125; 2.获取左值右值的符号值先给出代码： 123456789101112131415void checkZero(const Expr *expr, CheckerContext &amp;C) const &#123; // 忽略&#x27;()&#x27; 和 类型转化 const Expr *org_expr = expr-&gt;IgnoreParenCasts(); SVal val_org = C.getSVal(org_expr); // 本身是float类型(UnKnownVal)，则过滤 Optional&lt;DefinedSVal&gt; DV = val_org.getAs&lt;DefinedSVal&gt;(); if (!DV) &#123; return;&#125; // 变量、指针、引用 if (Optional&lt;Loc&gt; LocVal = val_org.getAs&lt;Loc&gt;()) &#123; // 从memregion中获取SVal val_org = C.getState()-&gt;getSVal(LocVal.getValue()); DV = val_org.getAs&lt;DefinedSVal&gt;(); if (!DV) &#123;return;&#125; &#125;&#125; 这部分涉及到内存模型的使用，因此我们多啰嗦一点，结合前面的测试文件具体看下对应哪些内容 123456789// float_var是DeclRefExpr(AST)，它的SVal其实是Loc类型, 同理的还有局部变量j，引用变量yif (float_var == 0) if (j == float_var) // 局部变量场景if (y == float_var) &#123;&#125; // 引用场景// float_var-1是BinaryOperator(AST), 它的SVal是float_var-1这个表达式的返回值，因此为UnKnownVal类型if (0 == float_var - 1)// 一级指针和二级指针都是Loc类型，需要从memregion中获取SValif (*x == float_var) &#123;&#125; // 指针场景if (**z == float_var) &#123;&#125; // 二级指针场景 3.检查符号值是否为0123456789101112void checkZero(Optional&lt;DefinedSVal&gt; DV, CheckerContext &amp;C) const &#123; ConstraintManager &amp;CM = C.getConstraintManager(); // 假设当前表达式的符号值，返回(可能为真，可能为假)2个状态 ProgramStateRef stateNotZero, stateZero; std::tie(stateNotZero, stateZero) = CM.assumeDual(C.getState(), *DV); // 不可能为”非0“，即肯定为0 if (!stateNotZero) &#123; assert(stateZero); reportBug(&quot;float compared with zero&quot;, stateZero, C); return; &#125;&#125; 4.提交错误报告123456789101112131415161718192021222324252627// 获取错误内容的表达式static const Expr *getDenomExpr(const ExplodedNode *N) &#123; const Stmt *S = N-&gt;getLocationAs&lt;PreStmt&gt;()-&gt;getStmt(); if (const auto *BE = dyn_cast&lt;BinaryOperator&gt;(S)) return BE-&gt;getRHS(); return nullptr;&#125;class FloatCmpZeroChecker : public Checker&lt;check::PreStmt&lt;BinaryOperator&gt;&gt; &#123;private: mutable std::unique_ptr&lt;BuiltinBug&gt; BT;public: void reportBug(const char *Msg, ProgramStateRef StateZero, CheckerContext &amp;C, std::unique_ptr&lt;BugReporterVisitor&gt; Visitor = nullptr) const &#123; // 生成不sink的节点，程序继续分析 if (ExplodedNode *N = C.generateNonFatalErrorNode(StateZero)) &#123; if (!BT) BT.reset(new BuiltinBug(this, &quot;float compared with zero&quot;)); // 提交错误报告 auto R = std::make_unique&lt;PathSensitiveBugReport&gt;(*BT, Msg, N); R-&gt;addVisitor(std::move(Visitor)); bugreporter::trackExpressionValue(N, getDenomExpr(N), *R); C.emitReport(std::move(R)); &#125; &#125;&#125;;","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://liji53.github.io/categories/LLVM/"}],"tags":[]},{"title":"【Clang Static Analyzer】基于Exploded Graph的检查","slug":"LLVM/llvm-PathChecker","date":"2022-06-11T20:45:01.000Z","updated":"2022-06-11T20:45:01.000Z","comments":true,"path":"2022/06/11/LLVM/llvm-PathChecker/","link":"","permalink":"https://liji53.github.io/2022/06/11/LLVM/llvm-PathChecker/","excerpt":"","text":"基于Exploded Graph的检查 对Program state的基本操作 1.获取SVal 2.遍历Region Store 3.假设符号值 4.生成新的符号值 参与Exploded Graph的构建 1.添加Exploded Node 2.添加自定义状态 遍历Exploded Graph 基于Exploded Graph的检查对Program state的基本操作在Exploded Graph和内存模型中我们简单介绍了Program state,它存储了程序上下文变量的符号值(region)、表达式的符号值(Environment)、变量的限制范围(Constraints)等等，下面我们介绍下对Program state的常用操作。 1.获取SVal获取符号值，主要分为2种情况：1.从表达式中获取符号值；2.从内存区域中获取符号值它的常规用法如下： 1234567// 1.从表达式获取符号值const Expr *E = /* AST表达式 */;SVal Val = C.getSVal(E); /*C是CheckerContext*/// 2.从内存区域获取符号值（理解为解引用）const Expr *E = /* 指针表达式 */;const MemRegion *Reg = State-&gt;getSVal(E, LC).getAsRegion ();SVal Val = State-&gt;getSVal(Reg); 2.遍历Region StoreRegion Store存储了MemRegion与SVal的映射关系，对它的遍历需要注册回调类来实现： 12345678910111213141516171819202122class CallBack : public StoreManager::BindingsHandler &#123; using store = llvm::SmallVector&lt;std::pair&lt;const MemRegion *, SVal&gt;, 8&gt;;public: store V; // Region Store会回调这个方法，返回false表示不继续遍历，返回true表示继续遍历 bool HandleBinding(StoreManager &amp;SMgr, Store Store, const MemRegion *Region, SVal Val) override &#123; V.emplace_back(Region, Val); return true; &#125;&#125;;CallBack Handler;ProgramStateRef State = C.getState();// 对Region Store遍历，在iterBindings接口中会回调HandleBindingState-&gt;getStateManager().getStoreManager().iterBindings(State-&gt;getStore(), Handler);for (const auto i : Handler.V) &#123; i.first-&gt;dump(); llvm::errs() &lt;&lt; &quot;\\n&quot;; i.second.dump(); llvm::errs() &lt;&lt; &quot;\\n&quot;;&#125; 3.假设符号值在执行条件语句之后，我们可能需要对变量的取值范围进行判断，通过ConstraintManager/state的assume系列函数，可以判断表达式值的范围。其实之前在CFG和Path-sensitive-checker回调函数的check::PreCall一节中已经给过一个的例子了。用法如下： 123456789101112131415SVal Val = /* 符号值 */;// 必须是DefinedSVal才行，不能是未初始化变量(UndefinedVal)和无法计算的值(UnknownVal)Optional&lt;DefinedSVal&gt; DVal = Val.getAs&lt;DefinedSVal&gt;();if (! DVal ) return ;// 1. 通过ConstraintManager来进行判断ConstraintManager &amp;CM = C.getConstraintManager();// 判断DV这个符号值是否为非0ProgramStateRef trueState = CM.assume(C.getState(), *DV, true);// 判断DV这个符号值是否在[0,1]的区间ProgramStateRef trueState = CM.assumeInclusiveRange(C.getState(), *DV, One, Two, true);// 2. 通过state来判断，其内部实现也是通过ConstraintManagerProgramStateRef TrueState, FalseState;// DVal可以是UnknownVal的std::tie(TrueState, FalseState) = State-&gt;assume(DVal); 4.生成新的符号值在比较符号值的时候，我们可能需要构建一些新的符号值，通过SValBuilder可以构建。比方： 1234567891011121314// 摘录自MallocChecker，用于计算内存buffer的大小SVal MallocChecker::evalMulForBufferSize(CheckerContext &amp;C, const Expr *Blocks, const Expr *BlockBytes) &#123; SValBuilder &amp;SB = C.getSValBuilder(); // 内存块的个数 SVal BlocksVal = C.getSVal(Blocks); // 一个内存块的大小 SVal BlockBytesVal = C.getSVal(BlockBytes); ProgramStateRef State = C.getState(); // 通过eval计算内存块的大小 SVal TotalSize = SB.evalBinOp(State, BO_Mul, BlocksVal, BlockBytesVal, SB.getContext().getSizeType()); return TotalSize;&#125; 参与Exploded Graph的构建Exploded Graph是符号执行时的路径图，只要可能达到的路径，都将分析执行，因此存在路径爆炸(函数堆栈比较深，条件分支比较多)的问题。在符号执行的过程中，我们可以往这个路径图中添加我们自己的节点、符号状态等等，甚至通过添加节点改变Exploded Graph的路径方向。Exploded Graph的一个重要原则就是：节点都是不可变的，只能新增。 1.添加Exploded Node有时候我们可能对函数的异常返回不关心，因此不需要对异常分支进行符号执行。这时候我们可以这么做： 12345678910111213141516171819// 测试程序int func(int i)&#123; if (!test()) &#123; /*don&#x27;t care*/ &#125; else &#123; /*需要符号执行，检查程序错误*/ &#125;&#125;// CSA checkervoid checkPostCall(const CallEvent &amp;Call, CheckerContext &amp;C) const &#123; // 获取函数返回值的符号值 SVal SVfunc = Call.getState()-&gt;getSVal(Call.getOriginExpr(), C.getLocationContext()); const Optional&lt;DefinedOrUnknownSVal&gt; DS = SVfunc.getAs&lt;DefinedOrUnknownSVal&gt;(); ProgramStateRef trueState, falseState; // 假设函数返回值，有没有可能真、假 std::tie(trueState, falseState) = Call.getState()-&gt;assume(*DS); // 只关心返回值为True的情况 if (trueState) &#123; // 对于False的分支，后面不会再符号执行了 C.addTransition(trueState); &#125;&#125; 2.添加自定义状态前面讲到Program State的GDM用于存储用户自定义的状态，一般需要检查有关联的一系列的事件时，就会用到。如内存泄漏的检查。下面截取SimpleStreamChecker的代码片段，看下如何使用： 12345678910111213141516171819202122232425262728293031323334353637383940/// 先自定义文件指针的状态struct StreamState &#123;private: enum Kind &#123; Opened, Closed &#125; K; StreamState(Kind InK) : K(InK) &#123;&#125;public: ...&#125;;// 对于open系列的函数，保存open返回的符号，为什么是checkPostCall，我们前面已经讲过了void SimpleStreamChecker::checkPostCall(const CallEvent &amp;Call, CheckerContext &amp;C) const &#123; // ... 省略 // Get the symbolic value corresponding to the file handle. SymbolRef FileDesc = Call.getReturnValue().getAsSymbol(); if (!FileDesc) return; // Generate the next transition (an edge in the exploded graph). ProgramStateRef State = C.getState(); State = State-&gt;set&lt;StreamMap&gt;(FileDesc, StreamState::getOpened()); C.addTransition(State);&#125;// 对于close系列的函数，根据close时的参数，查找对应的符号，并检查void SimpleStreamChecker::checkPreCall(const CallEvent &amp;Call, CheckerContext &amp;C) const &#123; // ... 省略 // Get the symbolic value corresponding to the file handle. SymbolRef FileDesc = Call.getArgSVal(0).getAsSymbol(); if (!FileDesc) return; // Check if the stream has already been closed. ProgramStateRef State = C.getState(); // 查找之前open时的符号 const StreamState *SS = State-&gt;get&lt;StreamMap&gt;(FileDesc); if (SS &amp;&amp; SS-&gt;isClosed()) &#123; // 重复关闭 &#125; // Generate the next transition, in which the stream is closed. State = State-&gt;set&lt;StreamMap&gt;(FileDesc, StreamState::getClosed()); C.addTransition(State);&#125;// 类似的还有Set、LIST、TRAITREGISTER_MAP_WITH_PROGRAMSTATE(StreamMap, SymbolRef, StreamState) 遍历Exploded Graph这种场景的使用，等实际用到的时候，可以参考UnreachableCodeChecker","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://liji53.github.io/categories/LLVM/"}],"tags":[]},{"title":"cryptography-tls","slug":"cryptograghy/cryptography-tls","date":"2022-05-25T08:42:21.000Z","updated":"2022-05-25T08:42:21.000Z","comments":true,"path":"2022/05/25/cryptograghy/cryptography-tls/","link":"","permalink":"https://liji53.github.io/2022/05/25/cryptograghy/cryptography-tls/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"net-ip","slug":"network/net-ip","date":"2022-05-23T06:28:48.000Z","updated":"2022-05-23T06:28:48.000Z","comments":true,"path":"2022/05/23/network/net-ip/","link":"","permalink":"https://liji53.github.io/2022/05/23/network/net-ip/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"net-tcp","slug":"network/net-tcp","date":"2022-05-23T06:28:26.000Z","updated":"2022-05-23T06:28:26.000Z","comments":true,"path":"2022/05/23/network/net-tcp/","link":"","permalink":"https://liji53.github.io/2022/05/23/network/net-tcp/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"net_http","slug":"network/net-http","date":"2022-05-23T06:27:38.000Z","updated":"2022-05-23T06:27:38.000Z","comments":true,"path":"2022/05/23/network/net-http/","link":"","permalink":"https://liji53.github.io/2022/05/23/network/net-http/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"【Clang Static Analyzer】Exploded Graph和内存模型","slug":"LLVM/llvm-explodedGraph","date":"2022-05-21T10:45:01.000Z","updated":"2022-05-21T10:45:01.000Z","comments":true,"path":"2022/05/21/LLVM/llvm-explodedGraph/","link":"","permalink":"https://liji53.github.io/2022/05/21/LLVM/llvm-explodedGraph/","excerpt":"","text":"Exploded-Graph和内存模型 Exploded-graph Program-Point Program-State Exploded-graph图 内存模型 SVal MemRegion SymExpr 三者与Exploded-graph的联系 参考资料与例子 Exploded-Graph和内存模型基于Exploded Graph检查指的是结合代码执行过程中的上下文来进行检查。打个比方，我们用GDB调试的时候打断点，然后在这个断点处查看上下文，能知道当前程序的变量值、调用堆栈等信息。CSA也是类似的检查过程。前面我们讲的Path-sensitive checker回调函数就可以理解成是程序断点，而Exploded Graph就是断点处的上下文信息，包括当前变量的值，表达式的值，符号的约束信息等。 Exploded-graphPath-sensitive checker的核心数据结构是Exploded graph，Exploded graph由Exploded graph node组成，Exploded graph node包含Program Point和Program State如图所示： Program-Point表示当前程序执行的位置。一般来说，我们写checker用到它的机会不多，往往在checkEndAnalysis(还记得一系列的回调函数把)遍历Exploded graph才用。一个CFGElement往往对应一个Program Point或者多个Program Point，下面是Program Point的部分信息： 12345678910// 部分关键信息&#123; &quot;kind&quot;: &quot;Statement&quot;, # Program Point的类型 &quot;block_id&quot;: 3, # 对应CFG的block ID， BlockEntrance类型的才有 &quot;stmt_kind&quot;: &quot;DeclStmt&quot;, # stmt的类型 &quot;stmt_id&quot;: 670, # 对应stmt的id，stmt和Program Point的对应关系是1对1或1对多 &quot;stmt_point_kind&quot;: &quot;PostStmt&quot;, # 当前程序执行的位置 &quot;node_id&quot;: 7, # Exploded graph node号，注意与block_id的区别 &quot;is_sink&quot;: 0 # 1的话表示后面不需要再执行了&#125; 详细资料ProgramPoint Program-StateProgram State包含我们要检查的核心信息，包含以下内容： Environment: 表达式的符号值（注意这些符号值生命短暂） Region Store: 表示上下文变量的符号值（如果变量后面不再用到了，会DeadSymbol，即会删除Region Store中对应的变量） Constraints：表示变量的限制范围 Taint: 存储受到“污染”的变量 GDM：用于存储checker的自定义的状态信息 关于Region Store、Environment、Constraints里面存的是什么，后面还会继续讲，我们先清楚大概的内容即可。 Exploded-graph图通过-cc1 -analyze -analyzer-checker=”debug.ViewExplodedGraph” 可以查看相关的图，但这个图非常的大，我只能截取部分内容： 这个图其实有一定的迷惑性，我一开始的时候，以为一个方框代表一个Exploded graph node。但其实CSA为了简化展示，把具有相同的Program State放在了一起。建议自己动手生成下，仔细观察下不同的代码对应的Exploded graph. 内存模型我们在写代码时，会涉及到变量的名字、内存地址、内存地址的值等相关概念, 同样的在CSA中同样也有类似的概念, 如”int a = 0” a是一个符号(名字)，在CSA中用SymExpr表示符号， 符号a的值是0，在CSA中用SVal表示符号值，是符号值的抽象 符号a的地址&amp;a，在CSA中用MemRegion表示内存区域，是内存地址的抽象 SVal在符号执行中，使用SVal(符号值)来参与模拟执行，因此SVal可以理解成各种类型的变量的值，包括具体的值（如int）、表达式的临时值、不确定的变量值、内存地址值等。其中SVal比较重要的子类有以下几种： UndefinedVal 表示未初始化的局部变量 UnknownVal 表示CSA无法计算的值，如float、switch中default选项 NonLoc 表示非地址类型的值 Loc 表示地址类型的值 MemRegionVal 表示内存地址的值 下面我们给出一段示例： 1234567891011struct S&#123; int member;&#125;;int global; // NonLoc - SymbolValint func()&#123; float pi = 3.14; // UnknownVal int i; // UndefinedVal int j = 0; // NonLoc - ConcreteInt int* p = &amp;j; // Loc - MemRegionVal struct S s; // NonLoc - LazyCompoundVal&#125; 详情：SVal MemRegionMemRegion是所有Region的基类，不仅表示存储SVal的内存区域，同时也表示内存段的信息(如代码段、堆栈段等)因此MemRegion分为2大类： MemSpaceRegion表示内存段的信息，共有5种类型，分别对应实际程序运行时的代码段、数据段、堆、栈 SubRegion表示内存区域，比方变量的内存区域VarRegion。SubRegion是有内存大小的，而MemSpaceRegion是没有大小的。 比较常用的是SubRegion，下面列举部分常见的： VarRegion 表示有内存地址的变量 ElementRegion 专门表示数组的子元素 FieldRegion 表示对象的成员 SubRegion内部都存在一个SuperRegion,表示父内存区域，通过这两者的关系，就可以构建出内存的层次。比方（引用自《Clang-analyzer-guild-v0.1》）： 12345678910111213struct A &#123; int x, y;&#125;;struct B: A &#123; int u, v;&#125;;struct C &#123; int t; B *b;&#125;;void foo(C c) &#123; c.b[5].y; // &lt;-- that&#125; 上面代码的内存模型如下： 详情：MemRegion SymExprSymExpr表示的是变量的符号(名字)，在符号执行过程中并不是每个变量的值都能确定的，因此对于那些无法确定值的变量，就会用SymExpr来表示。涉及符号执行的表达式大概分为4种：CallExpr(函数调用)、CaseExpr(类型转化)、BinaryOperator(二目运算)、UnaryOperator(一目运算)因此SymExpr也分为对应的4种类型： SymbolData 它的子类SymbolConjured表示无法对函数调用符号执行的符号值 BinarySymExpr 表示无法对二目运算符号执行的符号值 UnarySymExpr 表示无法对一目运算符号执行的符号值 SymbolCast 表示无法对类型转化符号执行的符号值 详情：SymExpr 三者与Exploded-graph的联系对于SVal、MemRegion、SymExpr的概念我们已经有初步的了解了，下面我们结合Exploded graph的Program State来看下他们的联系： 作用 SVal MemRegion SymExpr 作为Constraints的key ✔ 作为Region Store的key ✔ 作为Region Store的value ✔ 作为Environment的value ✔ 参考资料与例子用到Program Point来检查可参考下面案例：推荐阅读UnreachableCodeChecker 相关的博客：https://www.zhihu.com/people/movietravelcode/posts这篇文章以及《Clang-analyzer-guild-v0.1》让我对内存模型的理解省去大量的时间","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://liji53.github.io/categories/LLVM/"}],"tags":[]},{"title":"【Clang Static Analyzer】CFG和Path-sensitive checker回调函数","slug":"LLVM/llvm-CFG","date":"2022-05-14T17:12:43.000Z","updated":"2022-05-14T17:12:43.000Z","comments":true,"path":"2022/05/14/LLVM/llvm-CFG/","link":"","permalink":"https://liji53.github.io/2022/05/14/LLVM/llvm-CFG/","excerpt":"","text":"CFG和Path-sensitive checker回调函数 CFG 1-CFG图说明 2-CFG的遍历 Path-sensitive checker回调函数 1-check::PreStmt&lt;T&gt;和check::PostStmt&lt;T&gt; 2-check::PreCall和check::PostCall 3-check::BranchCondition 4-check::Location和check::Bind 5-check::EndAnalysis和check::BeginFunction和check::EndFunction 6-check::LiveSymbols和check::DeadSymbols 7-eval::Assume 8-eval::Call 参考资料与例子 CFG和Path-sensitive-checker回调函数前面我们讲到CSA的检查可以基于CFG，但这种检查的实际应用场景是极少的。但关于CFG的概念，以及对于CFG图的理解是我们需要知道的。CFG由AST构建出来，用于Path-sensitive的执行(即CSA是基于CFG的节点进行模拟执行的)，一般用于配合path-sensitive checker来检查生命周期。 而基于Exploded graph的检查是CSA的核心，涉及到相关的概念，我们需要先捋一下： Exploded graph: 可以理解为CSA分析过程中产生的数据结构，我们写Path-sensitive checker的核心工作就是往这个数据结构中添加信息。 Path-sensitive: 会根据不同条件分支，跟踪程序控制流的每个分支并记录每个分支的状态，比如有2个条件分支，则会记录这两个分支的程序状态。 符号执行: 跟程序执行类似，但使用符号值来模拟执行（并不是实际值)，且会探索所有可能的分支，并收集每个分支的符号变量的限制范围。 CFG如何使用CFG呢？其实我们只需要会遍历CFG，并能拿到相关信息即可。(毕竟很少用到)使用-cc1 -analyze -analyzer-checker=”debug.ViewCFG”可以查看CFG图。 1-CFG图说明CFG的图还是很容易理解的：官方CFGBlock详情官方CFGElement详情 2-CFG的遍历CFG的遍历也比较简单，参考代码如下： 1234567891011121314151617181920212223void checkASTCodeBody(const Decl *D, AnalysisManager &amp;mgr, BugReporter &amp;BR) const &#123; CFG *cfg = mgr.getCFG(D); // 遍历CFGBlock for (const auto&amp; cfgNode : *cfg) &#123; // 遍历当前节点的上(父)层节点 for (CFGBlock::const_pred_iterator I = cfgNode-&gt;pred_begin(); I != cfgNode-&gt;pred_end(); ++I) &#123; llvm::errs() &lt;&lt; &quot;CFG pred Node ID:&quot; &lt;&lt; (*I)-&gt;getBlockID() &lt;&lt; &#x27;\\n&#x27;; &#125; // 遍历当前节点的下(子)层节点 for (CFGBlock::const_succ_iterator I = cfgNode-&gt;succ_begin(); I != cfgNode-&gt;succ_end(); I++) &#123; llvm::errs() &lt;&lt; &quot;CFG succ Node ID:&quot; &lt;&lt; (*I)-&gt;getBlockID() &lt;&lt; &#x27;\\n&#x27;; &#125; // 遍历CFGElement for (const auto&amp; cfgElemet : *cfgNode) &#123; if (Optional&lt;CFGStmt&gt; stmt = cfgElemet.getAs&lt;CFGStmt&gt;()) &#123; const Stmt *astStmt = const_cast&lt;Stmt *&gt;(stmt-&gt;getStmt()); if (const CallExpr *CE = dyn_cast&lt;CallExpr&gt;(astStmt)) &#123; // 做一些检查！ &#125; &#125; &#125; &#125;&#125; Path-sensitive-checker回调函数Path-sensitive checker的核心数据结构是Exploded graph，但这个数据结构我们先缓缓，先看相关的回调函数。前面我们我们讲了基于AST的注册回调函数，但这些回调函数并不会参与到exploded graph的构建，一般只能做一些语法、函数禁用的检查。下面是一些常用的Path-sensitive回调函数，还有一些并没有列举（因为没用过） 1-check::PreStmt&lt;T&gt;和check::PostStmt&lt;T&gt;模板T可以是任意的AST Stmt类型，但实际上条件控制语句（if等）、返回语句(return)并不会发生回调PreStmt的回调发生在“符号执行”之前，PostStmt发生在执行之后。因此对于PreStmt来说，如果订阅的是表达式，那么这个表达式的符号值还没计算出来。如： 1234567891011121314/// 比方回调 &quot;i == 0;&quot;这个表达式void checkPreStmt(const BinaryOperator *S, CheckerContext &amp;C) const &#123; SVal rhs = C.getSVal(S-&gt;getRHS()); // 右值已经符号执行完成了 SVal exp = C.getSVal(S); // 整个表达式的符号值还没有执行 Optional&lt;DefinedSVal&gt; DV_rhs = rhs.getAs&lt;DefinedSVal&gt;(); Optional&lt;DefinedSVal&gt; DV_exp = exp.getAs&lt;DefinedSVal&gt;(); if (!DV_rhs) &#123; llvm::errs() &lt;&lt; &quot;checkPreStmt not rhs DefinedSVal&quot; &lt;&lt; &#x27;\\n&#x27;; &#125; if (!DV_exp) &#123; // 会打印，因为整个表达式的符号值还没计算出来 llvm::errs() &lt;&lt; &quot;checkPreStmt not exp DefinedSVal&quot; &lt;&lt; &#x27;\\n&#x27;; &#125;&#125; 同理，对于PostStmt来说，整个表达式的符号值已经执行可以获取，但子表达式可能在环境中已经不存在了无法获取关于代码中的DefinedSVal代表的是什么，我们后面再讲。 2-check::PreCall和check::PostCallcheck::PreCall的触发时机等价于check::PreStmt&lt;CallExpr&gt;，check::PostCalll的触发时机等价于check::PostStmt&lt;CallExpr&gt;但相比PreStmt和PostStmt，PreCall、PostCalll的参数CallEvent封装了函数的相关操作，可以方便我们使用。同样地，PreCall发生在函数“符号执行”之前，因此只能获取参数的符号值，而PostCalll在执行函数（可能）之后，因此可以对函数返回值进行判断。一般来说，PreCall往往用在判断函数参数(如fclose判断哪些fd被关闭)，PostCalll判断函数返回值（如fopen判断哪些fd被打开）。 123456789101112131415161718192021222324252627// 比方回调 &quot;if (i == 0) F1111(i);&quot; 这个情况下，函数(F1111)的参数i必然是0，可以检查F1111的参数是否为0void checkPreCall(const CallEvent &amp;Call, CheckerContext &amp;C) const &#123; // 从符号表中取符号名 IdentifierInfo* IIFunc = &amp;C.getASTContext().Idents.get(&quot;F1111&quot;); if (Call.getCalleeIdentifier() != IIFunc) // 检查函数名 return; if (Call.getNumArgs() != 1) // 检查函数参数个数是否为1 return; SVal args = Call.getArgSVal(0); // 获取参数1的符号值 Optional&lt;NonLoc&gt; NL = args.getAs&lt;NonLoc&gt;(); if (!NL) &#123; return; &#125; // 构造符号值为0的符号 BasicValueFactory &amp;BVF = C.getSValBuilder().getBasicValueFactory(); llvm::APSInt Zero = BVF.getIntValue(0, false); ConstraintManager &amp;CM = C.getConstraintManager(); // 检查函数参数的值的范围 if (CM.assumeInclusiveRange(C.getState(), *NL, Zero, Zero, true)) &#123; llvm::errs() &lt;&lt; &quot;F1111(args = 0)&quot; &lt;&lt; &#x27;\\n&#x27;; // 打印 &#125; // checkPreCall无法对函数返回值进行判断，但在PostCalll中可以 SVal ret = Call.getReturnValue(); Optional&lt;DefinedSVal&gt; DV = ret.getAs&lt;DefinedSVal&gt;(); if (!DV) &#123; llvm::errs() &lt;&lt; &quot;checkPreCall not excute func&quot; &lt;&lt; &#x27;\\n&#x27;; //打印 &#125; 3-check::BranchConditioncheck::BranchCondition发生在出现条件分支的情况，如if、while、for等，还包括||和&amp;&amp;一般用于检查条件值： 123456789// 比方回调&quot;int j; if (j)&#123;&#125;&quot;, j属于未初始化变量void checkBranchCondition(const Stmt *Condition, CheckerContext &amp;C) const &#123; SVal X = C.getSVal(Condition); // 如果条件的符号值是未初始化的变量 if (X.isUndef()) &#123; // 直接生成sink节点，不需要继续执行（其他检查也会停止） C.generateErrorNode(); &#125;&#125; 4-check::Location和check::Bindcheck::Location 发生在变量发生写（不包括变量初始化的赋值）和读的时候check::Bind 发生在变量发生写（包括变量初始化）的时候 12345678910int func(int i)&#123; int z = 1; // 会触发Bind int j = i; // 会触发Bind，Location（i变量被读取，参数is_load=true） j = z; // 会触发Bind和2次Location(z变量被读取，参数is_load=true；j变量被写入，参数is_load=false) if (j)&#123; // 会触发Location(j被读取，参数is_load = ture) return j; // 会触发Location(j被读取，参数is_load = ture) &#125; return j; // 程序不可达，不会触发&#125; 5-check::EndAnalysis和check::BeginFunction和check::EndFunctioncheck::EndAnalysis 发生在CSA完成分析一个函数体的时候，一般我们在这个时间节点遍历完整的Exploded Graph。check::BeginFunction 发生在函数的开始，一个函数只会回调一次。而check::EndFunction 发生在每个可能会return的分支 123456789int func(int i)&#123; // 这种情况，我理解的是会回调3次，但实际情况是根据return的值不同， // 会产生不一样的结果，目前我还不知道为什么会这样 // 使用check::PreStmt&lt;ReturnStmt&gt;能把所有可能return的都回调 if (i == 0) &#123; return -1; &#125; // 如果是负数，会回调EndFunction if (i == 2) &#123; return 3; &#125; // 如果是非负数，不会回调EndFunction return 4; // 会回调EndFunction&#125; 6-check::LiveSymbols和check::DeadSymbolscheck::DeadSymbols 发生在变量不再被使用的时候（并不是变量的生命周期结束）check::LiveSymbols 发生在check::DeadSymbols之前，一般用于把感兴趣的变量标记为InUse，这样就不会垃圾回收 123456789101112int func(int a)&#123; int i = 0; // 这种其实也会触发LiveSymbols和DeadSymbols int j = 0; int k = 0; if (a) &#123; i = 1; // 这个分支里，j是DeadSymbols &#125; else &#123; j = 1; // i是DeadSymbols &#125; return k; // i 和 j 都是DeadSymbols了&#125; 7-eval::Assume跟check::BranchCondition的触发场景类似。一般用于修改ProgramState,比方删除不需要再关注的“符号变量”。如： 12345678910111213// 来自MallocChecker的代码片段ProgramStateRef evalAssume(ProgramStateRef state, SVal Cond, bool Assumption) const &#123; RegionStateTy RS = state-&gt;get&lt;RegionState&gt;(); for (RegionStateTy::iterator I = RS.begin(), E = RS.end(); I != E; ++I) &#123; // If the symbol is assumed to be NULL, remove it from consideration. ConstraintManager &amp;CMgr = state-&gt;getConstraintManager(); ConditionTruthVal AllocFailed = CMgr.isNull(state, I.getKey()); if (AllocFailed.isConstrainedTrue()) state = state-&gt;remove&lt;RegionState&gt;(I.getKey()); &#125; // ... return state;&#125; 8-eval::Call这个回调函数可以让checker参与到CSA的分析过程中，但checker的开发人员需要对函数进行模拟。 参考资料与例子只使用CFG来检查的例子很少，可参考下面案例：推荐阅读DeadStoresChecker来熟悉CFG的使用 Path-sensitive checker的实例很多，但初学者可优先参考下面案例：推荐阅读SimpleStreamChecker来熟悉Path-sensitive checker 以及下面这个文档说明：推荐阅读CheckerDocumentation来熟悉各种回调函数","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://liji53.github.io/categories/LLVM/"}],"tags":[]},{"title":"【Clang Static Analyzer】基于AST检查","slug":"LLVM/llvm-syntax","date":"2022-04-21T07:42:33.000Z","updated":"2022-04-21T07:42:33.000Z","comments":true,"path":"2022/04/21/LLVM/llvm-syntax/","link":"","permalink":"https://liji53.github.io/2022/04/21/LLVM/llvm-syntax/","excerpt":"","text":"基于AST检查 AST的结构 1.Decl 2.Stmt 3.Expr AST的遍历 1. 通过ConstStmtVisitor遍历Stmt 2. 通过RecursiveASTVisitor遍历 Checkers的注册回调函数(AST) 检查器 AST matchers 1.通过Callback实现 2.更简洁的实现 参考资料与例子 基于AST检查Clang Static Analyzer 的检查可以分为三种： 基于AST(abstract syntax tree)的检查 基于CFG(Control flow graph)的检查 基于Exploded graph的检查（核心） 但不管哪种方法，在实现一个checker之前，我们需要对编译过程以及AST有一个直观的了解： 编译过程：（clang前端）词法-&gt;语法-&gt;语义-&gt;IR-&gt;优化-&gt;CodeGen (llvm后端) AST：语法解析之后的产物，最简单最直观的学习方法就是用clang -Xclang -ast-dump -fsyntax-only AST的结构虽然用-ast-dump能清楚看到每句源码对应的AST节点，但这里还是要强调下AST的2种最基本的类型Decl和Stmt 1.DeclDecl是声明，比方: 语句 类型 typedef int (* main_t )( int , char **); TypedefDecl int foo(int argc, char** argv); FunctionDecl int i; VarDecl AST的入口节点 TranslationUnitDecl Decl系列的类继承图以及常用方法可以看Decl 2.StmtStmt是定义（有内存分配的）、函数调用、表达式等，比方： 语句 类型 {…} CompoundStmt if (…) IfStmt return -1; ReturnStmt Stmt系列的类继承图以及常用方法可以看Stmt 3.ExprExpr是表达式，属于Stmt的子类，比方： 语句 类型 foo(); CallExpr char buf[1] = {0}; InitListExpr new CXXNewExpr(foo) CXXNewExpr 整数 IntegerLiteral 二目运算 BinaryOperator 一目操作(除了sizeof和alignof) UnaryOperator Expr系列的类继承图以及常用方法可以看Expr AST的遍历AST的遍历是通过继承（include/clang/AST/*Visitor.h）遍历类来实现的，常用的有： ConstStmtVisitor ConstDeclVistor RecursiveASTVisitor 1. 通过ConstStmtVisitor遍历Stmt通过ConstStmtVisitor 可以遍历属于Stmt类及其子类的节点，包括Expr。 12345678910111213141516171819202122class WalkAST : public ConstStmtVisitor&lt;WalkAST&gt; &#123; // 递归遍历子节点，这个是必须实现的 void VisitChildren(const Stmt *S) &#123; for (const Stmt *Child : S-&gt;children()) if (Child) this-&gt;Visit(Child); &#125;public: // 需要检查什么类型的Stmt，则重写对应的方法，如下面的这三个方法 void VisitStmt(const Stmt *S) &#123; // do some checking VisitChildren(S); &#125; void VisitCallExpr(const CallExpr *CE) &#123; // do some checking VisitChildren(CE); &#125; void VisitWhileStmt(const WhileStmt *WS) &#123; // do some checking VisitChildren(WS); &#125;&#125;; 需要注意的是：如while(true) 这种语句即属于Stmt也属于WhileStmt，但回调的时候只会调用WhileStmt，即优先回调子集。ConstDeclVistor与ConstStmtVisitor的用法相似，不再重复。 2. 通过RecursiveASTVisitor遍历12345678910111213141516class MyClass : public RecursiveASTVisitor&lt;MyClass&gt; &#123;public: // 需要检查什么类型的Stmt，则重写对应的方法，如下面的这三个方法，返回true表示继续遍历。 bool VisitWhileStmt(const WhileStmt *S) &#123; llvm::errs() &lt;&lt; &quot;VisitWhileStmt!!!!&quot; &lt;&lt; &#x27;\\n&#x27;; return true; &#125; bool VisitStmt(const Stmt *S) &#123; llvm::errs() &lt;&lt; &quot;VisitStmt!!!!&quot; &lt;&lt; &#x27;\\n&#x27;; return true; &#125; bool VisitCallExpr(const CallExpr *CE)&#123; llvm::errs() &lt;&lt; &quot;VisitCallExpr!!!!&quot; &lt;&lt; &#x27;\\n&#x27;; return true; &#125;&#125;; RecursiveASTVisitor 有三种类型的接口： Traverse* 这种接口是遍历AST的入口，如TraverseDecl、TraverseStmt WalkUpFrom* 这种接口会向前调用父类的WalkUpFrom Visit* 这种接口会回调实际的访问节点 如果遇到像while即属于Stmt也属于WhileStmt的，则RecursiveASTVisitor不像ConstStmtVisitor只会调用子集，而是会先调用VisitStmt，再调用一遍VisitWhileStmt Checkers的注册回调函数(AST)这里我们暂时只关注三个跟AST相关的回调函数（Path-sensitive的后面唠叨）: ASTCodeBody 会回调函数体 ASTDecl&lt;****&gt; 回调****Decl类型 checkEndOfTranslationUnit 回调整个AST 检查器这里我们简单搭一个检查器的实现框架： 12345678910111213141516class TestChecker : public Checker &lt;check::ASTCodeBody, check::ASTDecl&lt;FunctionDecl&gt;, check::ASTDecl&lt;VarDecl&gt;, check::EndOfTranslationUnit&gt; &#123;public: // Clang Static Analyzer core会回调这些注册函数，从而实现错误诊断代码逻辑 void checkASTCodeBody(const Decl *D, AnalysisManager &amp;mgr, BugReporter &amp;BR) const &#123; MyClass Walker = MyClass(); // 参考上小节AST的遍历 Walker.TraverseStmt(D-&gt;getBody()); &#125; void checkASTDecl(const FunctionDecl *D, AnalysisManager &amp;Mgr, BugReporter &amp;BR) const &#123;&#125; void checkASTDecl(const VarDecl *D, AnalysisManager &amp;Mgr, BugReporter &amp;BR) const &#123;&#125; void checkEndOfTranslationUnit(const TranslationUnitDecl *TU, AnalysisManager &amp;Mgr, BugReporter &amp;BR) const &#123;&#125; AST matchers如果你觉得上面的遍历AST的实现比较啰嗦的话，还可以通过AST matchers来实现。AST Matchers内部帮你实现了遍历的流程，你只需要注册你关注的代码模式即可。 1.通过Callback实现1234567891011121314151617// 注册id，回调中通过这个ID可以找到你想要检查的代码constexpr llvm::StringLiteral WarnAtNode = &quot;id&quot;;class HandleMatch : public MatchFinder::MatchCallback &#123;public: virtual void Run(const MatchFinder::MatchResult &amp;Result) &#123; const CallExpr *Class = Result.Nodes.getStmtAs&lt;CallExpr&gt;(WarnAtNode); // 如果注册的时候，用的是decl(XXXX),则参考这么这种 // const CXXRecordDecl *Class = Result.Nodes.GetDeclAs&lt;CXXRecordDecl&gt;(WarnAtNode); // 可以做业务，比方提交错误报告 ... &#125;&#125;;MatchFinder finder;finder.AddMatcher(stmt(hasDescendant(callExpr( callee(functionDecl(hasName(&quot;main&quot;)))).bind(&quot;id&quot;))), new HandleMatch);// 开始匹配，会遍历ASTfinder.matchAST(ASTContext); 2.更简洁的实现通过ASTMatchFinder.h提供的match函数，可以不需要实现上面的Callback，原理其实是一样的，只不过ASTMatchFinder.h把Callback封装了。 12345678constexpr llvm::StringLiteral WarnAtNode = &quot;id&quot;;// Matches返回所有已经匹配到的代码auto Matches = match(stmt(hasDescendant(callExpr( callee(functionDecl(hasName(&quot;main&quot;)))).bind(&quot;id&quot;))), new HandleMatch);for (const auto &amp;Match : Matches)&#123; // 在emitDiagnostics中可以做一些业务逻辑，比方提交日志。 emitDiagnostics(Match, D, BR, AM, this);&#125; 参考资料与例子找了2个简单的例子，供大家阅读：推荐阅读CStringSyntaxChecker来熟悉基于AST遍历的检查推荐阅读PointerIterationChecker来熟悉AST Matchers的检查","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://liji53.github.io/categories/LLVM/"}],"tags":[]},{"title":"【Clang Static Analyzer】环境","slug":"LLVM/llvm-environment","date":"2022-02-23T02:11:25.000Z","updated":"2022-02-23T02:11:25.000Z","comments":true,"path":"2022/02/23/LLVM/llvm-environment/","link":"","permalink":"https://liji53.github.io/2022/02/23/LLVM/llvm-environment/","excerpt":"","text":"CSA安装和运行 VS中构建LLVM 1-环境预准备 2-vs打开LLVM项目 3-编译并添加命令参数 添加第一个检查器 1-测试文件 2-添加checker定义 3-添加源文件 4-CMakeList中添加编译目标 5-测试 文档资料 CSA安装和运行最近在利用业余时间学习和研究代码检查工具，比对了几种代码检查工具之后，决定把Clang Static Analyzer（开源+可扩展性+丰富的文档）作为学习的对象，并尝试运用到我们的项目中去。本文我们将重点围绕llvm环境搭建，并实现一个简单的static analyzer checker。 VS中构建LLVM参考资料：https://llvm.org/docs/GettingStartedVS.html 1-环境预准备 Visual Studio 2019+，用2017试过，但构建失败了 Cmake python3.6+ pip install psutil 2-vs打开LLVM项目 下载LLVM项目： 1git clone https://github.com/llvm/llvm-project.git 用cmake生成vs项目文件 12cd llvm-projectcmake -S llvm -B build -DLLVM_ENABLE_PROJECTS=&quot;clang&quot; -DLLVM_TARGETS_TO_BUILD=X86 -DCMAKE_INSTALL_PREFIX=&quot;D:\\Program Files (x86)\\llvm&quot; -Thost=x64 再用vs代开build目录下的LLVM.sln文件，打开内容如下： 3-编译并添加命令参数默认是debug模式，编译clang.exe需要很长时间；改成release模式，可以快很多。编译完之后会在build目录下生成Debug/bin目录，再设置调试的命令参数，如下图所示： 添加第一个检查器参考资料：https://github.com/haoNoQ/clang-analyzer-guide/releases/download/v0.1/clang-analyzer-guide-v0.1.pdf下面的例子仅仅是为了让我们能够跑起来Clang Static Analyzer，对添加checker知道流程步骤即可，如果对其中的源码存在疑问，可以看后续文章。 1-测试文件目标代码如下： 12345typedef int (*main_t)(int, char**);int main(int argc, char** argv)&#123; main_t foo = main; return foo(argc, argv); // actually calls main()&#125; 我们要检查的内容就是: main函数是否在程序中被调用。 2-添加checker定义打开llvm-project\\clang\\include\\clang\\StaticAnalyzer\\Checkers\\Checkers.td，在alpha.core包中添加下面内容： 12345678def FixedAddressChecker : Checker&lt;&quot;FixedAddr&quot;&gt;, HelpText&lt;&quot;Check for assignment of a fixed address to a pointer&quot;&gt;, Documentation&lt;HasAlphaDocumentation&gt;;/// addeddef MainCallChecker : Checker&lt;&quot;MainCall&quot;&gt;, HelpText&lt;&quot;Check for calls to main&quot;&gt;, Documentation&lt;HasAlphaDocumentation&gt;; 这个td文件，会被TableGen工具翻译，翻译成.inc头文件，用于checker的注册。翻译之后的内容(部分)如下： 1234#ifdef GET_CHECKERS......CHECKER(&quot;osx.API&quot;, MacOSXAPIChecker, &quot;Check for proper uses of various Apple APIs&quot;, &quot;https://clang-analyzer.llvm.org/available_checks.html#osx.API&quot;, false)CHECKER(&quot;alpha.core.MainCall&quot;, MainCallChecker, &quot;Check for calls to main&quot;, &quot;https://clang-analyzer.llvm.org/alpha_checks.html#alpha.core.MainCall&quot;, false) 其中CHECKER的宏实现在BuiltinCheckerRegistration.h中，这里不再展开。 3-添加源文件在llvm-project\\clang\\lib\\StaticAnalyzer\\Checkers目录下新增文件MainCallChecker.cpp 123456789101112131415161718192021222324252627282930313233343536373839#include &quot;clang/StaticAnalyzer/Checkers/BuiltinCheckerRegistration.h&quot;#include &quot;clang/StaticAnalyzer/Core/BugReporter/BugType.h&quot;#include &quot;clang/StaticAnalyzer/Core/Checker.h&quot;#include &quot;clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h&quot;#include &quot;clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h&quot;using namespace clang;using namespace clang::ento;namespace &#123;// PreCall是一个ProgramPoint，StaticAnalyzer在分析过程中会进行回调class MainCallChecker : public Checker&lt;check::PreCall&gt; &#123; mutable std::unique_ptr&lt;BugType&gt; BT;public: void checkPreCall(const CallEvent &amp;Call, CheckerContext &amp;C) const;&#125;;&#125;void MainCallChecker::checkPreCall(const CallEvent &amp;Call, CheckerContext &amp;C) const &#123; if (const IdentifierInfo *II = Call.getCalleeIdentifier()) if (II-&gt;isStr(&quot;main&quot;)) &#123; if (!BT) BT.reset(new BugType(this, &quot;Call to main&quot;, &quot;Example checker&quot;)); ExplodedNode *N = C.generateErrorNode(); auto Report = std::make_unique&lt;PathSensitiveBugReport&gt;( *BT, BT-&gt;getDescription(), N); C.emitReport(std::move(Report)); &#125;&#125;// 注册checkervoid ento::registerMainCallChecker(CheckerManager &amp;Mgr) &#123; Mgr.registerChecker&lt;MainCallChecker&gt;();&#125;bool ento::shouldRegisterMainCallChecker(const CheckerManager &amp;mgr) &#123; return true;&#125; 4-CMakeList中添加编译目标在llvm-project\\clang\\lib\\StaticAnalyzer\\Checkers\\CMakeLists.txt 中添加 123VirtualCallChecker.cppMainCallChecker.cppWebKit/NoUncountedMembersChecker.cpp 5-测试重新编译obj.clangStaticAnalyzerCheckers和clang项目之后，测试 12345PS E:\\code&gt; clang -cc1 -analyze -analyzer-checker=&quot;alpha.core&quot; test.cpp.\\test.cpp:4:18: warning: Call to main [alpha.core.MainCall] int exit_code = foo(argc, argv); // actually calls main ()! ^~~~~~~~~~~~~~~1 warning generated. 可以看到，clangStaticAnalyzer确实找到了调用main函数的地方。同样的，如果仅仅需要检查（禁用）某个函数，仿照上面的过程即可。 文档资料学习CSA绕不开LLVM、Clang，好在LLVM的文档非常全面，以下全是官方文档链接：LLVM主页面(有提到三者的关系)：https://llvm.org/LLVM介绍(有跟gcc相比的优势)：https://llvm.org/pubs/2008-10-04-ACAT-LLVM-Intro.htmlLLVM向导(有通过LLVM编写新语言的官方教程)：https://llvm.org/docs/tutorial/index.htmlLLVM开发手册(项目结构等资料)：https://llvm.org/doxygen/Clang主页面：https://clang.llvm.org/Clang文档列表：https://clang.llvm.org/docs/index.htmlClang开发手册：https://clang.llvm.org/doxygen/CSA已有检查项：https://clang.llvm.org/docs/analyzer/checkers.htmlCSA开发教程：https://clang-analyzer.llvm.org/checker_dev_manual.htmlTablegen的介绍：https://llvm.org/docs/TableGen/ 除了上面的官方文档，还有一篇很好用的入门文章：CSA开发教程(16年写的)：https://github.com/haoNoQ/clang-analyzer-guide/releases/download/v0.1/clang-analyzer-guide-v0.1.pdf优秀的博客：https://www.zhihu.com/column/clang-static-analyzerhttps://csstormq.github.io/","categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://liji53.github.io/categories/LLVM/"}],"tags":[]},{"title":"原子类型","slug":"C++Basic/atomic","date":"2022-02-04T03:24:16.000Z","updated":"2022-02-04T03:24:16.000Z","comments":true,"path":"2022/02/04/C++Basic/atomic/","link":"","permalink":"https://liji53.github.io/2022/02/04/C++Basic/atomic/","excerpt":"","text":"原子类型 原子类型的实现 1.基本类型 2.内部类的关系与功能 3.基本操作 4.原子变量不能拷贝，赋值 5.atomic&lt;T&gt;自定义对象必须是POD 6.非atomic_flag不一定无锁 7.如果不是无锁的原子类型，其实底层实现就是mutex 8.原子读写的内部实现 9.默认内存顺序std::memory_order_seq_cst 10.compare_exchange_weak和compare_exchange_strong的区别 11.atomic_flag的实现 内存顺序 1.编译器指令重排序 2.内存模型 3.结论 原子类型的使用场景 无锁编程 参考资料 原子类型在c++11中，其中最大的一个变化就是对多线程的支持，而其中最重要的部分就是引入了原子类型。对原子类型的学习，需要一定的多线程基础，需要理解互斥、同步、原子操作等的相关概念，可以参考os-并发从原子类型对并发编程的意义来看，它是对临界资源的原子操作的抽象，比方test-and-set、compare-and-swap等这些原子操作抽象成了原理类型的方法。以前我们虽然只需要对数据互斥即可，但实际却是对代码段进行互斥，有了原子类型之后，将真正地实现数据的互斥而不是代码段互斥。 原子类型的实现下面我们结合源码(来自vs的atomic.h)来看看c++11的原子类型是如何实现的 1.基本类型在使用原子类型的时候，你可以直接用atomic_bool、atomic_char等类型，但更多的是使用std::atomic&lt;T&gt;类模板定义。其中T除了支持基本数据类型以外，还支持自定义的数据类型，自定义数据类型也能保证互斥，但不一定是lock-free的。在源码中，我们可以看到一系列的定义： 123using atomic_bool = atomic&lt;bool&gt;;using atomic_char = atomic&lt;char&gt;;/// 等等 2.内部类的关系与功能除了atomic&lt;T&gt;这个模板类之外，在它的内部实现中，我们还可以看到如_Atomic_integral_facade、_Atomic_integral、_Atomic_pointer、_Atomic_storage等。下面介绍下这些模板类的功能与关系： 1234567891011121314151617181920212223242526272829303132333435// 最低层的类，实际存储数据的类，提供最基本的读写（load和store）原子操作// 除了下面2种以外，还特例化了数据大小为2，4，8的类型template &lt;class _Ty, size_t /* = ... */&gt;struct _Atomic_storage&#123;&#125;； // 自定义数据结构，大小超过8的，平台不支持，内部使用的是自旋锁实现template &lt;class _Ty&gt; struct _Atomic_storage&lt;_Ty, 1&gt;&#123;&#125;； // 类型大小为1的，通过底层原子操作实现// 继承自_Atomic_storage的模板类，表示整型的原子类型，提供了整数的一系列操作如fetch_add、operator++等// _Atomic_storage类可以是自定义对象，因此只实现了读写的操作操作，而_Atomic_integral是对整型应该支持的原子操作的补充struct _Atomic_integral&lt;_Ty, 1&gt; : _Atomic_storage&lt;_Ty&gt;// 继承自_Atomic_storage的模板类,与_Atomic_integral类似，是对指针的原子操作的补充，比如指针++操作struct _Atomic_pointer : _Atomic_storage&lt;_Ty&gt; &#123;&#125;struct _Atomic_pointer&lt;_Ty&amp;&gt; : _Atomic_storage&lt;_Ty&amp;&gt; &#123;&#125;// _Atomic_integral_facade只是用来生成特定的_Atomic_integral类的，属于工厂类struct _Atomic_integral_facade : _Atomic_integral&lt;_Ty&gt;struct _Atomic_integral_facade&lt;_Ty&amp;&gt; : _Atomic_integral&lt;_Ty&amp;&gt;// 供用户使用的模板类，_Choose_atomic_base_t用于选择继承上述的基类，是实现的核心struct atomic : _Choose_atomic_base_t&lt;_Ty&gt; &#123;&#125;;// _Choose_atomic_base_t的实现template &lt;class _TVal, class _Ty = _TVal&gt;using _Choose_atomic_base2_t = typename _Select&lt;is_integral_v&lt;_TVal&gt; &amp;&amp; !is_same_v&lt;bool, _TVal&gt;&gt;::template _Apply&lt;_Atomic_integral_facade&lt;_Ty&gt;, typename _Select&lt;is_pointer_v&lt;_TVal&gt; &amp;&amp; is_object_v&lt;remove_pointer_t&lt;_TVal&gt;&gt;&gt;::template _Apply&lt; _Atomic_pointer&lt;_Ty&gt;, _Atomic_storage&lt;_Ty&gt;&gt;&gt;;// 如果上面的泛型编程看不懂，可以看这里T _Choose_atomic_base_t(T)&#123; if (is_integral(T) &amp;&amp; !is_bool(T))&#123; return _Atomic_integral_facade&lt;T&gt;; &#125; if (is_pointer(T))&#123; return _Atomic_pointer&lt;T&gt;; &#125; else&#123; return _Atomic_storage&lt;T&gt;; &#125;&#125; 这里的注释我写的挺详细的了,最后给出一张类关系图： 3.基本操作经过上一小节对atomic内部模板类的关系梳理，接下来对于不同原子类型所支持的操作应该就很好理解了。 操作 atomic_flag atomic&lt;bool&gt; atomic&lt;整型&gt; atomic&lt;指针&gt; atomic&lt;自定义&gt; test_and_set √ clear √ is_lock_free √ √ √ √ load,store √ √ √ √ exchange √ √ √ √ fetch_* √ √ 4.原子变量不能拷贝,赋值这是因为两个原子类型之间的操作不能保证原子化 12atomic(const atomic&amp;) = delete;atomic&amp; operator=(const atomic&amp;) = delete; 5.atomic&lt;T&gt;自定义对象必须是POD我们知道atomic&lt;T&gt;的类型可以是自定义对象，但自定义对象是有限制的 123/// 模板类中，有一个静态检查，表示T的类型必须是POD类型static_assert(is_trivially_copyable_v&lt;_Ty&gt; &amp;&amp; is_copy_constructible_v&lt;_Ty&gt; &amp;&amp; is_move_constructible_v&lt;_Ty&gt; &amp;&amp; is_copy_assignable_v&lt;_Ty&gt; &amp;&amp; is_move_assignable_v&lt;_Ty&gt;,&quot;...&quot;) 6.非atomic_flag不一定无锁除了atomic_flag,其他任何原子类型不一定是无锁的,具体跟平台相关。但在这个版本的VS中，只要是1,2,4,8大小的数据类型，就是无锁 1234_NODISCARD bool is_lock_free() const volatile noexcept &#123; constexpr bool _Result = sizeof(_Ty) &lt;= 8 &amp;&amp; (sizeof(_Ty) &amp; sizeof(_Ty) - 1) == 0; return _Result;&#125; 7.如果不是无锁的原子类型,其实底层实现就是mutex这个机制保证了一定的兼容性 1234567struct _Atomic_storage &#123; void store(const _TVal _Value, const memory_order _Order = memory_order_seq_cst) noexcept &#123; _Check_store_memory_order(_Order); _Guard _Lock&#123;_Spinlock&#125;; _Storage = _Value; &#125;&#125;； 8.原子读写的内部实现这里用的是windows的原子操作：_InterlockedExchange64 1234567891011121314151617struct _Atomic_storage&lt;_Ty, 8&gt;&#123; void store(const _TVal _Value) noexcept &#123; // store with sequential consistency const auto _Mem = _Atomic_address_as&lt;long long&gt;(_Storage); const long long _As_bytes = _Atomic_reinterpret_as&lt;long long&gt;(_Value);#if defined(_M_IX86) _Compiler_barrier(); __iso_volatile_store64(_Mem, _As_bytes); _STD atomic_thread_fence(memory_order_seq_cst);#elif defined(_M_ARM64) _Memory_barrier(); __iso_volatile_store64(_Mem, _As_bytes); _Memory_barrier();#else // ^^^ _M_ARM64 / ARM32, x64 vvv (void) _InterlockedExchange64(_Mem, _As_bytes);#endif // _M_ARM64 &#125;&#125;； 9.默认内存顺序std::memory_order_seq_cststd::memory_order_seq_cst指顺序一致性，关于内存顺序，我们稍后唠嗑， 1234_Ty operator=(const _Ty _Value) noexcept &#123; this-&gt;store(_Value); return _Value;&#125; 10.compare_exchange_weak和compare_exchange_strong的区别weak的意思是允许偶然出乎意料的返回(比如实际值和期待值一样的时候却返回了false)，通常它比起strong有更高的性能。可惜在vs的这个版本中并没有实现，与strong版本是一样的。 12345bool compare_exchange_weak(_Ty&amp; _Expected, const _Ty _Desired) volatile noexcept &#123; // we have no weak CAS intrinsics, even on ARM32/ARM64, so fall back to strong static_assert(_Deprecate_non_lock_free_volatile&lt;_Ty&gt;, &quot;Never fails&quot;); return this-&gt;compare_exchange_strong(_Expected, _Desired);&#125; 11.atomic_flag的实现atomic_flag 不一定是bool，比方这里就是long类型，atomic_flag一般是符合标准的最小的硬件实现类型，所以一定是无锁的 12345678910111213struct atomic_flag &#123; bool test_and_set(const memory_order _Order = memory_order_seq_cst) noexcept &#123; return _Storage.exchange(true, _Order) != 0; &#125; void clear(const memory_order _Order = memory_order_seq_cst) noexcept &#123; _Storage.store(false, _Order); &#125;#if 1 // TRANSITION, ABI atomic&lt;long&gt; _Storage;#else // ^^^ don&#x27;t break ABI / break ABI vvv atomic&lt;bool&gt; _Storage;#endif // TRANSITION, ABI&#125;; 内存顺序这部分的内容，其实我个人认为除了追求极致的并发性能以外，并不用太关注这个内存顺序，使用默认的内存顺序即可。现在我们再来看看为什么会有所谓的内存顺序？这里我们需要一些计算机组成原理、编译器相关的知识。 1.编译器指令重排序编译器编译的时候会经历Front-end(词法、语法等)、Optimizer、CodeGen 这三个阶段。在优化阶段（Optimizer）如果编译器认为代码的执行顺序不影响最终的结果，则可以依据情况将指令重排序从而提高性能。如: 123456// b的赋值不影响最终结果，可以重排序void func()&#123; int t = 1; a = t; // 全局原子类型 b = 2; // 全局原子类型&#125; 这段代码如果是在多线程情况下，可能就会因为重排序而发生问题。比如另一个线程需要根据b的值，对a进行某些操作，这时我们需要“顺序一致”。但也有可能，我们仅仅只是对a、b进行赋值，顺序的先后并不重要，这时我们仅需要互斥即可。因此需要内存顺序的一个原因就是因为编译器指令重排序的问题。 2.内存模型关于编译器的重排序问题，可能有人想到了可以用volatile来防止编译器的优化，但如果cpu对指令顺序进行优化，可能就没办法了。 在计算机组成原理中，有一个叫指令流水线的概念，简单来说，就是将一条指令分解成诺干阶段，如取指、译码、执行等阶段，由于每个阶段用到的硬件不一样，可以让这些指令分阶段的并发执行，从而加快指令的执行速度。而超标量流水线技术，是指令流水线的升级，以前取指、译码、执行等各个阶段各自只有一套硬件环境，现在硬件存在多套，于是就可以做到让每个时钟周期内并发多条独立指令。这种超标量流水线技术会导致在不影响结果的情况，cpu会优化指令的执行顺序。在实现中，X86平台其实并不会改变指令执行顺序(强顺序)，但如果是ArmV7这些架构的，则会改变指令执行顺序（弱顺序）。因此对于这些弱顺序的，为了保证执行的先后顺序，通常需要加入memory barrier,细心的同学可能已经发现了前面讲原子类型的实现时，已经出现过内存栅栏了。从8.原子读写的内部实现中可以看到在对store的实现中就对_M_IX86和_M_ARM64平台加入了内存栅栏，而x64架构就不需要内存栅栏。 3.结论在清楚了底层的指令执行顺序的之后，我们可能希望编译器或者cpu对指令顺序进行优化，从而提高性能，也可能要求指令必须顺序执行，因此就有了内存顺序这一个概念。在atomic&lt;T&gt;的接口中，最基本的几种接口像store、load是支持内存顺序，但正如一开始所说的，除了追求极限的执行效率，个人认为使用默认的强顺序一致即可。不用内存顺序的另一个原因则是因为编译器对内存顺序的支持情况可能是一样的，比如我在看VS对内存顺序的实现时，就发现除了memory_order_relaxed，其他的内存顺序都是强顺序一致的。最后，给出内存顺序的结论： 内存顺序 说明 std::memory_order_relaxed 同一个线程中, 不同原子变量可以是乱序的 std::memory_order_consume no reads or writes in the current thread dependent on the value currently loaded can be reordered before this load. Writes to data-dependent variables in other threads that release the same atomic variable are visible in the current thread. On most platforms, this affects compiler optimizations only std::memory_order_acquire no reads or writes in the current thread can be reordered before this load. All writes in other threads that release the same atomic variable are visible in the current thread std::memory_order_release no reads or writes in the current thread can be reordered after this store. All writes in the current thread are visible in other threads that acquire the same atomic variable std::memory_order_acq_rel 略 std::memory_order_seq_cst 顺序一致性，所有的线程观察到的整个程序中内存修改顺序是一致的 原子类型的使用场景无锁编程无锁编程的优势主要是2个： 避免了死锁、饥饿的产生 临界区非常短、竞争激烈的场景 在内存数据库领域就用到了相关的技术。 业界应用参考：https://www.zhihu.com/question/52629893最后从网上随便找了一个相关的无锁数据结构，仅供参考： 1234567891011121314151617template&lt;class T&gt;struct node&#123; T data; node* next; node(const T&amp; data) : data(data), next(nullptr) &#123;&#125;&#125;;template&lt;class T&gt;struct stack&#123; std::atomic&lt;node&lt;T&gt;*&gt; head; void push(const T&amp; data) &#123; node&lt;T&gt;* new_node = new node&lt;T&gt;(data); new_node-&gt;next = head.load(std::memory_order_relaxed); while (!head.compare_exchange_strong(new_node-&gt;next, new_node, std::memory_order_release)); &#125;&#125;; 参考资料《深入理解C++11：C++11新特性解析与应用》内存顺序的解释[英]：https://en.cppreference.com/w/cpp/atomic/memory_order","categories":[{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"利用lex和yacc做代码检查(上)","slug":"C++Project/lexAndYacc","date":"2022-01-13T09:15:34.000Z","updated":"2022-01-13T09:15:34.000Z","comments":true,"path":"2022/01/13/C++Project/lexAndYacc/","link":"","permalink":"https://liji53.github.io/2022/01/13/C++Project/lexAndYacc/","excerpt":"","text":"利用lex和yacc做代码检查(上)这篇文章我们将使用lex和yacc来对公司代码进行扫描检查。背景：公司的业务代码是用伪代码和c++来实现的，再由开发工具翻译成c++语言，本次我们要代码检查的就是这些伪代码以及c++代码组成的业务代码，然后找出其中的类型不一致等问题。 预备知识以下的预备知识，对于理解lex和yacc的程序是必须的，因此如果不清楚，须先自学 编译原理, 要求理c/c++解编译器的整体流程、理解词法分析、语法分析概述(转): https://blog.csdn.net/cprimesplus/article/details/105724168 正则表达式，主要在lex语法中用到，要求至少能看懂入门：https://liji53.github.io/2021/12/03/regxStudy/ lex和yacc的语法，2者语法结构类似，yacc比lex要复杂一些，先理解清楚lex，再去理解yacc会容易很多lex入门(转)：https://www.cnblogs.com/wp5719/p/5528896.htmllex和yacc小结(转)：https://www.daimajiaoliu.com/daima/4717f8908900400 c语言的语法文件，要求能看懂。 这两个文件是本次语法分析的基础文件，后续代码都在此基础上添加的c语言lex的语法文件：http://www.quut.com/c/ANSI-C-grammar-l-1998.htmlc语言yacc的语法文件：http://www.quut.com/c/ANSI-C-grammar-y-1998.html 本次词法、语法分析的目标公司的业务代码长这个样子，这种[xxx]的写法就是伪代码，其本质是宏。c++部分的语法分析由于我只找到c的语法分析，而且用c的语法分析对接下来的语法解析足够了，因此直接使用最新的The ANSI C grammar(上文已经提到)，这个文件后续作为待测试文件记test.cpp 12345678910111213// 1）函数调用基本写法：[函数名][入参][出参][function_name][parameter1=1, parameter2=&quot;test&quot;][output1=@id]// 2）函数调用多行写法[function_name2][ parameter1=1, parameter2=&quot;test&quot;][]// 3）宏调用写法,&lt;A-Z&gt; 可无&lt;A&gt;[marco][marco][variable][]// c++语法for(int i = 0; i &lt; 10; i++)&#123; variable1 = variable2;&#125; 先熟悉流程这一步我们通过生成c语言的语法分析器，来熟悉lex和yacc的流程。下载http://www.quut.com/c/ANSI-C-grammar-l-1998.html, 命名c.l下载http://www.quut.com/c/ANSI-C-grammar-y-1998.html, 命名c.y 1. 编译词法文件, 会生成lex.yy.c12# 编译词法文件lex c.l 2. 编译语法文件, 会生成y.tab.c, y.tab.h1234567891011121314151617# 直接编译会出现yacc: 1 shift/reduce conflict. 错误，先编辑c.y文件# 2.1 在c.y的序幕部分加以下内容%nonassoc LOWER_THAN_ELSE%nonassoc ELSE# 2.2 在c.y的规则部分selection_statement修改成以下内容selection_statement : IF &#x27;(&#x27; expression &#x27;)&#x27; statement %prec LOWER_THAN_ELSE | IF &#x27;(&#x27; expression &#x27;)&#x27; statement ELSE statement | SWITCH &#x27;(&#x27; expression &#x27;)&#x27; statement ;# 2.3 在c.y的最后，增加main函数int main(void) &#123; yyparse(); return 0;&#125;# 2.4 编译语法文件，其中-d用来生成头文件yacc -d c.y 3. 生成语法分析器, 生成a.out1gcc y.tab.c lex.yy.c 4. 测试词法分析器12345678# 4.1 写一个简单的c文件,带上错误echo &quot;int main()&#123;a=b&#125;&quot; &gt; test.cpp # 4.2 测试下分析器能不能检查出错误./a.out &lt; test.cpp# 4.3 程序输出结果如下，perfectint main()&#123;a=b&#125; ^ syntax error 词法分析lex在这里词法分析主要对上面示例中的1,2,3种写法进行解析，这里需要判断是否是伪代码，并返回伪代码的标记。由于c.l源文件内容较多，这里只贴修改部分代码 1. 在定义部分，增加2个伪代码的状态标志123456789%&#123;#include &lt;stdio.h&gt; #include &quot;y.tab.h&quot;void count(void);int marco_flag = 0; //伪代码状态，与MARCO_HEAD类似,表示除第一个[xxx]以外的状态%&#125;/* 状态（或条件）定义- 用来标志伪代码头,即第一个[xxx]部分的状态 */%s MARCO_HEAD%% 2. 在规则部分，增加伪代码的规则解析MARCO_SYMBOL_BEGIN、MARCO_NAME等需要在c.y中定义。 12345678910111213141516171819202122&quot;&lt;&quot;[A-Z]&quot;&gt;[&quot; &#123;count(); BEGIN MARCO_HEAD; return(MARCO_SYMBOL_BEGIN); &#125;[ \\t]*&quot;[&quot; &#123;count(); BEGIN MARCO_HEAD; return(MARCO_SYMBOL_BEGIN); &#125;&lt;MARCO_HEAD&gt;&#123;L&#125;(&#123;L&#125;|&#123;D&#125;)* &#123;count(); return(MARCO_NAME); &#125;&lt;MARCO_HEAD&gt;&quot;][&quot; &#123;count(); BEGIN INITIAL; marco_flag = 1; return(MARCO_SYMBOL_SPLIT); &#125; &lt;MARCO_HEAD&gt;&quot;]&quot; &#123;/*必须 写在&lt;MARCO_HEAD&gt;&quot;][&quot; 之后*/ count(); BEGIN INITIAL; return(MARCO_SYMBOL_END); &#125; &lt;MARCO_HEAD&gt;[ \\t\\v\\n\\f] &#123;count(); &#125;&lt;MARCO_HEAD&gt;. &#123;/* ECHO是一个宏，相当于 fprintf(yyout, &quot;%s&quot;, yytext)*/ ECHO; &#125; &quot;]&quot; &#123; count(); if(marco_flag)&#123; if(input() == &#x27;[&#x27;)&#123; return (MARCO_SYMBOL_SPLIT); &#125; else&#123; marco_flag = 0; return (MARCO_SYMBOL_END); &#125; &#125; else&#123; return(&#x27;]&#x27;); &#125; &#125; 这部分代码至少要放在下面代码之前，否则会因为规则的先后匹配错误 12(&quot;[&quot;|&quot;&lt;:&quot;) &#123; count(); return(&#x27;[&#x27;); &#125;(&quot;]&quot;|&quot;:&gt;&quot;) &#123; count(); return(&#x27;]&#x27;); &#125; 测试lex正确性最后我们测试下词法分析器的正确性，待测试文件即上文提到的test.cpp 1. 在c.y中定义部分添加宏定义后面只用到了c.y生成的头文件 1%token MARCO_SYMBOL_BEGIN MARCO_SYMBOL_SPLIT MARCO_SYMBOL_END MARCO_NAME 2. 在c.l中添加main函数123456789101112131415161718192021222324252627void writeout(int c)&#123; switch(c)&#123; case MARCO_SYMBOL_BEGIN: fprintf(yyout, &quot;(MARCO_SYMBOL_BEGIN, \\&quot;%s\\&quot;) &quot;, yytext);break; case MARCO_SYMBOL_SPLIT: fprintf(yyout, &quot;(MARCO_SYMBOL_SPLIT, \\&quot;%s\\&quot;) &quot;, yytext);break; case MARCO_SYMBOL_END: fprintf(yyout, &quot;(MARCO_SYMBOL_END, \\&quot;%s\\&quot;) &quot;, yytext);break; case MARCO_NAME: fprintf(yyout, &quot;(MARCO_NAME, \\&quot;%s\\&quot;) &quot;, yytext);break; case IDENTIFIER: fprintf(yyout, &quot;(IDENTIFIER, \\&quot;%s\\&quot;) &quot;, yytext);break; case CONSTANT: fprintf(yyout, &quot;(CONSTANT, \\&quot;%s\\&quot;) &quot;, yytext);break; case STRING_LITERAL: fprintf(yyout, &quot;(STRING_LITERAL, \\&quot;%s\\&quot;) &quot;, yytext);break; case SIZEOF: fprintf(yyout, &quot;(SIZEOF, \\&quot;%s\\&quot;) &quot;, yytext);break; default:break; &#125;&#125;int main (int argc, char ** argv)&#123; int c; if (argc&gt;=2)&#123; if ((yyin = fopen(argv[1], &quot;r&quot;)) == NULL)&#123; printf(&quot;Can&#x27;t open file %s\\n&quot;, argv[1]); return -1; &#125; while (c = yylex())&#123; writeout(c); &#125; fclose(yyin); &#125; return 0;&#125; 3. 编译词法分析器1lex lex.l &amp;&amp; yacc -d yacc.y &amp;&amp; gcc lex.yy.c 4. 测试test.cpp12345678910111213[liji@null test_compile]$ ./a.out test.cpp[(MARCO_SYMBOL_BEGIN, &quot;[&quot;) function_name(MARCO_NAME, &quot;function_name&quot;) ][(MARCO_SYMBOL_SPLIT, &quot;][&quot;) parameter1(IDENTIFIER, &quot;parameter1&quot;) =1(CONSTANT, &quot;1&quot;) , parameter2(IDENTIFIER, &quot;parameter2&quot;) =&quot;test&quot;(STRING_LITERAL, &quot;&quot;test&quot;&quot;) ](MARCO_SYMBOL_SPLIT, &quot;]&quot;) output1(IDENTIFIER, &quot;output1&quot;) =id(IDENTIFIER, &quot;id&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) [(MARCO_SYMBOL_BEGIN, &quot;[&quot;) function_name2(MARCO_NAME, &quot;function_name2&quot;) ][(MARCO_SYMBOL_SPLIT, &quot;][&quot;) parameter1(IDENTIFIER, &quot;parameter1&quot;) =1(CONSTANT, &quot;1&quot;) , parameter2(IDENTIFIER, &quot;parameter2&quot;) =&quot;test&quot;(STRING_LITERAL, &quot;&quot;test&quot;&quot;) ](MARCO_SYMBOL_SPLIT, &quot;]&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) &lt;A&gt;[(MARCO_SYMBOL_BEGIN, &quot;&lt;A&gt;[&quot;) marco(MARCO_NAME, &quot;marco&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) [(MARCO_SYMBOL_BEGIN, &quot;[&quot;) marco(MARCO_NAME, &quot;marco&quot;) ][(MARCO_SYMBOL_SPLIT, &quot;][&quot;) xxx(IDENTIFIER, &quot;xxx&quot;) ](MARCO_SYMBOL_SPLIT, &quot;]&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) for(int i(IDENTIFIER, &quot;i&quot;) = 0(CONSTANT, &quot;0&quot;) ; i(IDENTIFIER, &quot;i&quot;) &lt; 10(CONSTANT, &quot;10&quot;) ; i(IDENTIFIER, &quot;i&quot;) ++)&#123; variable1(IDENTIFIER, &quot;variable1&quot;) = variable2(IDENTIFIER, &quot;variable2&quot;) ; 从上文的第7行， ](MARCO_SYMBOL_SPLIT, “]”)这个内容其实是有问题的。 因为在规则部分，处理”]”的时候，用到了input()来判断下个字符是不是”[“， 因此yytext的值是”]”，其实应该是”][“","categories":[],"tags":[]},{"title":"smart_ptr","slug":"C++Basic/smart-ptr","date":"2022-01-08T21:48:07.000Z","updated":"2022-01-08T21:48:07.000Z","comments":true,"path":"2022/01/08/C++Basic/smart-ptr/","link":"","permalink":"https://liji53.github.io/2022/01/08/C++Basic/smart-ptr/","excerpt":"","text":"智能指针的实现shared_ptr 的实现我们都知道靠引用计数，但引用计数的生命周期是怎么样的，智能指针是否线程安全，weak_ptr是否需要计数？现在我们通过阅读源码，来一探究竟。 shared_ptr的实现代码来自vs的memory.h,用的是c++14标准 构造函数(c++11动态数组，需要显式提供delete functor)在vs中神奇的发现c++17才支持的动态数组，c++14就支持了 12345678910111213141516171819202122template &lt;class _Ty&gt;class shared_ptr : public _Ptr_base&lt;_Ty&gt; &#123; explicit shared_ptr(_Ux* _Px) &#123; // construct shared_ptr object that owns _Px /// 已经能自动选择数组类型的删除器 if constexpr (is_array_v&lt;_Ty&gt;) &#123; _Setpd(_Px, default_delete&lt;_Ux[]&gt;&#123;&#125;); &#125; else &#123; _Temporary_owner&lt;_Ux&gt; _Owner(_Px); /// 由于shared_ptr的生命周期随时可以结束，因此引用计数器必须是在heap上 _Set_ptr_rep_and_enable_shared(_Owner._Ptr, new _Ref_count&lt;_Ux&gt;(_Owner._Ptr)); _Owner._Ptr = nullptr; &#125; &#125; _NODISCARD _Elem&amp; operator[](ptrdiff_t _Idx) const noexcept /* strengthened */ &#123; return get()[_Idx]; &#125;&#125;；// 测试std::cout &lt;&lt; __cplusplus &lt;&lt; std::endl; // 201402std::shared_ptr&lt;int[]&gt; p_list(new int[4]&#123; 1,2,3,4 &#125;); // 本来应该在c++17中才支持的std::cout &lt;&lt; p_list[1] &lt;&lt; std::endl; // 2，同上 拷贝构造/移动构造函数/赋值移动系列的函数，会使原shared_ptr变成空指针赋值会使原shared_ptr引用计数减一 12345678910111213141516171819202122shared_ptr(const shared_ptr&amp; _Other) noexcept &#123; // construct shared_ptr object that owns same resource as _Other this-&gt;_Copy_construct_from(_Other);&#125;void _Copy_construct_from(const shared_ptr&lt;_Ty2&gt;&amp; _Other) noexcept &#123; // implement shared_ptr&#x27;s (converting) copy ctor _Other._Incref(); _Ptr = _Other._Ptr; _Rep = _Other._Rep;&#125;void _Move_construct_from(_Ptr_base&lt;_Ty2&gt;&amp;&amp; _Right) noexcept &#123; // implement shared_ptr&#x27;s (converting) move ctor and weak_ptr&#x27;s move ctor _Ptr = _Right._Ptr; _Rep = _Right._Rep; _Right._Ptr = nullptr; _Right._Rep = nullptr;&#125;/// 减一是因为shared_ptr(_Right)是个临时变量，在swap出作用域之后就析构shared_ptr&amp; operator=(const shared_ptr&lt;_Ty2&gt;&amp; _Right) noexcept &#123; shared_ptr(_Right).swap(*this); return *this;&#125; weak_ptr的实现weak_ptr 类型指针不会导致堆内存空间的引用计数增加或减少。另外weak_ptr没有实现operator-&gt;和operator* 构造函数12345678910111213141516171819template &lt;class _Ty&gt;class weak_ptr : public _Ptr_base&lt;_Ty&gt; &#123; weak_ptr(const weak_ptr&amp; _Other) noexcept &#123; this-&gt;_Weakly_construct_from(_Other); // same type, no conversion &#125; weak_ptr(const shared_ptr&lt;_Ty2&gt;&amp; _Other) noexcept &#123; this-&gt;_Weakly_construct_from(_Other); // shared_ptr keeps resource alive during conversion &#125; /// 不增加shared_ptr的引用计数，增加weak_ptr的引用计数 void _Weakly_construct_from(const _Ptr_base&lt;_Ty2&gt;&amp; _Other) noexcept &#123; // implement weak_ptr&#x27;s ctors if (_Other._Rep) &#123; _Ptr = _Other._Ptr; _Rep = _Other._Rep; _Rep-&gt;_Incwref(); &#125; else &#123; _STL_INTERNAL_CHECK(!_Ptr &amp;&amp; !_Rep); &#125; &#125;&#125; lock函数123456789101112131415_NODISCARD shared_ptr&lt;_Ty&gt; lock() const noexcept &#123; // convert to shared_ptr shared_ptr&lt;_Ty&gt; _Ret; (void) _Ret._Construct_from_weak(*this); return _Ret;&#125;bool _Construct_from_weak(const weak_ptr&lt;_Ty2&gt;&amp; _Other) noexcept &#123; // implement shared_ptr&#x27;s ctor from weak_ptr, and weak_ptr::lock() if (_Other._Rep &amp;&amp; _Other._Rep-&gt;_Incref_nz()) &#123; _Ptr = _Other._Ptr; _Rep = _Other._Rep; return true; &#125; return false;&#125; 引用计数通过前面的源码大家也可以看出来，shared_ptr和weak_ptr在交换指针时并不是线程安全的，但引用计数却是线程安全的shared_ptr的引用计数为0，管理的对象可以销毁，但引用计数对象可能仍然存在，需要weak_ptr的引用计数也为0，才销毁 接口与成员变量12345678910111213141516171819202122232425262728#define _MT_INCR(x) _INTRIN_RELAXED(_InterlockedIncrement)(reinterpret_cast&lt;volatile long*&gt;(&amp;x))#define _MT_DECR(x) _INTRIN_ACQ_REL(_InterlockedDecrement)(reinterpret_cast&lt;volatile long*&gt;(&amp;x))class __declspec(novtable) _Ref_count_base &#123; virtual void _Destroy() noexcept = 0; // destroy managed resource virtual void _Delete_this() noexcept = 0; // destroy self _Atomic_counter_t _Uses = 1; _Atomic_counter_t _Weaks = 1;/// 原子操作 void _Incref() noexcept &#123; // increment use count _MT_INCR(_Uses); &#125; void _Incwref() noexcept &#123; // increment weak reference count _MT_INCR(_Weaks); &#125;/// shared_ptr的引用计数为0，则释放资源对象 void _Decref() noexcept &#123; // decrement use count if (_MT_DECR(_Uses) == 0) &#123; _Destroy(); _Decwref(); &#125; &#125;/// 只有weak_ptr的引用计数为0，才释放引用计数 void _Decwref() noexcept &#123; // decrement weak reference count if (_MT_DECR(_Weaks) == 0) &#123; _Delete_this(); &#125; &#125;&#125;;","categories":[{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"正则表达式入门","slug":"pythonOther/regxStudy","date":"2021-12-03T02:22:13.000Z","updated":"2021-12-03T02:22:13.000Z","comments":true,"path":"2021/12/03/pythonOther/regxStudy/","link":"","permalink":"https://liji53.github.io/2021/12/03/pythonOther/regxStudy/","excerpt":"","text":"正则表达式从入门到工作最近工作中用到了很多正则表达式，多少需要记录下使用心得。但一直犹豫要不要写这篇文章，因为网上的正则表达式太多，但想到，写笔记是为了以后的方便，还是决定做吧，而且除了要写基础的，更要写一些特色出来。 是什么简单来说，正则表达式就是用来对文件(字符串)进行匹配的语言(规则)，匹配到之后呢，就可以对文本进行增删改查，增删改查跟语言相关，因此不涉及这方面知识，当然示例代码用的是python 正则表达式的广泛应用最开始接触正则是在shell命令下的grep、sed、awk，后来用的python、js等语言也都支持(包括C++在C11标准中也支持了正则).擅长用工具的人，还能发现像notepad、Everything等各种工具都支持正则,正则表达式就像基础功能一样，不管在编程语言中，还是工具中都有广泛的应用 学习资料，网站正是如此的广泛的应用，因此网上学习资料是不缺的。 在线测试用具：https://tool.oschina.net/regex 常用正则表达式(转)：https://blog.csdn.net/sirobot/article/details/89478951 正则表达式原理(转)：https://zhuanlan.zhihu.com/p/107836267 正则表达式入门基础语法1. 匹配普通文本12re.search(r&#x27;hello world&#x27;,&#x27;example hello world!&#x27;)# &lt;re.Match object; span=(8, 19), match=&#x27;hello world&#x27;&gt; 匹配任意一个字符.(除了换行符\\n) 12re.search(r&#x27;..llo&#x27;,&#x27;example hello world!&#x27;)#&lt;re.Match object; span=(8, 13), match=&#x27;hello&#x27;&gt; 2. 匹配字符组[]虽然叫字符组，但其实匹配的还是一个字符，只不过这个字符是一个范围 123# 匹配axample，bxample，cxample,[abc]表示a或b或cre.search(r&#x27;[abc]xample&#x27;,&#x27;cxample hello world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;cxample&#x27;&gt; 如果字符很多，可以使用-来表示一个范围的字符 123# 匹配axample，bxample，cxample,[a-c]等价[abc]re.search(r&#x27;[a-c]xample&#x27;,&#x27;cxample hello world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;cxample&#x27;&gt; 还可以用^来表示非的意思 123# 匹配axample，bxample，cxample,[^d-z]等价[abc]re.search(r&#x27;[^d-z]xample&#x27;,&#x27;cxample hello world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;cxample&#x27;&gt; 3. 转义字符 \\转义字符主要是为了匹配一些无法表达的特殊字符，如\\t,\\n等。转义字符跟字符集一样，仅匹配一个字符 123# 这里\\t匹配制表符re.search(r&#x27;\\texample&#x27;,&#x27; example hello world!&#x27;)#&lt;re.Match object; span=(0, 8), match=&#x27;\\texample&#x27;&gt; 转义字符也可以用来表示一类字符，如\\w,\\d,\\s等 123# 这里\\w 等价[a-z0-9_]re.search(r&#x27;\\w&#x27;,&#x27; example hello world!&#x27;)# &lt;re.Match object; span=(1, 2), match=&#x27;e&#x27;&gt; 数量词前面的基础语法都只能匹配一个字符，如果需要匹配多次，下面的数量词就派上用场了,数量词需要在字符之后 1. 基础数量词匹配0次或者无限次*匹配1次或者无限次+匹配0次或者1次？ 123456# 匹配至少一个空白字符 后接 至少一个[a-z0-9_]字符 re.search(r&#x27;\\s+\\w+&#x27;,&#x27;example hello_world!&#x27;)# &lt;re.Match object; span=(7, 19), match=&#x27; hello_world&#x27;&gt;# 匹配0个或一个空白字符 后接 至少一个[a-z0-9_]字符re.search(r&#x27;\\s?\\w+&#x27;,&#x27;example hello_world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;example&#x27;&gt; 2. 匹配诺干次{m} 匹配前一个字符m次{n,m} 匹配前一个字符n至m次 123# 匹配数字 4到5次re.search(r&#x27;\\d&#123;4,5&#125;&#x27;,&#x27;1 22 333 4444&#x27;)# &lt;re.Match object; span=(9, 13), match=&#x27;4444&#x27;&gt; 字符边界(位置匹配)字符边界简单来说就是匹配字符在哪个位置, 但除了^和$常用，平常用的比较少。对于边界字符的理解，可以把位置看成空字符，即”” 1. 简单常用位置符号^表示开头$表示结尾 123# 不匹配&#x27;11 21&#x27;re.search(r&#x27;^\\d+ 22$&#x27;,&#x27;11 22&#x27;)# &lt;re.Match object; span=(0, 5), match=&#x27;11 22&#x27;&gt; 2. 其他位置符号\\b是单词边界，就是\\w和\\W之间的位置\\B是\\b的反面，即非单词边界 123# 从结果可以看到，还包括\\w和^、$之间的位置re.sub(r&#x27;\\b&#x27;,&quot;@&quot;,&#x27;1.Hello world&#x27;)# &#x27;@1@.@Hello@ @world@&#x27; 3. 先行断言(?=exp) 其中exp是一个子表达式，即exp前面的位置。(?!exp) 与上面相反 12345# 把位置理解成&quot;&quot;,这里就是在ll字符前面的空字符替换成@re.sub(r&#x27;(?=ll)&#x27;,&quot;@&quot;,&#x27;1.Hello worlld&#x27;)# &#x27;1.He@llo wor@lld&#x27;re.sub(r&#x27;(?!ll)&#x27;,&quot;@&quot;,&#x27;1.Hello worlld&#x27;)# &#x27;@1@.@H@el@l@o@ @w@o@rl@l@d@&#x27; 分组和引用前面讲了字符组[ab], 但这只能表示一个字符, 如果想要匹配ab或者cd就无能为力了；又或者ab*, *只作用于一个字符，你想要把ab作为一个整体匹配多次，同样无能为力。分组用于解决这些问题，分组也可以认为是子表达式 1. 分组(exp) 其中exp是子表达|式 表示左右任意匹配一个 123# 匹配&#x27;.&#x27;前面是数字或者字母的re.search(r&#x27;(\\d+|[a-zA-Z]+)\\.&#x27;,&#x27;1.hello&#x27;)# &lt;re.Match object; span=(0, 2), match=&#x27;1.&#x27;&gt; 2. 引用引用是为了对重复出现的文本进行匹配，要引用需要先分组(exp) 会自动产生编号，从1开始;&lt;number&gt; 引用编号为number的分组匹配到的字符串(?:exp) 不会捕获，即不会有编号(?P&lt;name&gt;exp) 定义一个命名分组;(?P=name)引用别名为name的分组匹配到的字符串 123456789# 常用于匹配html标签re.search(r&#x27;&lt;([a-z]+)&gt;.*&lt;/\\1&gt;&#x27;,&#x27;&lt;span&gt;xxx&lt;/span&gt;&#x27;)# &lt;re.Match object; span=(0, 16), match=&#x27;&lt;span&gt;xxx&lt;/span&gt;&#x27;&gt;# (?:span) 不捕获，没有编号re.search(r&#x27;&lt;(?:span)&gt;&lt;(div)&gt;.*&lt;/\\1&gt;&#x27;,&#x27;&lt;span&gt;&lt;div&gt;xxx&lt;/div&gt;&#x27;)# &lt;re.Match object; span=(0, 20), match=&#x27;&lt;span&gt;&lt;div&gt;xxx&lt;/div&gt;&#x27;&gt;# 使用别名re.search(r&#x27;&lt;(?P&lt;name1&gt;\\w+)&gt;&lt;(?P&lt;name2&gt;h[1-5])&gt;.*&lt;/(?P=name2)&gt;&lt;/(?P=name1)&gt;&#x27;,&#x27;&lt;html&gt;&lt;h1&gt;xxx&lt;/h1&gt;&lt;/html&gt;&#x27;)# &lt;re.Match object; span=(0, 25), match=&#x27;&lt;html&gt;&lt;h1&gt;xxx&lt;/h1&gt;&lt;/html&gt;&#x27;&gt; 正则表达式不能干的事几乎所有讲正则表达式的博客，都是在说正则表达式无所不能，这里我结合实际，把实际中无法直接用正则匹配的情况说下，当然也可能是我水平不够，写不出来。 1. 不能(^abc)字符集可以[^abc]，表示非abc的字符；但没有表示非abc字符串的表达式，(^abc),^表示的是开头 2. 不能就近匹配比方“select a from select a into b”, 我希望匹配离into最近的select，但事与愿违 总结我写的内容虽然没有覆盖全正则表达式的所有语法，但作为入门足够了。正如前面写的，正则表达式在工具中也有广泛应用，在平常工作中可以多用正则表达式来查找文件，查找奇奇怪怪的内容，对工作效率提升up","categories":[],"tags":[]},{"title":"allocator","slug":"C++Basic/stl-allocator","date":"2021-10-11T19:04:04.000Z","updated":"2021-10-11T19:04:04.000Z","comments":true,"path":"2021/10/11/C++Basic/stl-allocator/","link":"","permalink":"https://liji53.github.io/2021/10/11/C++Basic/stl-allocator/","excerpt":"","text":"分配器杂谈分配器在stl的容器中用于空间的分配与释放，以及对象的初始化与析构，下面我们简单了解下stl 6大组件中的allocator 分配器的思想与接口分配器将内存的分配与对象的构造行为分离出来，一是为了提高效率对于已分配好的内存可以反复利用，避免内存碎片，但更重要的是为了泛型编程的可复用性，降低内存分配与构造行为的耦合性。 1.基本接口12345678template &lt;class T&gt;T* allocator&lt;T&gt;::allocate(size_type n);template &lt;class T&gt;void allocator&lt;T&gt;::deallocate(T* ptr);template &lt;class T&gt;void allocator&lt;T&gt;::construct(T* ptr);template &lt;class T&gt;void allocator&lt;T&gt;::destroy(T* ptr) allocate和deallocate 在gcc中的实现就是::operator new和delete而construct 用到了placement new，为的是调用对象的构造函数。而destroy 自然是显式调用析构函数 2.rebind在allocator的实现中都会有一个rebind的结构体，它的作用是获得其他类型的内存分配器allocator&lt;other&gt; 12345template &lt;typename _Tp1&gt;struct rebind&#123; typedef allocator&lt;_Tp1&gt; other;&#125;; 因为在stl容器中，除了要给对象分配内存，往往还需要给存数据的节点分配内存，比如list，list节点存放数据和下一个节点，而rebind用来给这个节点分配内存的。 uninitialized的细节uninitialized系列的函数虽然不属于allocator，但提供了大规模元素初始值的设置，能大大提高拷贝的效率 1. uninitialized_copyuninitialized_copy 会把 [first, last)上的内容复制到以result为起始处的空间，返回复制结束的位置由于实际代码嵌套层数太多而且还有各种type_traits的处理，这里写伪代码供参考： 123456789101112131415161718192021222324252627282930313233343536ForwardIter uninitialized_copy(InputIter first, InputIter last, ForwardIter result)&#123; if (is_trivially_copy_assignable(result))&#123; /// 根据result来判断对象的构造函数是否无关紧要(可以理解为是否为POD) if (is_pointer_iterator())&#123; /// 指针版本，实际通过偏特化来实现 std::memmove(result, first, n * sizeof(Up)); /// memmove能够保证源串在被覆盖之前将重叠区域的字节拷贝到目标区域中，比memcpy更安全 &#125; else&#123; /// 迭代器版本 if (is_random_access_iterator_tag())&#123; /// 可以看到，为了性能，stl偏特化了随机访问迭代器版本 for (auto n = last - first; n &gt; 0; --n, ++first, ++result) &#123; *result = *first; &#125; return result; &#125; else&#123; for (; first != last; ++first, ++result) /// 性能比random_access_iterator差，因为需要调用运算符重载函数 &#123; *result = *first; &#125; return result; &#125; &#125; &#125; else&#123; auto cur = result; try&#123; for (; first != last; ++first, ++cur)&#123; std::construct(&amp;*cur, *first); /// 使用了replacement new &#125; &#125; catch (...)&#123; /// commit or rollback 构造出所有元素，要么不构造出任何一个 for (; result != cur; --cur) std::destroy(&amp;*cur); /// 调用析构函数 &#125; return cur; &#125;&#125; 2. uninitialized_filluninitialized_fill 会在 [first, last) 区间内填充元素值value伪代码实现如下： 1234567891011121314151617181920212223void uninitialized_fill(ForwardIter first, ForwardIter last, const T&amp; value)&#123; if (is_trivially_copy_assignable(first))&#123; /// 根据first的类型判断构造函数是否无关紧要 if (is_random_access_iterator_tag())&#123; n = last - first; /// 类型萃取difference_type if is_pointer_iterator()&#123; std::memset(first, (unsigned char)value, (size_t)(n)); /// 如果迭代器是指针，直接调用memset &#125; else&#123; for (; n &gt; 0; --n, ++first)&#123; *first = value; &#125; &#125; &#125; else&#123; for (; first != last; ++first)&#123; *first = value; &#125; &#125; &#125; else&#123; ...... /// 省略，与uninitialized_copy的实现类似 &#125;&#125; 3. uninitialized_moveuninitialized_move 会把[first, last)上的内容移动到以result为起始处的空间，返回移动结束的位置由于实现上与uninitialized_copy基本一致，大部分内容省略 1234567891011121314151617ForwardIter uninitialized_move(InputIter first, InputIter last, ForwardIter result)&#123; if (is_trivially_copy_assignable(result))&#123; if (is_pointer_iterator())&#123; std::memmove(result, first, n * sizeof(Up)); &#125; else&#123; ...... *result = std::move(*first); ...... &#125; &#125; else&#123; ...... std::construct(&amp;*cur, std::move(*first)); /// 实际调用移动构造函数 ...... &#125;&#125; 内存池版本的allocator弃用1.std::alloc的原理参考：《stl源码剖析》原理图：当申请的内存较大时，直接通过new进行内存分配，当申请小块内存时，使用内存池管理。内存池通过16个数组进行管理，每个数组各自管理大小分别为 8， 16， 24，…128 bytes(8 的倍数)的小额区块，这些区块通过链表的方式链接起来 2.什么时候弃用的，为什么弃用弃用原因参考(官网)：https://gcc.gnu.org/onlinedocs/libstdc++/manual/memory.html#allocator.design_issues弃用版本(官网)：https://gcc.gnu.org/onlinedocs/libstdc++/manual/api.html#table.extension_allocators从gcc3.4版本开始默认使用__gnu_cxx::new_allocator，同时这个版本对分配器做了较大的改动，新增了如bitmap_allocator、mt_allocator等的分配器可是使用内存池的版本比直接使用new进行分配要有优势(减少内存碎片,提高效率)，但为什么GNU要废弃内存池版本呢？通过官网的解释是为了稳定、兼容。（原文：has the advantage of working correctly across a wide variety of hardware and operating systems, including large clusters）同时指出了内存池的缺点：由于内存的创建销毁顺序的不确定，在内存中加载和释放共享对象时可能有问题。（原文：order-of-destruction and order-of-creation for memory pools may be difficult to pin down with certainty, which may create problems when used with plugins or loading and unloading shared objects in memory） Gnu提供的allocator其他版本1.现有版本new_allocator：默认版本，使用new和delete管理malloc_allocator：使用malloc和delete管理debug_allocator：会申请相比于目标值稍大一些的内存，并用额外的内存存储size信息。在deallocate中用一个assert()来检查被存储的size信息和将要被释放的内存的size是否一致throw_allocator：具有内存跟踪和标记的功能__pool_alloc ：即上面的旧版本内存池分配器__mt_alloc ： 多线程内存池分配器bitmap_allocator：内存池的基础上用bitmap标记内存块的使用和释放 2.__mt_alloc的原理资料：https://gcc.gnu.org/onlinedocs/libstdc++/manual/mt_allocator.htmlmt_alloc分为多线程版本和单线程版本，遗憾的是多线程版本只给出了接口，并没有实现。但实现原理其实是在pool_allocator的基础上，从1维数组变成2维数组，第二维指向线程id。 123456789101112131415161718192021222324/// 多线程池版的内存池，数据结构class __pool&lt;true&gt; : public __pool_base&#123; /// 线程id节点，这些节点会组成一个链表，用于从真实线程id映射到内部线程id（1-4096） struct _Thread_record &#123; _Thread_record* _M_next; /// 下一个空闲线程id size_t _M_id; /// 内部使用的线程id，范围是1到4096 &#125;; union _Block_record&#123; _Block_record* _M_next; /// 下一个空闲节点 size_t _M_thread_id; /// 申请该内存的线程id &#125;; struct _Bin_record &#123; _Block_record** _M_first; /// 一维数组，idx为线程id，存free_list的头节点 _Block_address* _M_address; /// 实际内存块的地址 size_t* _M_free; /// 一维数组，idx为线程id，存空闲内存块计数 size_t* _M_used; /// 一维数组，idx为线程id，存使用内存块计数 __gthread_mutex_t* _M_mutex; /// 互斥锁,申请和释放内存小块时用 &#125;; _Bin_record* _M_bin; /// 一维数组，内存池按2的指数对小内存块进行管理，idx为2的指数 size_t _M_bin_size; ///bin的个数 _Thread_record* _M_thread_freelist; /// 线程id的列表&#125;; 3.bitmap_allocator的原理资料：https://gcc.gnu.org/onlinedocs/libstdc++/manual/bitmap_allocator.html网友分析：https://www.jianshu.com/p/425ab2e81b59","categories":[{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"没有登录认证下解决文件冲突方案","slug":"pythonOther/fileConflict","date":"2021-10-08T21:37:29.000Z","updated":"2021-10-08T21:37:29.000Z","comments":true,"path":"2021/10/08/pythonOther/fileConflict/","link":"","permalink":"https://liji53.github.io/2021/10/08/pythonOther/fileConflict/","excerpt":"","text":"web、后台解决文件冲突需求背景背景是之前给团队做了几个提升软件质量、提升工作效率的工具，这些工具需要通过web来修改后台程序的配置，但随着使用的人越来越多，并发的问题也越来越突出，今天我们主要解决在没有登录认证的情况下，多个用户同时操作文件冲突的问题。 寻找解决方法多人同时操作文件，如何保证文件的并发控制，拿到这个问题，我们首先想到了以下几种解决方向： 通知的方式：简单来说就是让其他人知道现在有人正在修改文件，请不要修改文件，并及时刷新页面 冲突的方式：修改文件并提交时，判断文件的修改时间，如果读配置的时间在修改时间之后，则不允许修改 文件锁的方式：类似svn提交代码的操作，在修改文件之前先对文件加锁，修改完成之后再解锁，保证原子性 经过技术评估，方案2最简单，方案1和方案3都需要花点精力。但从用户角度来说，方案3最好，因此最终选择3。再回到技术上，要实现方案3，需要考虑以下几个技术要点： 服务端需要知道是哪个client在修改配置文件； 什么情况下加锁，释放锁(切换文件的读写模式、切换到其他文件、关闭刷新网页)； 异常情况下如何保证锁释放（断网、浏览器奔溃、加了文件锁但不在电脑前了） 方案设计上面的几个技术要点，解决如下： 虽然没有用户体系，但要识别客户端，可以通过cookie的方案来解决，client随机生成id，server根据client id来记录文件的锁定情况 正常情况下，切换文件模式、关闭刷新网页 这些自然靠js自己判断 异常情况下，我们可以参考保活机制来实现自动解锁；页面长时间不操作，则可以通过js判断 时序图如下： 代码实现1.识别客户端由于我们不需要鉴权认证，仅仅只要能区别客户端用户就行，因此cookie可以客户端自己生成，只需要确保唯一性。关键代码如下(作为C++开发，写前端的代码，大家将就下): 12345678910111213141516171819// 查询浏览器本地cookiefunction get_local_cookie()&#123; cook_list = document.cookie.split(&#x27;;&#x27;) for (var i = 0; i &lt; cook_list.length; i++)&#123; var arr = cook_list[i].split(&#x27;=&#x27;) if (arr[0] == &#x27;name&#x27; &amp;&amp; arr[1].substring(0, 9) == &#x27;autotest_&#x27;)&#123; return arr[1] &#125; &#125; return &#x27;&#x27;&#125;// 获取cookie，没有则生成cookie，有则获取当前cookieif (get_cookie() == &#x27;&#x27;)&#123; url = window.location.href + &#x27;cgi-bin/login.cgi&#x27; url += &quot;?name=autotest_&quot; + Math.round(Math.random()*10000) + Date.parse(new Date()) var request = new XMLHttpRequest(); request.open(&quot;GET&quot;, url, true); request.send(null);&#125; 其实没必要通过服务器返回set-cookie，js可以直接生成存储cookie。后端代码login.cgi： 123456789101112131415161718&#x27;&#x27;&#x27;http协议交互格式：get请求：http://192.168.0.1:8088/cgi-bin/login.cgi?name=(autotest_random+timestamp)response header:&#x27;Set-Cookie&#x27;: name=autotest_random+timestamp&#x27;&#x27;&#x27;def create_cookie(): # 获取数据 form = cgi.FieldStorage() site_name = form.getvalue(&#x27;name&#x27;) # Path 需要设置为/ 否则js无法获取 return &#x27;Set-Cookie: name=%s; Path=/&#x27; % site_nameprint (&#x27;Content-Type: text/html&#x27;)print (create_cookie())print (&#x27;HTTPOnly: false&#x27;)print () 2.保活机制+页面活动检测保活是为了在断网、网页异常的异常情况下，后台能够检测到client异常，并自动进行解锁。 这里js直接用setInterval，如果页面非活动状态会有问题 1234567891011121314151617181920// 后台启动定时器，发送保活包，如果长时间未保活，后台自动解锁myWorker = new Worker(&quot;js/keeplive.js&quot;);myWorker.postMessage(_get_url(&#x27;keeplive&#x27;));// 检查页面是否有人操作，长时间无人操作，则进行文件解锁function eventFunc()&#123; myWorker.postMessage(&quot;init&quot;);&#125;var body = document.querySelector(&quot;html&quot;);body.addEventListener(&quot;click&quot;, eventFunc);body.addEventListener(&quot;keydown&quot;, eventFunc);body.addEventListener(&quot;mousemove&quot;, eventFunc);body.addEventListener(&quot;mousewheel&quot;, eventFunc);myWorker.onmessage = function(e) &#123; is_timeout = e.data if (is_timeout)&#123; cgiHttp(&#x27;releaseLock&#x27;) alert(&quot;长时间未操作，页面强制刷新！&quot;) location.reload() &#125;&#125; keeplive.js 主要用来发保活包，以及判断页面长时间未操作，代码如下： 1234567891011121314151617181920212223242526var url = &#x27;&#x27;var init = 0var interval = 30 * 1000 // 保活发送间隔30svar pageTimeout = 20 * 60 * 1000 // 页面超时20分钟var is_timeout = falseonmessage = function(e) &#123; if (e.data == &#x27;init&#x27;)&#123; init = 0 &#125; else&#123; url = e.data &#125;&#125;setInterval(function()&#123; if (url == &#x27;&#x27; || is_timeout == true)&#123; return &#125; var request = new XMLHttpRequest(); request.open(&quot;GET&quot;, url, true); request.send(null); init += 1 if (init &gt;= pageTimeout/interval)&#123; postMessage(true); /// 通知主线程刷新页面 is_timeout = true &#125;&#125;, interval); keeplive.cgi 是后台用来接收保活包的，并把包转发给管道，由喂狗程序去判断是否异常并解锁 1234567891011121314151617181920&#x27;&#x27;&#x27;http协议交互格式：get请求：http://10.20.147.33:8088/cgi-bin/keeplive.cgi?cook=autotest_***response:&#x27;&#x27;&#x27;# todo 管道没有加锁保护，并发存在问题def _feed_dog(cookie_name): pipe_name = commVariable.pipe_name + &#x27;feedDog&#x27; if not os.path.exists(pipe_name): os.mkfifo(pipe_name) pipe_fd = os.open(pipe_name, os.O_WRONLY) os.write(pipe_fd, cookie_name.encode())form = cgi.FieldStorage()cookie = form.getvalue(&#x27;cook&#x27;)_feed_dog(cookie)print (&#x27;Content-Type: text/html&#x27;)print () 喂狗程序代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576g_lock_times = 3*60 # 3分钟lock_manager = &#x27;/tmp/filelock_manager&#x27;pipe_name = &quot;/tmp/pipefeedDog&quot;g_mutex = threading.Lock()g_file_lock_variable = &#123;&#125;# 更新内存中文件锁的时间戳def update_lock_timestamp(cookie): g_mutex.acquire() for system in g_file_lock_variable: for business in g_file_lock_variable[system]: if cookie == g_file_lock_variable[system][business][0]: g_file_lock_variable[system][business][1] = int(time.time()) g_mutex.release()# 从文件中更新到内存中def _update_lock_from_file(data): # 删除文件锁已经不存在的 for system in list(g_file_lock_variable.keys()): if not data.__contains__(system): g_file_lock_variable.pop(system) continue for business in list(g_file_lock_variable[system].keys()): if not data[system].__contains__(business): g_file_lock_variable[system].pop(business) # 更新新增的文件锁 for system in data: for business in data[system]: if not g_file_lock_variable.__contains__(system): g_file_lock_variable[system] = &#123;business: [data[system][business], int(time.time())]&#125; continue if not g_file_lock_variable[system].__contains__(business): g_file_lock_variable[system][business] = [data[system][business], int(time.time())]# 删除超时的文件锁def _delete_timeout_lock(): isChange = False for system in g_file_lock_variable: for business in list(g_file_lock_variable[system].keys()): # 超时，删除该文件锁 if (int(time.time()) - g_file_lock_variable[system][business][1]) &gt;= g_lock_times: g_file_lock_variable[system].pop(business) isChange = True return isChange# 把内存中的文件锁状态跟新到文件中def update_file_lock(): if not os.path.exists(lock_manager): return with open(lock_manager, &#x27;r+&#x27;, encoding=&quot;utf-8&quot;) as fd: try: data = json.load(fd) except: data = &#123;&#125; g_mutex.acquire() _update_lock_from_file(data) isChange = _delete_timeout_lock() if isChange: fd.seek(0) fd.truncate() content = &#123;s: &#123;b: g_file_lock_variable[s][0] for b in g_file_lock_variable[s]&#125; for s in g_file_lock_variable&#125; fd.write(json.dumps(content)) g_mutex.release()def check_timeout(): update_file_lock() threading.Timer(int(g_lock_times/3), check_timeout).start()# 启动检查是否文件锁是否过期的定时器check_timeout()# 从管道中读cookie,更新文件锁的最新情况if not os.path.exists(pipe_name): os.mkfifo(pipe_name)while True: pipe_fd = os.open(pipe_name, os.O_RDONLY) # 阻塞 cook = os.read(pipe_fd, 100) update_lock_timestamp(cook) os.close(pipe_fd) 3.关闭刷新页面，解锁靠js判断页面关闭、刷新时发送请求 12345678910111213141516// 关闭页面时，进行文件解锁window.onbeforeunload = function()&#123; url = window.location.href + &#x27;cgi-bin/releaseLock.cgi&#x27; const formData = new FormData(); formData.append(&quot;system&quot;, g_system) formData.append(&quot;subSystem&quot;, g_sub_system) formData.append(&quot;business&quot;, g_business) formData.append(&quot;fileName&quot;, g_fileName) formData.append(&quot;cook&quot;, g_cookie) window.navigator.sendBeacon(url, formData)&#125;// 刷新页面时，则强制解锁该client的所有文件锁if (performance.navigation.type == 1)&#123; cgiHttp(&#x27;releaseLock&#x27;) console.log(g_business)&#125; 4.切换模式配置的编辑使用了jsonEditor，只需要监听mode的切换即可 1234567891011121314151617181920var jsonOptions = &#123; mode: &#x27;view&#x27;, modes: [&#x27;view&#x27;, &#x27;code&#x27;, &#x27;tree&#x27;], onError: function(err) &#123; alert(err.toString()); &#125;, onModeChange: function(newMode,oldMode)&#123; if ((newMode == &#x27;code&#x27; || newMode == &#x27;tree&#x27;) &amp;&amp; oldMode == &#x27;view&#x27;)&#123; cgiHttp(&#x27;getLock&#x27;) if (g_response.hasOwnProperty(&#x27;success&#x27;) &amp;&amp; g_response[&#x27;success&#x27;] != true)&#123; alert(&#x27;本文件已经被锁定，请稍后再试&#x27;) g_jsonEditor.setMode(&#x27;view&#x27;) &#125; &#125; else if (newMode == &#x27;view&#x27; &amp;&amp; ((oldMode == &#x27;code&#x27; || oldMode == &#x27;tree&#x27;)))&#123; cgiHttp(&#x27;releaseLock&#x27;) console.log(g_response) &#125; &#125;&#125;; 最终效果","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"cryptography-公钥密码","slug":"cryptograghy/cryptography-publicKey","date":"2021-09-20T18:40:41.000Z","updated":"2021-09-20T18:40:41.000Z","comments":true,"path":"2021/09/20/cryptograghy/cryptography-publicKey/","link":"","permalink":"https://liji53.github.io/2021/09/20/cryptograghy/cryptography-publicKey/","excerpt":"","text":"公钥密码公钥密码又叫非对称密码，在加密、数字签名、密钥交换的场景中，经常用到公钥密码，但这三个问题的解决方案不一定非要用公钥密码来解决。比方DSA用于数字签名，DH用于密钥交换，因此在概念上，我们要对公钥密码以及常见的应用场景做区分。 DH(Diffie-Hellman)算法在密钥交换问题中，我们可以让加密通信的双方交换一些信息，然后根据这些信息，双方可以各自生成相同的密钥，但其他人无法生成相同的密钥。DH并不能算是公钥密码（仅个人理解：因为双方都有各自的私钥，无法用于加密解密），仅能用于密钥交换这种场景 离散对数离散对数是在公钥密码系统中非常的重要，在DH算法和后面的RSA算法都是基于离散对数问题才能实现。对于一个整数n、底数G（原根）、质数P，可以找到唯一的指数a, 则指数a称为离散对数。它背后的数学原理，涉及到欧拉公式、群的概念等等，就不介绍了，但我们至少要知道下面这个公式。n = G^a mod P按照这个公式，我们可以轻松计算出n，但是反过来，仅知道n、G、P却很难计算出a，这就是安全性的基础。 DH密钥交换步骤DH密钥交换的过程如图所示：看下第⑤步骤的公式A计算的密钥 = (G^B mod P)^A mod PB计算的密钥 = (G^A mod P)^B mod P其实最终可以表示成共享密钥 = G^(A*B) mod P DHE算法DH算法可以根据一端的私钥是否是静态的，以此分成2种实现： static DH算法，已经被废弃 DHE算法 static DH算法一般是服务端的私钥固定，客户端的私钥动态生成，但这样做，攻击者可以根据历史的数据暴力破解出服务器的私钥，因此这种算法已经废弃。而DHE算法指的是双方的私钥都是动态生成，这样每次会话的过程都是独立的，攻击者破解难度就很大了。现实中，tls的密钥交换算法ECDHE 其实就是 DHE + ECC。 RSARSA是目前主流的公钥算法，当前RSA的密钥长度一般在1024位以上。 加解密过程RSA的加密过程可以用下面的公式来表示：密文 = 明文^E mod NRSA的解密过程可以用下面的公式来表示：明文 = 密文^D mod N其中E和N的组合就是公钥，D就是私钥。想要通过E和N来破解密文，这就回到了离散对数问题，这是非常困难的。 密钥对的生成E和D并不是随意的，两者必须有一种公式关系。否则上面的加解密机制是无法实现的。密钥对的生成步骤如下： 随机生成2个很大的质数p、q(至少512位以上) 生成N = p*q 生成L，L为p-1 和q-1的最小公倍数 （L只在生成过程中出现） 随机生成E，E要同时符合 {1&lt;E&lt;L，E和L的最大公约数必须为1} 生成D，D要同时符合{1&lt;E&lt;L, E*D mod L = 1} 如图所示： RSA安全的基础除了需要通过离散对数来保证RSA的安全，还需要基于以下1个数学难题来保证RSA的安全： 质因数分解困难。由于N是公开，如果攻击者能通过N来计算出p、q，那么RSA就被破解了，幸好目前还没有有效的算法能对大整数进行质因数分解(一旦有了，RSA也就不能用了) 那能不能通过E和D的关系来计算出D呢？E * D mod L = 1要计算出D必须知道L，而L又通过p、q计算出来的，因此无法通过E来计算D RSA的缺点RSA虽然是用的最广泛的公钥算法之一，但RSA也存在缺点： 生成密钥麻烦，在密钥对的生成过程中，需要随机找2个大质数，因此难以一次会话一次加密 （tls的密钥交换算法不首选RSA的原因之一） 密钥长度问题，一般需要1024位以上，使得运算代价很高（在相同安全强度下，基于ECC的密钥长度比RSA要短很多） ECCECC相比RSA，可以用较短的密钥达到相同的安全程度，同时具有处理速度更快、传输带宽更少的优点。 ECC加密过程ECC的数学原理比RSA要复杂得多，涉及到椭圆曲线方程、阿贝尔群、有限域椭圆曲线、曲线点的阶等等一系列的概念与数学原理。这里好复杂，参考资料（可以先零散的看些中文文章，对基础概念有些了解之后，再看这篇英文，把知识点串联起来）：https://cryptobook.nakov.com/asymmetric-key-ciphers/elliptic-curve-cryptography-ecc密钥对生成过程如下： 选择一种有限域椭圆曲线Ep，比方secp256k1的曲线为y^2 = x^3 + 7 (mod p) 其中p为一个很大的整数. 选一个基点G（对于secp256k1，G点可以任意曲线点，因为cofactor=1） 随机选择一个整数k， 这个k就是私钥，这里逆推k是很困难的。 计算出公钥，P = k*G ，其中P也是曲线上的一个点。 加密的过程如下： 将明文编码为M(怎么编码的我还不清楚)，M也为曲线上一点，并选择一个随机数r，要求r &lt; n（n为G的阶） 计算出2段密文Cipher1 和Cipher2, 其实这两个密文，还是曲线上的2个点。 Cipher1 = M + rPCipher2 = rG 解密过程如下： 明文编码M = Cipher1−k*Cipher2 = M + rQ − krG = M + rkG − krG = M 将M解码即可 数字签名在对称密码中我们讲到了消息验证码这一种用于验证消息完整性的技术了，现在我们来了解下另一种可以验证消息完整性的技术，除了识别篡改，还能防止否认。整体结构如图所示： 数字签名的校验过程数字签名分为生成数字签名的过程以及验证数字签名的过程，一般对消息的散列值进行签名。如图所示：它的核心思想就是利用没有私钥的人无法生成该私钥所生成的密文。 对数字签名的攻击数字签名虽然能识别数据的完整性，但却无法认证数据的所有人。 如果有人将签名、公钥 替换成自己的签名、公钥，不管他怎么修改数据，都是合法的。这种攻击手段也叫中间人攻击。对于中间人攻击，需要证书来识别通信的对象是否合法。 利用RSA加解密公式的一致性，比方有人诱导你帮他签名一段数据，你用私钥签名其实是在帮他解密了，过程如下：签名 = 附件数据^D mod N （你以为这只是一段随意的数据） = 密文^D mod N （其实这是密文） = 解密后的消息 （你看到签名之后是一段乱码，以为签名成功了，其实这是混合加密过程中的对称密钥）要防止这种情况发生，首先确保不要随便用自己的私钥给不清楚的消息签名，其次对于不同的场景要使用不同的密钥对，比方密钥交换和数字签名不要用一个密钥对。 参考资料书籍：《图解密码技术》网上资料：https://www.cnblogs.com/Kalafinaian/p/7392505.htmlhttps://cryptobook.nakov.com/asymmetric-key-ciphers/elliptic-curve-cryptography-ecc","categories":[{"name":"密码学","slug":"密码学","permalink":"https://liji53.github.io/categories/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[]},{"title":"cryptography-对称密码","slug":"cryptograghy/cryptography-cipher","date":"2021-09-20T18:40:11.000Z","updated":"2021-09-20T18:40:11.000Z","comments":true,"path":"2021/09/20/cryptograghy/cryptography-cipher/","link":"","permalink":"https://liji53.github.io/2021/09/20/cryptograghy/cryptography-cipher/","excerpt":"","text":"对称密码(共享密码)对称加密算法简单来说，就是把数据尽可能的打乱，并能把打乱的数据还原。 DESDES是以每64位为单位对明文进行加密的对称加密算法。它的密钥长度为56位(不包括8位校验码)。 Feistel结构Feistel网络是一种加密设计结构，而非加密算法。很多对称加密算法都采用这种设计结构。如下图所示(三轮)：每一轮解密的过程：这2张图中长得像网一样的结构就叫做Feistel网络。对于Feistel网络，我们需要知道： 无论轮函数怎样实现（即使论函数不可逆),只要子密钥正确，就可以解密，因此轮函数可以设计的无比复杂。 Feistel网络的轮数，可以任意增加，无论经过多少轮，都能解密 DES算法DES是16轮的Feistel型加密算法。在进行16轮加密之前，DES会先对明文做一个固定的初始置换IP（其实这个置换对安全没有任何用处），等到16轮加密完成之后还会做一次逆置换。所谓的置换其实就是按照固定的规则把第N位的数据放到其他位置，把数据打乱而已。下面我们看下DES的轮函数流程：这里扩展置换就是把32位的数据按照固定的位置置换表扩展成48位。S盒变换根据固定的算法，把48位的数据变成32位，S盒也是保证安全的关键。P盒变换就是根据另一张固定的位置置换表(做法跟第一步的初始置换IP类似)把数据打乱。可以看到每一个步骤都需要按照固定的格式进行转化，限于篇幅，如果对它感兴趣，可以看《密码学原理与实践》。子密码的生成过程，可以参考博客：https://www.cnblogs.com/TheFutureIsNow/p/10794182.html 3DESDES已经可以被暴力破解了，而3DES就是用于增加DES的强度，其实就是对DES重复进行3次。如图所示：3DES的密钥长度为3*56=168位，其中中间的步骤不是加密而是解密这是为了兼容普通的DES。3DES的主要问题就是运行速度并不快，安全性也不如AES。 AESAES是目前的主流对称加密算法，有128、192、256三种密钥长度。 AES算法AES并没有使用Feistel结构，但也要经过多轮加密，加密的轮数与密钥的长度相关(128位密钥需要10轮)。AES也是分组加密，每组128位，比起DES，加密、解密的过程中可以按字节、行、列为单位进行并行计算。每一轮的加密步骤如图所示：其中SubBytes、ShiftRows、MixColumns的算法实现，自行参考《密码学原理与实践》 AES性能AES加解密的速度与数据长度线性相关。从2008年开始，X86架构中开始支持AES-NI指令集，这种指令集能帮助AES加解密加速。通过命令grep aes /proc/cpuinfo可以查看cpu是否支持。如果cpu支持，自然首选AES。而在一些嵌入式领域中，如果不支持AES硬解，可以选择ChaCha20 算法。这个算法的性能比AES更加强大。 分组密码的模式分组密码的模式指的是将明文分组之后，如果明文长度超过分组长度，需要对分组进行迭代加密，从而使整个明文都加密。分组密码的模式并不是某一种加密算法特有的，是分组密文的迭代过程。 ECB模式这种模式将明文分组之后各自加密成密文分组。如图所示：如果存在多个相同的明文分组，会导致生成相同的密文分组，因此ECB存在风险，实际中不要使用 CBC模式CBC(Cipher Block Chaining)模式中，明文分组需要与前一个密文分组进行异或运算，如图所示：CBC模式的主要问题是加密的过程必须串行，无法并行，因此在效率上比较差。 CFB模式CFB(Cipher FeedBack)模式中，会对前一个密文分组进行加密，如图所示：CFB可以用重放攻击，所谓的重放攻击就是利用之前的数据再次发给接收人，从而欺骗接收者。如图所示：这里成功的篡改了数据，因此CFB模式也不能使用。 CTR模式CTR(CounTeR)模式通过对累加计数器加密来生成密钥流。如图所示：由于计数器的加密过程、明文的异或计算都可以并行，因此这种模式是实现中常用的模式(GCM模式中的C指的就是这个模式)最常见的GCM模式，我们在最后进行补充。 消息认证码消息认证码(message authentication code)用于确认数据的完整性,简称MAC。 散列函数介绍MAC之前，需要知道散列函数的概念。散列函数能将任意长度单向计算出一个固定长度的值。如图所示：所谓的单向指的是无法通过计算出的值反推出原文。一般我们把计算出来的值称为摘要、指纹而散列函数一般也叫哈希函数，常见的散列算法有MD5、SHA-1、SHA-256、SHA-384等。其中MD5、SHA-1 已经被破解，这里的破解指的是已经找到2个不同的数据却具有相同的散列值。散列函数是校验数据完整性（一致性）的核心，消息认证码、数字签名、认证等都必须依赖散列函数。校验的过程如下图所示： 对散列函数的攻击对散列函数的攻击，这里我们主要是了解下生日攻击。这种攻击方式并不是通过寻找特定散列值的数据，而是找两个散列值相同的2条消息，这是对单向散列函数的“强抗碰撞性”的攻击。生日攻击的破解难度比暴力破解的难度要小很多。举个暴力破解的例子：你去买房，通过房产局跟房东签订了电子合同，合同里写明了100w的房款，并且双方保留一份合同的散列值。你是一名黑客，想要把合同的100w改成10w，于是你不停的修改电子合同，不停的计算散列值，期望找到一个相同的散列值，这样就能替换原合同了。生日攻击的例子：你同样去买房，但这次你不通过房产局签合同，你直接跟房东签合同，你拿出事先准备好的电子合同，并双方保留散列值。晚上你偷偷摸摸入侵电脑把电子合同换成另一份事先准备好的具有相同散列值的合同。于是房东跟你毁约了，并赔偿了你一笔违约金。。。 消息认证码的校验过程仅靠数据摘要对数据进行验证在需要通信的场景中是不够的。攻击者完全可以同时篡改你的数据+指纹。我们先看下消息认证码的过程：它的思想其实就是利用共享密钥是只有你我两人知道这个一个特征实现的。注意这里共享密钥并不是用于加密数据的，只是跟消息进行组合。 HMAC的实现消息认证码的实现可以有多种，我们大概看下HMAC的实现：如果仅通过HMAC机制仍然存在漏洞，攻击者可以重放攻击：因此在通信的过程中，消息里常常带一个随机数nonce字段，每次通信nonce都会发生变化，于是就无法重放攻击了。 GCM模式最后我们再来介绍下GCM模式，前面介绍的CBC、CFB、CTR等模式只能提供加密的功能，但不具备校验数据完整性的功能。 工作原理GCM模式同时具备了2种功能（AEAD），简单来说就是 CTR模式 + GMAC机制（另一种MAC）它的实现过程（图片来自：https://zhuanlan.zhihu.com/p/376692295）： 参考资料书籍：《图解密码技术》《密码学原理与实践》（第二版）网上资料：https://www.cnblogs.com/TheFutureIsNow/p/10794182.htmlhttps://zhuanlan.zhihu.com/p/376692295","categories":[{"name":"密码学","slug":"密码学","permalink":"https://liji53.github.io/categories/%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"tags":[]},{"title":"探索difflib(初探匹配算法)","slug":"pythonOther/difflibParse","date":"2021-09-10T08:04:57.000Z","updated":"2021-09-10T08:04:57.000Z","comments":true,"path":"2021/09/10/pythonOther/difflibParse/","link":"","permalink":"https://liji53.github.io/2021/09/10/pythonOther/difflibParse/","excerpt":"","text":"让difflib展示更智能继上一篇文章pytest测试报告自定义比较内容，我们修改了pytest-html的源码，用difflib的html比对方式生成了新的测试报告。但用了之后发现，difflib的行比对效果极差，如果存在几处(测了下3个字符以上)不一致的地方就整行变红色，而不是只显示差异字符。如下图： 我想要的效果是beyond compare这种(只把差异字符标红，而并不是整行变红) 网上百度difflib的实现原理，居然完全空白，于是只能自己看源代码分析原因。 首先我们知道difflib有3种差异模式：”Added “ ; “Changed”; “Deleted”。 现在我们要找为什么我们期望的”Changed”会变成”Added”。 difflib源码分析1. 生成html(table)的源码1234567def make_table(self,fromlines,tolines,fromdesc=&#x27;&#x27;,todesc=&#x27;&#x27;,context=False,numlines=5): # 省略...... return table.replace(&#x27;\\0+&#x27;,&#x27;&lt;span class=&quot;diff_add&quot;&gt;&#x27;). \\ replace(&#x27;\\0-&#x27;,&#x27;&lt;span class=&quot;diff_sub&quot;&gt;&#x27;). \\ replace(&#x27;\\0^&#x27;,&#x27;&lt;span class=&quot;diff_chg&quot;&gt;&#x27;). \\ replace(&#x27;\\1&#x27;,&#x27;&lt;/span&gt;&#x27;). \\ replace(&#x27;\\t&#x27;,&#x27;&amp;nbsp;&#x27;) 2. 匹配度导致的整行变红下面就定位到_fancy_replace 这个函数，这个函数作用是把原字符串替换成标注差异的字符串 1234567891011121314151617181920&quot;&quot;&quot; Example:&gt;&gt;&gt; d = Differ()&gt;&gt;&gt; results = d._fancy_replace([&#x27;abcDefghiJkl\\n&#x27;], 0, 1,... [&#x27;abcdefGhijkl\\n&#x27;], 0, 1)&gt;&gt;&gt; print(&#x27;&#x27;.join(results), end=&quot;&quot;)- abcDefghiJkl? ^ ^ ^+ abcdefGhijkl? ^ ^ ^&quot;&quot;&quot;def _fancy_replace(self, a, alo, ahi, b, blo, bhi): best_ratio, cutoff = 0.74, 0.75 cruncher = SequenceMatcher(self.charjunk) # 省略...... if cruncher.real_quick_ratio() &gt; best_ratio and \\ cruncher.quick_ratio() &gt; best_ratio and \\ cruncher.ratio() &gt; best_ratio: best_ratio, best_i, best_j = cruncher.ratio(), i, j # 省略...... 这里的逻辑是匹配度要达到0.74，就能展示字符差异，而不是整行差异 3. 匹配度与预期不符12345# Where T is the total number of elements in both sequences, and# M is the number of matches, this is 2.0*M / T.def ratio(self): matches = sum(triple[-1] for triple in self.get_matching_blocks()) return _calculate_ratio(matches, len(self.a) + len(self.b)) 按照源码的注释，如果只有个别字符不一样，匹配度应该是很高的。在我自己的例子中，只有5个字符不一样，2个比对的字符串分别有250个字符，按照公式，匹配度应该有2*(250-5)/(250*2)=0.98，但实际却只有0.6多 4. 匹配的块少了这个函数会返回所有匹配的内容。Match(a=3, b=2, size=2)，表示左边字符串第3位开始，右边字符串第2位开始相同，相同字符个数为2个 1234567891011121314151617&quot;&quot;&quot;&gt;&gt;&gt; s = SequenceMatcher(None, &quot;abxcd&quot;, &quot;abcd&quot;)&gt;&gt;&gt; list(s.get_matching_blocks())[Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]&quot;&quot;&quot;def get_matching_blocks(self): # 省略...... while queue: alo, ahi, blo, bhi = queue.pop() i, j, k = x = self.find_longest_match(alo, ahi, blo, bhi) if k: # if k is 0, there was no matching block matching_blocks.append(x) if alo &lt; i and blo &lt; j: queue.append((alo, i, blo, j)) if i+k &lt; ahi and j+k &lt; bhi: queue.append((i+k, ahi, j+k, bhi)) matching_blocks.sort() 期望是所有匹配的子串都能找到返回，但实际却缺少了几个Match 5. 自动垃圾启发式计算惹的祸这个函数看字面意思是找最长的字串，但实际是有条件的。 123456789101112131415161718def find_longest_match(self, alo=0, ahi=None, blo=0, bhi=None): # 省略...... for i in range(alo, ahi): # look at all instances of a[i] in b; note that because # b2j has no junk keys, the loop is skipped if a[i] is junk j2lenget = j2len.get newj2len = &#123;&#125; for j in b2j.get(a[i], nothing): # a[i] matches b[j] if j &lt; blo: continue if j &gt;= bhi: break k = newj2len[j] = j2lenget(j-1, 0) + 1 if k &gt; bestsize: besti, bestj, bestsize = i-k+1, j-k+1, k j2len = newj2len # 省略...... 这个函数里有一个关键变量b2j， 这个变量维护了字符串中频率很低的字符，以及坐标位置。这么做的目的是为了提高运行效率，毕竟如果要比较的字符串很大，每一个字符都比较很影响效率。因此通过比较个别“冷门”字符就能快速匹配。 自动垃圾启发式计算的定义， 引用官方原文： SequenceMatcher支持使用启发式计算来自动将特定序列项视为垃圾。 这种启发式计算会统计每个单独项在序列中出现的次数。 如果某一项（在第一项之后）的重复次数超过序列长度的 1% 并且序列长度至少有 200 项，该项会被标记为“热门”并被视为序列匹配中的垃圾。 这种启发式计算可以通过在创建SequenceMatcher时将 autojunk 参数设为 False 来关闭。 结论原因找到了，只要匹配的字符串长度超过200字符，就可能匹配度变低。比较遗憾的是HtmlDiff类并没有把autojunk参数暴露出来，因此还是要通过修改源码才行, 修改如下： 1234def _fancy_replace(self, a, alo, ahi, b, blo, bhi): best_ratio, cutoff = 0.74, 0.75 #cruncher = SequenceMatcher(self.charjunk) cruncher = SequenceMatcher(self.charjunk, autojunk=False) 注意：这么改，效率会变低 最后上个效果图：","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"pytest测试报告自定义比较内容","slug":"pythonOther/pytestHtml","date":"2021-09-09T08:48:22.000Z","updated":"2021-09-09T08:48:22.000Z","comments":true,"path":"2021/09/09/pythonOther/pytestHtml/","link":"","permalink":"https://liji53.github.io/2021/09/09/pythonOther/pytestHtml/","excerpt":"","text":"pytest-html自定义比较内容pytest通过assert进行断言，而断言产生的错误内容是python自带的错误解释。但这个错误内容长这样，是不是一脸懵。 我想要的效果是像beyond compare那样： 预备知识&amp;资料遇到问题，先从网上找资料，其中有几篇文章对了解pytest还是很有帮助的 资料： https://www.cnblogs.com/yoyoketang/p/9748718.html https://www.cnblogs.com/linuxchao/p/linuxchao-pytest-html.html https://www.cnblogs.com/yoyoketang/p/14108144.html 但这些文章，并不是我想要的，于是只能自己从pytest-html的源码入手，定制测试报告 定位pytest-html源码pytest-html的源码不多，还是很容易理解的，实现都在pytest_html/plugins.py文件中 1. 分析测试报告的html通过下图，可以看到我们要修改的测试报告的内容位于 2.定位源码通过找生成div(class=’log’)的代码，可以定位到以下代码，这部分的代码就是用来生成div标签的html 12345678910111213141516171819def _populate_html_log_div(self, log, report): if report.longrepr: # longreprtext is only filled out on failure by pytest # otherwise will be None. # Use full_text if longreprtext is None-ish # we added full_text elsewhere in this file. text = report.longreprtext or report.full_text if html_log_content is None: for line in text.splitlines(): separator = line.startswith(&quot;_ &quot; * 10) if separator: log.append(line[:80]) else: exception = line.startswith(&quot;E &quot;) if exception: log.append(html.span(raw(escape(line)), class_=&quot;error&quot;)) else: log.append(raw(escape(line))) log.append(html.br()) 生成目标html直接上代码， 这里用到了difflib，不要忘记import difflib 由于代码是通过Full diff来判断的，因此调用pytest的时候不要忘加-vv参数选项 123456789101112@staticmethoddef _my_diy_html_log_div(text): if text.find(&#x27;Full diff&#x27;) != -1: idx1 = text.find(&#x27;AssertionError: assert&#x27;) + len(&#x27;AssertionError: assert&#x27;) idx2 = text.find(&#x27;E At index&#x27;) compare_str = text[idx1:idx2] left = compare_str[:compare_str.find(&#x27;==&#x27;)].replace(&#x27;\\\\n&#x27;,&#x27;\\n&#x27;) right = compare_str[compare_str.find(&#x27;==&#x27;)+len(&#x27;==&#x27;):].replace(&#x27;\\\\n&#x27;,&#x27;\\n&#x27;) diff = difflib.HtmlDiff() diff_content = diff.make_file(left.splitlines(), right.splitlines()) return diff_content return None 调用者代码如下： 12345678910111213141516171819def _populate_html_log_div(self, log, report): if report.longrepr: text = report.longreprtext or report.full_text # add by liji html_log_content = self._my_diy_html_log_div(text) if html_log_content is None: for line in text.splitlines(): separator = line.startswith(&quot;_ &quot; * 10) if separator: log.append(line[:80]) else: exception = line.startswith(&quot;E &quot;) if exception: log.append(html.span(raw(escape(line)), class_=&quot;error&quot;)) else: log.append(raw(escape(line))) log.append(html.br()) else: log.append(raw(html_log_content)) 代码最后一句：log.append(raw(html_log_content))，必须要加raw，否则报告长这样 这是因为log.append(html)，字符串html会被转义，’&lt;’、’&gt;’、’&amp;’等会被转义 通过看py/_xmlgen.py 的源码，可以看到raw不会escape 123456def __object(self, obj): #self.write(obj) self.write(escape(unicode(obj)))def raw(self, obj): self.write(obj.uniobj) 最后效果展示 格式是difflib的html格式，大致满足要求了！","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"mysql-并发","slug":"database/mysql-lock","date":"2021-09-04T13:20:46.000Z","updated":"2021-09-04T13:20:46.000Z","comments":true,"path":"2021/09/04/database/mysql-lock/","link":"","permalink":"https://liji53.github.io/2021/09/04/database/mysql-lock/","excerpt":"","text":"mysql-并发对于MySql服务器来说，可能同时要处理多个事务。如果在处理多事务的时候，让事务排队进行这样对性能的影响非常大。如何让Mysql既有较好的隔离性，又有较好的性能，这就是MVCC和锁要做的事情。 隔离与MVCC1. 事务并发问题 脏写：一个事务修改了另一个未提交事务修改过的数据 脏读：一个事务读到了另一个未提交事务修改过的数据 不可重复读：一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值 幻读：一个事务先查询出一些记录，之后另一个事务又向表中插入一些记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来 如果按照问题的严重性来看：脏写 &gt; 脏读 &gt; 不可重复读 &gt; 幻读 2. 隔离级别对于上面的4种问题，SQL标准设立了4种隔离级别 隔离级别 脏读 不可重复读 幻读 READ UNCOMMITTED Possible Possible Possible READ COMMITTED Not Possible Possible Possible REPEATABLE READ Not Possible Not Possible Possible SERIALIZABLE Not Possible Not Possible Not Possible 这里没有脏写，是因为对于脏写来说，不管哪种隔离级别，都不允许发生。当然这只是SQL标准要求实现的，在实际各种数据库的实现中，4种隔离级别的支持程度是不一样的。如：oracle 只支持READ COMMITTED 和 SERIALIZABLE。而Mysql虽然支持4种隔离级别，但实现上却并不完全按照这个标准来的（REPEATABLE-READ能禁止幻读的产生）mysql中默认的隔离级别是REPEATABLE-READ。 3. 事务id和版本链在搞清楚隔离级别的实现之前，我们先了解下事务ID和版本链的概念。如果某个事务执行过程中对某个表执行了增、删、改操作，那么InnoDB 存储引擎就会给它分配一个独一无二的事务id（只有第一次增、删、改才分配）,事务ID是向上增加的。再来回看下数据/索引页的内容：roll_pointer指向的是改记录对应的undo log，同时把历史undo log链接起来：这个就是版本链的结构，其中头节点表示当前记录的最新值。 4. 隔离级别的实现对于READ UNCOMMITTED来说，由于可以读未提交事务的记录，因此对于该隔离级别只需要读最新版本的记录即可。对于SERIALIZABLE来说，采用的是加锁的方式来实现的（等会就讲）而REPEATABLE READ和READ COMMITTED 都需要保证读到的是已经提交事务的记录，因此它们通过版本链来实现(判断版本链中哪个版本是当前事务可见的)。他们的区别就是： READ COMMITTED在每次读数据之前都会生成一个ReadView REPEATABLE READ只有在第一次读取数据的时候才生成一个ReadView，之后的查询复用这个ReadView 5. ReadViewReadView简单来说就是记录了当前有哪些活跃的事务，这样在遍历版本链的时候，就能判断该版本是否已经提交。ReadView的数据格式如下： 123456struct ReadView&#123; int m_ids[n_max_ids]; // 当前活跃读写事务的事务id列表 int min_trx_id; // 当前系统中活跃读写事务中最小的事务id int max_trx_id; // 当前系统中应该分配给下一个事务的id 值 int creator_trx_id; // 表示生成该ReadView 的事务的事务id,如果是只读事务则为0&#125;; 查找已经提交事务的记录过程如下(伪代码)： 123456789101112query(ReadView, record): if record.trx_id == ReadView.creator_trx_id: # 正在访问自己修改的记录，返回这条记录 return record if record.trx_id &lt; ReadView.min_trx_id: # 这条记录在生成ReadView时已经提交了 return record if record.trx_id &gt;= ReadView.max_trx_id: # 有新的事务开启，需要递归查找下一个版本 query(ReadView, record.roll_pointer) else: if record.trx_id in ReadView.m_ids: # 这条记录的事务仍然活跃，查找下一个版本 query(ReadView, record.roll_pointer) else: # 说明这条记录已经提交 return record 6. MVCC(Multi-Version Concurrency Control)所谓的MVCC指的就是REPEATABLE READ和READ COMMITTED这两种隔离级别访问版本链的过程。现在再回头看下REPEATABLE READ和READ COMMITTED的过程区别： 12345678910111213Read Committed隔离级别： 事务1 事务2 update row = X select row(生成ReadView) committed select row(并不会返回X，因为ReadView中事务2是活跃的) Repeatable Read隔离级别： 事务1 事务2 update row = X select row(生成ReadView) committed select row(重新生成ReadView，事务2不活跃，返回X) 7.purge的过程我们已经知道ReadView和MVCC是干什么的了，现在我们来看下purge的过程。purge用于完成最终的delete和update操作，由于MVCC的存在，事务在提交之后，并不能立即把undo log删除，同时像delete操作也只是做了一个标记，并不是真正删除。而这些脏活累活就是由purge来完成的。在事务提交之后，如果存在update和delete的操作，则会根据事务的提交顺序，生成history链表。如图所示：purge线程会先从history list中找undo log，再从undo log所在的页中找undo log是否在被使用，这样可以避免大量的随机读写。如果一个undo log页中存在仍然在使用的undo log，则表示整个页都不能回收。怎么判断是否仍然在使用呢？通过找到最老的ReadView即可，最老的ReadView保存了那个时刻的活跃事务的快照，这些事务即使提交了，也不能回收。 锁在开发中难免会遇到并发的处理，常见的并发处理参考os-并发，但在InnoDB中mutex、rwlock这种锁称之为latch，并不是我们这次要讨论的对象。它们的区别如下： 1. 多粒度锁首先介绍两个基本的锁：共享锁(S lock)：允许事务读一行数据独占锁(X lock)：允许事务删除/更新 一行数据（插入通过隐式锁实现）这一对锁的语义跟读写锁一致。因此不再介绍它们的互斥情况，但独占锁和共享锁是不存在饥饿现象的，同时存在要加独占锁和共享锁的情况下，总是独占锁优先。 刚才说的锁针对的是一行记录，称为行锁，但事务也可以对表进行加锁，这种就是表锁。表锁也分为共享锁和独占锁。但表锁和行锁该如何配合呢，比方说一条记录已经加了X锁了，这时候要对这张表加S锁，如何知道这种表的其中某些记录有加X锁呢？通过意向锁(Intention Lock)来实现，简单来说就是在加行S锁之前，先对这张表加IS锁，这样当需要对表加X锁时，就能知道这张表是否存在行S锁他们的兼容情况如下： 兼容性 X IX S IS X 不兼容 不兼容 不兼容 不兼容 IX 不兼容 兼容 不兼容 兼容 S 不兼容 不兼容 兼容 兼容 IS 不兼容 兼容 兼容 兼容 虽然InnoDB有表锁的存在，单实际上表锁却是server层实现的东西，如对表进行Alter 、Drop等DDL操作。 2. Gap锁和Next-key锁在InnoDB中有3种行锁： Record lock：对一行记录加锁 Gap lock：间隙锁，能锁定一个范围，单不包含记录本身 Next-key lock：前面2种锁功能相加，Gap lock + Record lock 前面我们说过REPEATABLE READ这种隔离级别是可以解决幻读问题的，解决幻读的办法就是使用gap锁。但由于gap锁定的数据并不存在，因此对于gap锁来说，独占锁和共享锁是没有区别的，只要加锁了，如果其他事务要在这个范围内插入记录，就会阻塞。 3. 锁的结构如果每条记录都要生成对应的一个锁结构，对于要锁定大量数据的InnoDB来说，就又容易照成空间浪费。因此它的如图所示：其中”一堆比特位“表示的就是页内哪条数据被锁定了（一个比特对应一条记录）。而对于行锁来说，图中n_bit表示的是”一堆比特位“的长度。 4.死锁处理既然有并发有锁，那就不可避免的会发生死锁。对于线程的死锁，应用程序一般不会加死锁检测机制，有死锁一般就要重启了。但对于数据库事务来说，死锁是很容易操作的事情，就不能简单重启来解决了。当前数据库一般采用超时机制和wait for graph的方式来解决，其中wait for graph就是通过破坏锁的环形依赖这个条件来解决的。如图所示：图中t1和t2有环形依赖。通常来说InnoDB选择回滚undo量最小的事务。 参考资料书籍：《MySQL是怎样运行的：从根儿上理解MySQL》《Mysql技术内幕 InnoDB存储引擎》（第二版）《高性能MySql》（第三版）官方资料：https://dev.mysql.com/doc/refman/8.0/en/innodb-storage-engine.html","categories":[{"name":"数据库","slug":"数据库","permalink":"https://liji53.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"oracle数据迁移","slug":"pythonOther/oracleMigration","date":"2021-09-02T06:31:01.000Z","updated":"2021-09-02T06:31:01.000Z","comments":true,"path":"2021/09/02/pythonOther/oracleMigration/","link":"","permalink":"https://liji53.github.io/2021/09/02/pythonOther/oracleMigration/","excerpt":"","text":"数据迁移总结(oracle)此类博客太多的坑，都不完整，要不执行着就报错执行不下去了。总的来说，能不用oracle就不要用，学习成本太高。 方法一:客户端exp/imp(不推荐)1. 环境准备，下载工具下载地址： https://www.oracle.com/cn/database/technologies/instant-client/winx64-64-downloads.html 下载以下2个文件： instantclient-basic-windows.x64-12.2.0.1.0.zip instantclient-tools-windows.x64-12.2.0.1.0.zip 注意：exp和imp工具在tools里，版本12.2.0.1.0 上才有， 2. 环境安装，配置TNS文件解压之后，在exp、imp工具的同级目录下新增Network/Admin/tnsnames.ora文件（环境变量看自己的需求） tnsnames.ora文件内容参考： 123456789ora11g_test = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.1)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = helowinXDB) ) ) 3.使用方法使用之前，需要建立好表空间、用户，这里不详细讲 12exp.exe usr/password@ora11g_test file=usr_export.dmp owner=usrimp.exe usr/password@target_oracle file=usr_export.dmp full=y 4. 存在问题说实在的，报的问题实在太多，很多解决不了，下面是随便罗列的几个，因此放弃这个方法. 123EXP-00113: Feature New Composite Partitioning Method is unsupported. EXP-00107: Feature (BINARY XML) of column XML_CONTENT in tableORA-00904: &quot;DUMMYFLAG&quot;: invalid identifier 方法二：expdp和impdp（不推荐）经历方法一的失败，网上看到有数据泵的方式，因此再次尝试 1. 环境&amp;资料使用数据泵需要10g以上的oracle server版本，同时需要在服务端运行，相关的教程建议看 https://hevodata.com/learn/export-data-from-oracle-using-expdp/#i1 https://docs.oracle.com/cd/E11882_01/server.112/e22490/dp_export.htm#SUTIL200 https://oracle-base.com/articles/10g/oracle-data-pump-10g#TableExpImp 2. 使用方法连接本地数据库 1sqlplus &#x2F; as sysdba 创建连接远程数据库(本地的话不需用)(网上很多教程没有提到这一步，如果不创建，生成的dmp文件在远程的oracle服务器上) 1SQL&gt;create public database link orcl11g connect to system identified by oracle using &#x27;(DESCRIPTION =(ADDRESS_LIST =(ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.2)(PORT = 1521)))(CONNECT_DATA =(SERVICE_NAME = test)))&#x27;; 创建dmp文件本地存储路径，并赋予权限 12SQL&gt;create directory data_dir as &#x27;/home/oracle/back/data&#x27;;SQL&gt;Grant read,write on directory data_dir to test; shell下，导出数据(有多种导出模式：导整个数据库、按表空间导、按用户导、按表名导、按查询条件导) 12mkdir -p /home/oracle/back/dataexpdp system/system dumpfile=export.dmp directory=data_dir network_link=orcl11g schemas=test 导入数据（注意：需要先建表空间、用户，即使按整个数据库模式） 1impdp test/*** dumpfile=export.dmp directory=data_dir schemas=test 3. 问题用了方法二，问题同样很多，有些报错解决不了。因此这个方法也放弃 123ORA-14460ORA-26059....... 方法三: 写脚本也试过用plsql的导出用户对象、导出表的方式，但也是动不动就出问题，而且无法实现自动化，想要灵活的定制只能自己写脚本同步数据。下面是相关代码， 工具：python 1. 整体代码结构123456789101112131415161718192021222324252627282930import cx_Oracleimport osg_table_space_name_list = [[&#x27;TEST1_DATA&#x27;, &#x27;test1dat.dbf&#x27;, 1024], [&#x27;TEST2_DATA&#x27;, &#x27;test2dat.dbf&#x27;, 1024]] grant_privilege = [&quot;CONNECT&quot;,&quot;RESOURCE&quot;,&quot;DBA&quot;,&quot;UNLIMITED TABLESPACE&quot;, &quot;select any table&quot;,&quot;create any table&quot;, &quot;drop any table&quot;]g_user_name_list = [[&quot;LJ_TEST&quot;, &quot;TEST1_DATA&quot;, grant_privilege], [&quot;LJ_TEST2&quot;, &quot;LJ_TEST2&quot;, grant_privilege]]exist_table_space_str = &quot;select count(*) from dual where exists(&quot; \\ &quot;select * from v$tablespace a where a.name = upper(&#x27;%s&#x27;))&quot;create_table_space_str = &quot;CREATE TABLESPACE %s DATAFILE &quot; \\ &quot;&#x27;/home/oracle/app/oracle/oradata/helowin/%s&#x27; &quot; \\ &quot;SIZE %dM EXTENT MANAGEMENT LOCAL SEGMENT SPACE MANAGEMENT AUTO&quot;exist_user_name_str = &quot;select count(*) from dual where exists(&quot; \\ &quot;select * from all_users a where a.username = upper(&#x27;%s&#x27;))&quot;create_user_name_str = &quot;CREATE USER %s IDENTIFIED BY test &quot; \\ &quot;DEFAULT TABLESPACE %s TEMPORARY TABLESPACE TEMP&quot;query_table_data_str = &quot;select * from %s.%s&quot;insert_table_data_str = &quot;insert into %s.%s (%s) values (%s)&quot;delete_table_data_str = &quot;truncate table %s.%s&quot;if __name__ == &#x27;__main__&#x27;: client = OracleClient() client.create_table_space() client.create_user_name() client.create_table() client.sync_data() 2.连接数据库12345678910111213141516class OracleClient: def __init__(self): os.environ[&#x27;NLS_LANG&#x27;] = &#x27;SIMPLIFIED CHINESE_CHINA.utf8&#x27; # 待同步的数据库 dsn = cx_Oracle.makedsn(&quot;192.168.0.1&quot;, &#x27;1521&#x27;, service_name=&#x27;test&#x27;) self.m_client = cx_Oracle.connect(&#x27;system&#x27;, &#x27;oracle&#x27;, dsn) self.m_cursor = self.m_client.cursor() # 数据源 src_dsn = cx_Oracle.makedsn(&quot;192.168.0.2&quot;, &#x27;1521&#x27;, service_name=&#x27;test&#x27;) self.m_src_client = cx_Oracle.connect(&#x27;system&#x27;, &#x27;oracle&#x27;, src_dsn) self.m_src_cursor = self.m_src_client.cursor() def __del__(self): self.m_cursor.close() self.m_client.close() self.m_src_cursor.close() self.m_src_client.close() 3. 建立表空间12345678910def create_table_space(self): for table_space_name in g_table_space_name_list: self.m_cursor.execute(exist_table_space_str % table_space_name[0]) data = self.m_cursor.fetchall() # todo: if table space created, should drop and recreate. if data[0][0] != 0: continue self.m_cursor.execute(create_table_space_str % (table_space_name[0], table_space_name[1], table_space_name[2])) self.m_client.commit() 4. 建用户123456789101112def create_user_name(self): for user_name in g_user_name_list: self.m_cursor.execute(exist_user_name_str % user_name[0]) data = self.m_cursor.fetchall() # todo: if user created, should drop and recreate. if data[0][0] != 0: continue self.m_cursor.execute(create_user_name_str % (user_name[0], user_name[1])) for privilege in user_name[2]: self.m_cursor.execute(&quot;GRANT %s TO %s&quot; % (privilege, user_name[0])) self.m_client.commit() 5. 建表1234567891011121314151617181920212223242526272829 def _get_table_name_list(self): src_table_name_list = &#123;&#125; dst_table_name_list = &#123;&#125; for user_name in g_user_name_list: self.m_src_cursor.execute(query_table_name_str % user_name[0]) src_data = self.m_src_cursor.fetchall() src_table_name_list[user_name[0]] = [x[0] for x in src_data] self.m_cursor.execute(query_table_name_str % user_name[0]) data = self.m_cursor.fetchall() dst_table_name_list[user_name[0]] = [x[0] for x in data] return src_table_name_list, dst_table_name_list def _create_table(self, user_name, table_name): query_table_name_str = &quot;select TABLE_NAME from all_tables where OWNER = &#x27;%s&#x27;&quot;query_create_table_str=&quot;select dbms_metadata.get_ddl(&#x27;TABLE&#x27;,&#x27;%s&#x27;,&#x27;%s&#x27;) from dual&quot; self.m_src_cursor.execute(query_create_table_str % (table_name, user_name)) create_table_obj = self.m_src_cursor.fetchall() create_table_str = create_table_obj[0][0].read() self.m_cursor.execute(create_table_str) self.m_client.commit() def create_table(self): src_table_name_list, dst_table_name_list = self._get_table_name_list() for user_name in src_table_name_list: for table_name in src_table_name_list[user_name]: # todo, if table created, should recreated if table_name in dst_table_name_list[user_name]: continue self._create_table(user_name, table_name) 6. 同步数据123456789101112131415161718192021222324252627def _sync_data(self, user_name, table_name): self.m_src_cursor.execute(query_table_data_str % (user_name, table_name)) titles = &#x27;,&#x27;.join([i[0] for i in self.m_src_cursor.description]) data_placeholder = &#x27;,&#x27;.join([&#x27;:&#x27;+str(i+1) for i in range(len(self.m_src_cursor.description))]) try: all_table_data = self.m_src_cursor.fetchall() except cx_Oracle.DatabaseError as msg: print(&quot;\\033[1;31;40mError[%s.%s]:%s \\033[0m&quot; % (user_name, table_name, msg)) return # if contains old data,should drop self.m_cursor.execute(delete_table_data_str % (user_name, table_name)) self.m_client.commit() try: self.m_cursor.executemany(insert_table_data_str % ( user_name, table_name, titles, data_placeholder), all_table_data) except cx_Oracle.DatabaseError as msg: print(&quot;\\033[1;31;40mError[%s.%s]:%s \\033[0m&quot; % (user_name, table_name, msg)) return self.m_client.commit()def sync_data(self): src_table_name_list, dst_table_name_list = self._get_table_name_list() for user_name in src_table_name_list: for table_name in src_table_name_list[user_name]: if table_name not in dst_table_name_list[user_name]: self._create_table(user_name, table_name) self._sync_data(user_name, table_name)","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"mysql-事务","slug":"database/mysql-transaction","date":"2021-08-29T18:42:00.000Z","updated":"2021-08-29T18:42:00.000Z","comments":true,"path":"2021/08/29/database/mysql-transaction/","link":"","permalink":"https://liji53.github.io/2021/08/29/database/mysql-transaction/","excerpt":"","text":"mysql-事务先看下事务的概念：需要保证原子性、隔离性、一致性和持久性（AICD）的一个或多个数据库操作。 redo logInnoDB的事务持久性，通过redo log来保证，简单来说就是把对数据的修改记录下来，如果出现宕机，在重启的时候对数据进行恢复(与double write的区别mysql-存储布局)。它的机制可以与日志文件系统如ext3、ext4 对比学习，参考操作系统-文件系统 1.redo log格式InnoDB通过redo log来记录事务对数据库做了哪些修改(也包括undo log的修改)。它的格式如下： type 表示日志的类型 space ID + page number 表示表空间的ID和page number （指向修改了哪个页） data 表示修改的内容。举个例子（修改字符串），本字段只要记录：页内的偏移 + string的长度 + 新string的值。 但是实际插入一条数据，涉及修改的内容可能会很分散，比如：如果每个修改点都记录一条日志，这个日志就会变得很大。因此针对这种复杂的修改，mysql专门设计多种针对某种复杂操作的日志。比方针对插入一条紧凑行格式的记录(格式比较复杂，不展示)，在恢复的时候判断type类型，然后调用专门用于恢复这类日志的函数，函数中自己计算哪些数据涉及修改 2. Mini-Transaction（redo log分组）还是以插入一条数据为例，当插入数据时，如果当前页的数据已经满了，这就会导致页分裂，我们至少需要2条(实际更多)redo log来记录这次的修改。在修复的时候，这2条redo log 不能只恢复其中1条，因此需要将这两条日志当成一个组进行恢复，这个组的所有日志要么都恢复，要么都不恢复。怎么解决呢？参考流的处理，一般要么标记这个流的长度，要么在流的尾巴加一个特殊标志如‘\\0’。因此在一组redo log的末尾加入一个特殊的redo log，如下图所示：在系统恢复的时候，只有解析到类型为MLOG_MULTI_REC_END 的redo 日志，才认为是一组完整的redo 日志并恢复。我们把一次原子操作的过程称为Mini-Transaction，而一条语句可能存在多个Mini-Transaction，如下图： 3.log buffer 管理还记得mysql-整体架构和mysql-存储布局中提到的redo log的内存和物理结构吗？下面我们看下redo log buffer的管理。InnoDB并不是一下子把整个log buffer的数据写入到磁盘中的，因此实际写入的redo log和内存中的redo log是有速度差异的，需要2个指针分别表示： 4. checkpoint如果脏页已经刷到磁盘中了，那么对应的redo log也就没有用处了，后面新产生的redo log就可以覆盖。结合我们上面已经提到过的2种状态（从哪里开始写内存buffer，从哪里开始写入磁盘），现在新增redo log是否可以被覆盖(脏页已经写入磁盘) 这一种状态。新的状态如下：同样需要一个指针(checkpoint)记录哪些redo log已经无效了。现在我们在来整理下这个checkpoint的过程： 脏页数据写入到磁盘，将flush链表中对应的控制块移除 更新内存中无效redo的指针：找到flush链表中最老节点的redo log位置值赋值给checkpoint 更新硬盘中无效redo的指针：将新的checkpoint的位置 写到日志文件 5. 恢复过程 确认恢复的起点：从日志文件的头部信息中获取checkpoint的位置 依次扫描起点后面的redo log，并按照日志的内容进行恢复 但修复的时候一个页面可能有好几个redo log，为了加快修复的过程，mysql设计了哈希表，对于同一个页面的数据一次性修复： undo logredo log用来恢复提交事务修改过的物理页，而undo log用来记录事务修改过的记录的版本。undo log 用于保证事务的原子性和隔离性，也可以说用来帮助事务的回滚和MVCC功能。了解下回滚的概念：当事务失败了，撤销事务对当前数据库造成的影响，从而保证事务的原子性 1. 需要undo log的操作需要回滚的操作，就三种：增、删、改。而查询是不需要回滚的。它的基本思路如下： 对‘增’的操作，只要把这条记录的主键值记下来，在回滚的时候删除这个主键值对应的记录即可 对‘删’的操作，要把删除记录的数据全部记录下来，在回滚的时候再把这些内容插入到表中 对‘改’的操作，要把修改记录的旧值记录下来，回滚的时候把这条记录更新回旧值 2. undo logInnoDB将插入、删除、更新数据时需要记录的内容写到undo log中，插入undo log格式如下：可以看到undo日志会将主键的值和长度记录了下来删除和更新undo log格式比较复杂，思路上面已经写过，不再展示undo log日志类型虽然有多种，但只分为2类:insert类和update类（包括删除和更新）这么分类的原因是insert类型的日志在事务提交之后就可以直接删除，而update类的undo log不能删除（MVCC中讲原因） 3. undo log缓存undo log是作为一种页类型出现在buffer pool中的（注意与redo log buffer 的区别），关于表空间-页的介绍，参考mysql-存储布局一个事务可能包含多个语句，一个语句可能产生多条undo日志。因此一个事务产生的undo log可能一个页面放不下，需要放到多个页面中。另外，普通表和临时表的的undo日志要分别记录，并且undo log又分为insert和update类型。如图所示：这就是一个事务产生的undo log的内存布局，当然实际中并不会直接分配4个链表，而是按需分配 4. undo log页重用一个事务可能产生很多的很多条undo log，也可能只有1、2条undo log。因此若为每个事务都分配一个单独undo页会非常浪费空间。mysql在事务提交之后，在某些情况下对这些undo log页进行了重用。它的策略如下： 链表中只包含一个Undo页面 该Undo页面已经使用的空间小于整个页面空间的3/4 而insert类型的undo log 和update类型的undo log在重用的时候又不一样： insert类型可以直接覆盖 update类型不能直接删除，因此在页的剩余空间中继续写（需要等purge线程回收undo log页） 关于undo log的分配过程有点小复杂，可以从《MySQL是怎样运行的：从根儿上理解MySQL》找答案。而purge的过程还要再等等。 参考资料书籍：《MySQL是怎样运行的：从根儿上理解MySQL》《Mysql技术内幕 InnoDB存储引擎》（第二版）《高性能MySql》（第三版）官方资料：https://dev.mysql.com/doc/refman/8.0/en/innodb-storage-engine.html","categories":[{"name":"数据库","slug":"数据库","permalink":"https://liji53.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"mysql-索引","slug":"database/mysql-index","date":"2021-08-21T13:21:02.000Z","updated":"2021-08-21T13:21:02.000Z","comments":true,"path":"2021/08/21/database/mysql-index/","link":"","permalink":"https://liji53.github.io/2021/08/21/database/mysql-index/","excerpt":"","text":"mysql-索引在使用数据库时，表索引的设计，以及使用sql语句时如何使用索引，是DBA、开发非常关心的事情。如果连索引的实现原理都不清楚，根本就无法写出高效的查询语句，也无法对表结构进行优化。 聚簇索引1.索引的结构我们已经知道了在一个页中如何通过页目录对页内数据进行查找（回顾mysql-存储布局数据页格式）。而如何快速找到数据在哪个页中，则通过索引实现，索引页和数据页的页类型是相同的，因为InnoDB也是按照数据页的格式存放索引。如图所示：聚簇索引页它存放的是主键值 + 页号。使用聚簇索引查找数据时，通主键遍历索引页，就可以找到页号了。如果数据量很大，则需要多个索引页，这些索引页又需要更上一层的索引页。如图所示：现在我们可以知道，实际的用户记录存放在B+树的最底层叶子节点上。实际应用中B+树的层数也就3-4层，一般不会超过4层。从IO次数来看，如果是指定主键查询，4层的B+树，只需要4次磁盘访问即可。 2.聚簇索引聚簇索引使用主键值的大小进行排序，包括内页数据按照主键值排序成一个单向链表，索引页也按照主键值大小排序形成双向链表这种B+树就是聚簇索引，前面展示的图即为聚簇索引，聚簇索引包含实际用户数据。聚簇索引不是认为创建的，默认就有。 3.根节点在刚创建索引的时候，会为这个索引建立一个根节点，由于刚开始没有数据，数据直接往根节点插入，等到这个根节点满的时候，会把页数据复制到一个新的页，再对这个新页进行页分裂操作，而原来的根节点变成存储索引的非叶子节点。根节点页面是不动的，这样InnoDB再需要遍历索引的时候，就能知道索引的入口。 二级索引1. 二级索引的结构聚簇索引只有在查询条件是主键的情况下才能使用，如果我们想要以别的列作为查询条件，如何避免全表查询呢？我们可以通过建立多颗B+树，来达到这个目的，如下图所示： 2. 与聚簇索引的区别二级索引与聚簇索引的区别： 二级索引的叶子节点存储的不是用户数据，而是 索引列+主键值 非叶子节点存储的不是 主键+页号，而是 索引列+页号 二级索引按照索引列大小排序，而聚簇索引按照主键值排序 因此通过二级索引查找，能找到对应的主键值，再通过主键值到聚簇索引中查找，就能找到完整的用户记录了(再到聚簇索引中查找的过程称为回表) 3.联合索引联合索引是同时以多个列作为索引，但联合索引的多个列并不是等价的，它是先按照一个列进行排序，如果值相同，再按照第二个列排序，依此类推。联合索引的结构和二级索引基本一样，因此联合索引本质上还是二级索引。 索引的使用1. 索引的代价显而易见，索引有2方面的代价： 空间上，每建立一个索引，就需要建立一颗B+树 时间上，进行增删改时，需要对索引进行维护，保证它的有序,尽管有change buffer 使用二级索引，需要回表到聚簇索引中查找数据，但回表也是有代价的： 二级索引的叶子节点存放的是主键值，这些主键值是散列存放的，访问聚簇索引是随机IO 因此如果回表的数据量很大，二级索引的效率就越低，甚至宁愿使用全表扫描。 2. 如何建立索引总结如下： 最好为那些列基数(重复值越少，基数越大)大的列建立索引，为基数太小的列建立索引效果可能不好。 建立索引的列，在允许的情况下，数据类型的范围越小越好。 鼓励只对字符串的前几个字符进行索引，即二级索引中索引记录只保留字符串的前几位 最好让主键值AUTO_INCREMENT，或者让Innodb自动创建，因为主键值如果是随机插入的，影响插入性能。 3. 如何使用索引总结如下： 由于联合索引按照从最左边的列开始排序，因此搜索条件中的各个列必须是联合索引中从最左边连续的列。 匹配前缀词，如like ‘%.com’ 这种语法会导致全表搜索，在插入相关列的时候，我们可以逆序插入。 在查询列表中尽量不要全部查询，而只包含索引的列，这样能避免回表。 如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式或者函数调用形式出现的话，是用不到索引的。 参考资料书籍：《MySQL是怎样运行的：从根儿上理解MySQL》《Mysql技术内幕 InnoDB存储引擎》（第二版）《高性能MySql》（第三版）官方资料：https://dev.mysql.com/doc/refman/8.0/en/innodb-storage-engine.html","categories":[{"name":"数据库","slug":"数据库","permalink":"https://liji53.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"mysql-存储布局","slug":"database/mysql-layout","date":"2021-08-14T22:20:07.000Z","updated":"2021-08-14T22:20:07.000Z","comments":true,"path":"2021/08/14/database/mysql-layout/","link":"","permalink":"https://liji53.github.io/2021/08/14/database/mysql-layout/","excerpt":"","text":"mysql-存储布局我们平常在软件设计时，大部分打交道的都是内存中的数据结构。这次我们来看看InnoDB在文件中是如何设计数据结构的(回顾mysql-整体架构InnoDB架构的On-Disk Structures)。 磁盘架构从前面一节的架构图中，我们可以看到有多种表空间文件，如系统表空间(ibdata1)、独立表空间(表名.ibd)等。除了表空间，还存在doublewrite 文件，重做日志文件。 1. 表空间InnoDB中包含多种表空间，如： 系统表空间，change buffer的页存储在这里 独立表空间，设置了innodb_file_per_table之后，用户创建的每个表都会生成对应的表名.idb 通用表空间，在创建表的时候可以指定数据存储到对应的通用表空间，从逻辑上，我们可以把它看成是多个独立表空间的集合。 Undo 表空间，保存了undo log的表空间 临时表空间 2.boublewrite 文件double write 用于保证数据的可靠性，我们知道HDD的扇区大小是512B，而InnoDB中一个页的大小是16K，如果在写一个页的过程中，突然断电了，磁盘只能保证扇区的写入是原子的，却不能保证16K页的数据原子性。这跟redo log的作用并不是一回事，redo log保证的是事务的原子性，它只会记录对页的操作。一旦16K的页只写了1K的数据，这个页从结构来说就被破坏了，因此double write用于保证页的结构性完整。它的原理如图所示：从版本8.0.20开始，boublewrite从系统表空间移到了单独的文件中。double write由于是顺序写入，比起将数据写入到数据文件中，开销并不是很大。默认是2个文件分别对应flush list 和LRU list 3.redo log文件redo log的作用我们后面在讲，这里我们简单了解下它的物理文件的结构即可。默认存在ib_logfile0 和ib_logfile1 两个文件。它的结构如图所示：其中前2048个字节，用来存储一些管理信息。比方说当前日志文件从哪里开始恢复数据(也就是checkpoint的位置)。而后面的数据就是redo log buffer的镜像(回顾mysql-整体架构)。如果出现日志写满了，则从头覆盖写第一个文件。 表空间管理下面我们了解下表空间内部数据是如何管理的。 1.表空间结构mysql对表空间的管理，按照”组(group)-区(extent)-页(page) “进行管理，其中页的大小为16k，也是mysql操作的最小单元；页的上一级是区，管理了64个页，一个区的大小为1M；最上层的是组，管理了256个区。如图所示：其中我们看到像FSP_HDR、IBUF_BITMAP 等这些16k大小的条目就是所谓的页。这里我们需要清楚mysql这么设计的原因： 让数据连续存储，在进行范围查询(通过聚簇索引查询)时能减少随机IO。 虽然表空间是一个文件，但物理上可能是不连续的(参考文件系统)，在数据量到达一定程度时，mysql按区来申请空间，用于保证物理空间的连续。 将表空间划分成组、区，这样能方便管理页 图中的表空间虽然比较简单，但在细入到各个页的结构之前，我们还需要清楚其他的一些基本概念。 2.段与碎片区mysql里面也有段的概念，跟编译时将程序分成代码段、数据段的概念类似，mysql将每个区、甚至页按照功能属性进行逻辑分类，比方说一张表至少可以分为数据、索引、回滚三个段。段是按照区为单位进行申请的。但如果一张表的数据量很小，这时候也按照区为单位进行空间申请就可能照成浪费。因此有专门的碎片区用于存储这些数据量比较小的表，等这些少量数据增长到一定大小的时候（32页），就开始按照区为单位进行申请。 3.系统表空间除了上面的独立表空间(用户创建的表)，还存在系统表空间，用于存储整个系统的属性：我们看到除了第一个组的第一个区不一样，其他结构跟独立表空间一摸一样。而第一个区新增了第4-第8页，分别表示: SYS Insert Buffer Header 存储Insert Buffer的头部信息 INDEX Insert Buffer Root 存储Insert Buffer的根页面 TRX_SYS Transction System 事务系统的相关信息 SYS First Rollback Segment 第一个回滚段的页面 SYS Data Dictionary Header 数据字典头部信息 4.逻辑结构搞清楚了表空间的物理存储结构之后，我们简单再看下它的逻辑存储结构： 区管理innodb通过XDES Entry表来管理组内的256个区。表空间头部信息页(FSP_HDR)和扩展描述页(XDES)用来存储XDES Entry表 1. 页的通用部分每个页都是16k，它们(共有11种页)有相同部分的结构：其中File Header描述了页的通用信息，比方说页号、页类型、校验和、上一个页号、下一个页号、日志序列号等。File Trailer 用于校验页是否完整，它的校验过程: 修改数据时，File Header记录下新数据的校验和。 先写入File Header和数据内容，等File Header写入成功，再写入File Trailer 如果中间宕机了，只要比对File Header和File Trailer的校验和是否一致就性了 2.表空间头部信息页(FSP_HDR)和扩展描述页(XDES)FSP_HDR和XDES的结构类似，可以对照着一起看。FSP_HDR页的格式：XDES页的格式： 3.区块描述符(XDES Entry)FSP_HDR和XDES都有一张XDES Entry表，这张表记录了所属组256个区的信息。这些信息包括： 属于哪个段(如果是碎片区则无效)； 上一个XDES Entry和下一个XDES Entry的指针； 区的种类（包括空闲区、有剩余空间的碎片区、没有剩余空间的碎片区、附属于某个段的区）； 页的空闲bitmap表 段和碎片区的概念大家已经清楚了，而第4项用于快速找到当前组剩余的空闲页。下面我们重点看下它的2个指针的作用，它用于双向链表。假设你要插入一条数据，这时候如果数据比较少，则mysql从碎片区找空闲页。而如果当前的数据量比较大，InnoDB则从对应的段中找有空闲页的区。因此如果不使用链表，而是全遍历，就又影响性能了。mysql根据区的种类以及段ID将不同类型的区链接了起来。直属于表空间：&nbsp;&nbsp;&nbsp;&nbsp;1. 碎片区：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.1 空闲碎片区链表&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.2 有剩余空间的碎片区链表&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.3 没有剩余空间的碎片区链表&nbsp;&nbsp;&nbsp;&nbsp;2. 段1：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.1 属于段1，空闲区链表&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.2 属于段1，有剩余空间的链表&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3 属于段1，没有剩余空间的链表&nbsp;&nbsp;&nbsp;&nbsp;3. 段2：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;… 将这些区链接之后，就不需要对所有的XDES entry进行遍历了。(可以适当的想想内存池管理) 4.File Space Header结构前面我们讲了XDES Entry的双向链表，但链表的入口在哪里的？其中碎片区的链表入口在File Space Header，这个结构体属于FSP_HDR特有的，因此我们可以把碎片区理解成是表空间直属的。由于在FSP_HDR页格式的图中已经描述了每个字段的内容，因此不再细说。 段管理XDES Entry用于描述区的信息，而INODE Entry用于描述段的信息。 1. 段信息节点页 - 数据格式INODE页的格式：如果表空间中的段特别多(索引很多)，一个INODE页可能放不下所有的INODE Entry，因此需要申请新的INODE页，于是List Node再次出现。List Node for INODE Page List就是用于链接的(前后指针)，而这个链表的入口也在FSP_HDR的File Space Header中。 2. 段描述符(INODE Entry)格式如下：前面在讲XDES Entry的双向链表时，我们已经把碎片区的链表入口找到了，而属于某个段的链表入口则是在这个结构中。除了3个链表的入口以外，还有32个碎片页的页号记录。这32个碎片页是在表数据小的时候用到。。。（回看”段与碎片区”的描述） 页-数据/索引页(INDEX)前面讲的都是InnoDB用于管理表空间所用到的数据格式，下面我们看看用户的实际数据是怎么存储的。在mysql中存储数据的页和存储索引的页在结构上是没有区别的。 1.数据页格式其中Infimum和Supremum是最小、最大记录，这2条记录是系统自动给我们生成的。 2.行记录格式每一条用户记录的格式：图中第一行的内容如下： 变长字段长度列表：存储varchar字符串类型的时候，用于记录字符串的长度 NULL值列表：记录列的值是否为NULL的bitmap表，只要创建创建表的时候没有not NULL声明，就会有相应的bit位。 记录头信息：重点关注next_record用于链表(理解成next指针)，这是为了让mysql的数据按照主建的大小顺序排列。 3.页目录（Page Directory）在一个页中，InnoDB除了会把记录从小到大排序以外，还会对页内数据进行分组，而且每个分组的记录数在1-8条，如果超过8条，则会将记录进行拆分。这么做的原因自然还是为了加快查找速度，通过分组只要遍历组和相应组的1-8条记录即可。页目录就是用来存放分组信息(指向当前组最大节点的偏移地址)：图中内部数据指针只画了部分，大家理解即可。 4.页面头部（Page Header）这个结构自然用于存放本页的全局信息。比如有多少条记录，第一条记录的入口地址， Page Directory槽的个数，还未使用的空间大小等，感兴趣的自己看《MySQL是怎样运行的：从根儿上理解MySQL》。 总结图上面的这些数据结构除了专业搞mysql的，可能根本记不住，如果某一天要用到了，可以参考下面这张全图:这些数据结构背后的设计，更加值得我们学习，比方： 文件内部分组、分区、分页的分层管理 段与碎片区的概念 如何快速找到空闲的页 数据量小的时候如何避免空间浪费，数据量大的时候如何保证物理空间连续。 如何在文件中实现链表、双向链表、页目录 如何避免随机IO，提高磁盘读写效率 如何保证数据的一致性等等。。。 资料书籍：《MySQL是怎样运行的：从根儿上理解MySQL》《Mysql技术内幕 InnoDB存储引擎》（第二版）《高性能MySql》（第三版）官方资料：https://dev.mysql.com/doc/refman/8.0/en/innodb-storage-engine.htmlPS：如果对InnoDB的存储格式感兴趣，强烈推荐《MySQL是怎样运行的：从根儿上理解MySQL》","categories":[{"name":"数据库","slug":"数据库","permalink":"https://liji53.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"mysql-整体架构","slug":"database/mysql-arch","date":"2021-08-11T19:20:30.000Z","updated":"2021-08-11T19:20:30.000Z","comments":true,"path":"2021/08/11/database/mysql-arch/","link":"","permalink":"https://liji53.github.io/2021/08/11/database/mysql-arch/","excerpt":"","text":"mysql-整体架构现在的软件开发基本上都离不开数据库的支持，而最常用的关系型数据库有oracle、SQL Server、mysql等，但如果考虑到开源，mysql应该是最受欢迎的。在《Mysql技术内幕 InnoDB存储引擎》中作者认为一个新的OLTP项目不使用mysql InnoDB存储引擎是非常愚蠢的（非常的自信）。 数据库的分类关系型数据库(sql)：适合存储结构化数据(抽象成二维表格模型)，支持事务保证ACID，支持SQL适合复杂、多表的查询，缺点是海量数据的读写效率以及可扩展性。非关系型数据库(NoSql)：常给web应用提供可扩展的高性能数据库，有redis、HBase、BigTable、MongoDB 行数据库和列数据库：行数据库存储数据的方式是一行行存储的，适合OLTP应用。列数据库按列存储，因此每一列数据都为索引(数据即索引)，适合OLAP应用 OLTP(on line transaction processing)：对数据做增删改的操作频繁的应用，要求稳定性、实时性。如银行交易系统、淘宝购物等。OLAP(on line analytical processing)：对数据的查询频繁、查询量大的应用，适合做数据分析，为决策提供支持。 按照上面分类，我们的主角InnoDB属于关系型数据库-行数据库-目标群体主要面向OLTP的应用。 整体架构在学习mysql之前，我们要先熟知它的整体框架:server层(后续介绍优化器)在这里不做介绍。而存储引擎我们只看InnoDB的实现。InnoDB与其他mysql存储引擎的比较，参考官网：https://dev.mysql.com/doc/refman/8.0/en/storage-engines.htmlInnoDB的架构：聚焦到内存池以及存储磁盘的架构：这张图有点复杂，我们先看内存部分。 内存架构1. buffer pool - 结构InnoDB会申请一大块内存，并对这块内存进行分页，一个页的大小是16K。其中控制块记录了对应缓存页的表空间ID、页号、链表节点信息等。而在多线程的环境中，为了减少锁的开销，一般会通过减少锁的空间颗粒度从而减少锁的冲突(参考操作系统-并发)因此将buffer pool设计成多个小的buffer pool，能有效提升多线程的性能。如图所示：其中chunk是mysql申请内存的单位，这样可以细化内存申请的颗粒度，避免大规模的内存拷贝。 2. buffer pool - free链表、Flush链表、LRU链表mysql针对不同的业务场景，将不同状态的缓存页的控制块按照链表的形式链接了起来。 free链表, 当我们要访问数据时，先通过哈希表（key为表空间ID+页号，散列算法为mod，哈希桶的个数为比buffer pool页数*2大一点的质数）来快速定位是否在buffer pool中，如果不在pool中，则从free链表中取一个空闲的缓存页控制块 flush链表，当我们修改了这个页的数据，于是就变成了脏页，需要在未来的某个时间点写入磁盘。而flush链表就是记录了哪些页需要flush到磁盘。 LRU链表，如果buffer pool的空间满了，而需要访问的页没有命中时，就需要从磁盘中读一个页，并把当前buffer pool中的一个页淘汰掉，LRU链表管理了缓存池中页的可用性。 Free和flush链表不涉及太复杂的策略，但LRU的策略是我们需要清楚的（LRU策略会经常遇到，比方在操作系统-虚拟memory就遇到过）mysql会把LRU链表分成2部分：young和old,分表表示热数据和冷数据如图所示：它的策略如下： 每次从磁盘中读一个新的页时，会把新的页放入到old区的头部。这样就能防止把一些真正的热数据淘汰 记录缓存页第一次访问时间，如果在一定时间间隔后，再次访问了这个缓存页，就会把它移动到young区域的头部。防止出现短时间内访问大量使用频率非常低的页面。 第二条策略会导致链表节点移动频繁，因此只有被访问的缓存页位于young 区域的1/4 后边，才会被移动到LRU链表头部。 3. change buffer(insert buffer)change buffer是insert buffer的升级，官方文档中就叫change buffer。change buffer只有在对非唯一的二级索引进行DML操作才会使用。必须是二级索引的原因：二级索引对主键的存放是散列的，对于HDD存储，随机读写的代价是巨大的，参考文件系统。因此在DML操作时，如果需要修改的二级索引页不在buffer pool中，则会先放入到change buffer，避免随机读写。而必须是非唯一索引的原因：非唯一索引不需要读整个索引判断是否唯一，再次避免了随机读它的架构如图所示：从图中可以知道： change buffer 属于buffer pool的一部分（默认最大使用25%的buffer pool） InnoDB会以一定的周期将insert buffer中的索引页和实际数据页合并。如果宕机了，inset buffer数据较多的话，需要花大量时间恢复数据。 change buffer页的数据也是按照B+树组织的，其中叶子节点存放了二级索引的记录。insert buffer bitmap用于记录实际二级索引页的剩余可用空间(下一节看它的物理位置)，帮助change buffer 与二级索引进行合并。 4. 自适应哈希索引从内存池的架构图中，我们可以知道，自适应哈希索引是对buffer pool中的数据页建立索引，并不是对全表建立索引。而有意思的是自适应这个词，这表示InnoDB会监控对索引页的查询，只有在一定情况下才对数据页建立索引，它的策略如下： 对数据页的访问模式必须是一样的（如where a = ‘xxx’, 不支持范围查询） 以条件1的模式访问了100次 以条件1的模式访问了N次，其中N=页中记录*1/16 同时为了减少锁的冲突，InnoDB将自适应哈希索引默认分成8个分区(可以通过参数修改)注意：在buffer pool中我们提到了用于判断数据是否在buffer pool的哈希表，这两个不是一回事。 5. log buffer这里的log 指redo log，不包括undo log（后面详细介绍这两个）。log也需要写入到磁盘，跟普通数据一样，不可能有一条log就立马写入磁盘，因此redo log同样需要buffer（默认16M）。redo log buffer同样也进行分页管理，一个页是512B（跟HDD的扇区大小一致，这样能保证原子，因此redo log 不需要double write策略）。如图所示：关于redo log buffer 的管理，我们后面再讲，先知道有这个东西即可。 后台线程这里我们主要讲InnoDB中的后台线程，而不是server层用于负责连接以及负责执行sql的线程。 1.线程分类InnoDB中主要有以下4种线程: Master Thread: 主要负责将缓存池中的数据异步刷新到磁盘。 IO Thread：主要负责异步IO的回调处理，默认有4个read、4个write、1个insert buffer、1个log Purge Thread：事务提交后，undo log可能不再需要了，该线程用来回收无用的undo log页。（回收的策略由于涉及到read View，在后面讲） Page cleaner Thread: 将脏页的更新都放到这个线程中执行 2.Master ThreadMaster Thread的逻辑参考《Mysql技术内幕 InnoDB存储引擎》，只写了部分逻辑 1234567891011121314151617181920212223def master_thread(): while True: if InnoDB is idle: # innodb_io_capacity(参数)表示磁盘吞吐量，默认200 # 官方给出的参考是如果是7200RPM的HDD，建议把这个参数改成100，如果是SSD磁盘，建议把这个参数改大 if last_ten_second_io &lt; innodb_io_capacity: do_buffer_pool_flush_to_disk(100) # 将100个脏页写如磁盘 do_merge_insert_buffer() # insert buffer的索引合并到硬盘 do_log_buffer_flush_to_disk() # 将redo log刷新到磁盘 do_full_purge() # 回收undo 页 if buf_get_modified_ratio_pct &gt; 70%: do_buffer_pool_flush_to_disk() # 脏页刷新到硬盘，新版本中已经放到Page cleaner Thread中执行。 else: do_log_buffer_flush_to_disk() # 将redo log刷新到磁盘 if last_one_second_io &lt; 5 % innodb_io_capacity: do_merge_insert_buffer() # 磁盘io压力不大,将insert buffer的索引合并到硬盘 # buf_get_modified_ratio_pct(参数)，默认90 # 当脏页的数量大于90%时，则进行脏页刷新 if buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct: do_buffer_pool_flush_to_disk() # 脏页刷新到硬盘，新版本中已经放到Page cleaner Thread中执行。 if no_user_active: do_full_purge() # 回收undo 页 sleep(1) 主要是干这些事情： 刷新脏页到磁盘（已经交给新的线程做了） 合并插入缓存的数据（尽量在空闲的时候） 将redo log数据刷新到磁盘（为保证原子性，总时执行） 回收无用的undo log页（已经交给新的线程执行了） 参考资料书籍：《MySQL是怎样运行的：从根儿上理解MySQL》《Mysql技术内幕 InnoDB存储引擎》（第二版）《高性能MySql》（第三版）官方资料：https://dev.mysql.com/doc/refman/8.0/en/innodb-storage-engine.html","categories":[{"name":"数据库","slug":"数据库","permalink":"https://liji53.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"数据监控(influxDb+grafana)","slug":"pythonOther/deployMonitor","date":"2021-07-30T03:02:02.000Z","updated":"2021-07-30T03:02:02.000Z","comments":true,"path":"2021/07/30/pythonOther/deployMonitor/","link":"","permalink":"https://liji53.github.io/2021/07/30/pythonOther/deployMonitor/","excerpt":"","text":"数据监控方案背景&amp;预备知识​ 经过一个月多月的程序运行，数据沉淀在mongodb中，接下来就要考虑统计报表了，数据统计能最直接的体现你的工作价值！ ​ 从网上找了一些数据监控的解决方案，得益于docker的简单部署，让我们在验证方案可行性上省去了大量时间。整体方案：1.使用docker部署InfluxDb和Grafana；2.用influxDb远程连接Mongodb，并用脚本生成influxdb数据；3.最后通过Grafana的web展示出来。 ​ 预备知识： 了解InfluxDb，会使用python或其他语言读写influxdb数据库 了解Grafana，会简单使用对应的web即可 了解mongodb，由于数据源在mongodb，因此需要会从mongodb中读数据 环境部署1. 下载安装包下载地址： https://dl.grafana.com/oss/release/grafana-8.0.6-1.x86_64.rpm https://dl.influxdata.com/influxdb/releases/influxdb-1.7.10.x86_64.rpm 2. 生成docker镜像这里我把2个软件合成了一个镜像。 启动脚本文件run-tool.sh: 12service grafana-server startinfluxd -config /etc/influxdb/influxdb.conf dockerfile文件： 123456789101112131415FROM centos:7COPY influxdb-1.7.10.x86_64.rpm /home/COPY grafana-8.0.6-1.x86_64.rpm /home/COPY run-tool.sh /RUN cd /etc/yum.repos.d/ \\ &amp;&amp; curl -O http://mirrors.aliyun.com/repo/Centos-7.repo \\ &amp;&amp; rm CentOS-Base.repo; mv Centos-7.repo CentOS-Base.repo \\ &amp;&amp; yum clean all; yum makecache; yum -y update \\ &amp;&amp; yum install -y /sbin/service; yum install -y fontconfig \\ &amp;&amp; yum install -y urw-fonts \\ &amp;&amp; cd /home/ \\ &amp;&amp; rpm -ivh influxdb-1.7.10.x86_64.rpm \\ &amp;&amp; rpm -ivh grafana-8.0.6-1.x86_64.rpm \\ &amp;&amp; chmod +x /run-tool.shCMD /run-tool.sh 生成镜像命令： 1docker build -t tool:monitor . 3. 启动容器1docker run --name monitor --privileged -it -p 192.168.0.1:8086:8086 -p 192.168.0.1:3000:3000 -v /home/liji/docker/tmp:/mnt tool:monitor 验证是否部署成功，登录grafana的web界面查看，存在以下登录界面说明部署成功： 数据生成数据生成这个环节是粘合剂，把业务生成的数据通过某种规则转成直观的统计数据，是最核心的步骤。本环节我是通过python对mongodb里的数据进行统计，仅贴部分代码： 1. 连接mongodb、连接influxdb123456789import datetimeimport pymongofrom influxdb import InfluxDBClient# 连接mongodburl = &quot;mongodb://&quot; + g_mongo_ip + &#x27;:&#x27; + g_mongo_portmongo_client = pymongo.MongoClient(url)# 连接influxdbinflux_client = InfluxDBClient(g_influx_ip, g_influx_port, database=&#x27;test&#x27;)influx_client.create_database(g_influx_database) # 没有则创建 2. 统计mongodb的数据(DIY)12mongo_db = mongo_client[mongo_db_name]mongo_db[mongo_col_name].find(&#123;&quot;xxx&quot;: &#123;&quot;$exists&quot;: True&#125;&#125;).count() 3. 写入influxdb(DIY)123456789points = [&#123; &quot;measurement&quot;: mongo_db_name, &quot;time&quot;: datetime.datetime.utcnow().isoformat(&quot;T&quot;), &quot;fields&quot;: &#123; &quot;current_problem_count&quot;:100, &quot;resolve_problem_count&quot;:20 &#125; &#125;]influx_client.write_points(points) 4. 验证数据是否写入在安装了influxdb的环境中运行influx，具体命令可以百度 123456789[root@123106ce0db7 /]# influxConnected to http://localhost:8086 version 1.7.10InfluxDB shell version: 1.7.10&gt; show databases name: databasesname----_internaltest 界面展示这个环节是对grafana的界面操作，我也是刚入门，基本操作如下： 1. 配置数据源 选择influxdb以及选择连接地址端口 选择要连接的数据库，不用怕错误，点击“save &amp; test”的时候，会自动帮你测试连接情况 2. 配置展示面板 选择要展示的数据 3. 结果呈现这个效果是我的效果，暂时已经符合我的预期了哈 网上盗的图，参考 总结整个数据监控部署实现差不多花了2天半时间，在这个过程中让我第一次接触influxdb时间序列数据库，也第一次体验了数据监控的方案。作为开发，使用了你以前没用过的技术，确实很爽，但也要及时总结、温故而知新。","categories":[],"tags":[]},{"title":"os-文件系统","slug":"operatingSystem/os-fileSystem","date":"2021-07-10T20:11:07.000Z","updated":"2021-07-10T20:11:07.000Z","comments":true,"path":"2021/07/10/operatingSystem/os-fileSystem/","link":"","permalink":"https://liji53.github.io/2021/07/10/operatingSystem/os-fileSystem/","excerpt":"","text":"文件系统文件系统是OS用来组织和分配存储设备的方法，现在linux系统用的基本都是Ext4文件系统，在window上则基本都是NTFS文件系统，接下来我们将学习它们的数据结构与实现原理。 HDD和SSD基础在了解文件系统的实现之前，需要先知道存储介质的特性，因为文件系统(包括很多应用程序，像数据库)正是基于这些特征才设计的。 HDD的硬件特性如上图，你需要清楚的是 扇区：即图中的编号，操作硬盘的基本存储单元，对扇区的读写是原子的， 寻道：图中seek的动作，寻道时间一般在几毫秒到十几毫秒 旋转：图中Rotates的动作，旋转一圈的时间一般也要几毫秒(如10000RPM = 6 ms/R) 以现有的技术发展，寻道、旋转时间的进步比内存、cpu的发展慢的多，甚至是停滞的 一次读写实际花费的时间应该是：T(I/O) = Tseek + Trotation + Ttransfer其中Ttransfer一般是100M/s到几百M/s之间有了这个公式之后，在对文件系统的设计(包括应用程序的设计)，要尽可能的利用这个公式，提高传输效率。在涉及读写的时候，主要考虑二种读写模式： 随机读写：在随机读写中，每次磁头都需要重新定位，它的IO时间为Tseek + Trotation + Ttransfer 顺序读写：在顺序读写中，如果一次性写入一大块的数据，则只需要一次的Tseek和Trotation 即可。但如果是分批次的顺序写入，除了第一次的Tseek和Trotation时间，后面每次读写还需要Trotation时间(因为磁盘是一直在转的，分批次写入会有时间差，导致磁盘转过头) SSD的硬件特性关于SSD，你需要清楚的是： Page: 读写以page为单位，一般4k或8K Block：删除的基本单位，由多个page组成 SSD内部一般会维护一个mapping table，维护逻辑地址到物理地址的映射，不需要寻道和旋转，可以直接计算出物理地址。它的定位时间一般在0.1ms SSD如果损坏了，数据很难恢复，而HDD要容易的多 HDD没有写入次数的限制，SSD存在写入寿命的限制（因此有损耗均衡的机制） 基于这些硬件特性，SSD在随机读写上的性能要远好于HDD，而在顺序读写上一般也比HDD快1倍。（SSD内部的机制如垃圾回收机制，损耗均衡等不再介绍） 文件系统的实现文件系统会把硬盘分割成一个个块，以块为单位进行读写，一般一个块4K大小。每个块只属于一个文件(目录)，如果文件不足block大小，则剩余的容量不再使用 Ext2的布局Ext2文件系统的布局(图片来源：https://blog.csdn.net/gongjiwei/article/details/82025142):MBR: 引导块，常用于启动电脑block group：由诺干个块组成的，为了提高访问同一目录下文件的效率(减少Tseek)，文件系统会把同一个目录下的文件尽量放在一个group中。superblock：记录此文件系统的整体信息，如块大小，容量等，每个block group都有，用于备份。group description table: 块组描述符表，记录了每个块组的块位图、inode位图、inode table等的位置，同样每个block group都有，用于备份。block bitmap：块位图中的每一位表示当前块组中对应的那个块是否被使用。自身占一个块inode bitmap：i节点位图中的每一位表示inode是否可用。自身占一个块data blocks：数据块，用于存放文件、目录的数据inode table:ext2中一个inode占用128byte（记录文件的属性，不包括文件名）,它的属性如下：这里可以看到inode中存储了数据块的地址(block字段)，再结合文件系统布局图，可以看到一共有15个地址。但为什么要设计成12个direct block以及3个一级、二级、三级间接block呢？（细品这些数据结构） 设计成多级间接block是为了支持大容量的文件：(12 + 1024 + 1024^2 + 1024^3) × 4 KB 设计成12个direct block，是因为大多数文件的大小只有2k，这样就可以直接定位到block，而不用去data block间接查找，提高效率 Ext2目录结构data blocks既可以用于存放文件的数据，也可以用于存放目录的数据.其中目录的数据结构如下： 1234567 struct ext2_dir_entry_2 &#123; __le32 inode; // 文件入口的inode号，0表示该项未使用 __le16 rec_len; // 目录项长度 __u8 name_len; // 文件名包含的字符数 __u8 file_type; // 文件类型 char name[255]; // 文件名 &#125;; 目录数据会保存此目录下的所有文件名和目录名，以及文件的入口地址。至于其他的信息则存放在inode节点中 Fat的布局了解完基于inode组织的文件系统之后，我们再来了解下基于链表组织的Fat文件系统。像SD卡的文件系统一般就是Fat32，在Fat文件系统中对应Ext2 Block的描述是簇。它的磁盘布局如下：其中Fat表的位置由DBR来定位，Fat2是Fat1的备份，而Fat表的数据会读到内存中，它的布局如下：它描述了： 簇的分配情况(0表示没有分配)，因此不存在像bitmap这样的数据结构 文件下一个数据块的簇号，因此不需要类似inode的block字段 但从上面的布局中，我们没有找到用于描述文件信息的元数据，其实这些元信息都存放在目录项中，而目录项的数据又存放在数据块中，因此这里看不到。如果想要实际看看文件系统的结构，可以用WinHex可查看存储介质的二进制数据 Ext4的数据管理方式Ext2、Ext3基于表的方式查找数据块;Fat基于链表的方式查找数据块;而Ext4基于extent tree的方式查找数据块。Ext4的数据布局可以直接参考Ext2的布局，下面我们主要看Ext4是如何查找数据块的。Ext4的inode 同样存在i_block[15] 结构，除了可以用于新的Extent tree结构，还可以兼容老的Ext系统。先看Ext2采用表来查找数据块的问题：如果一个文件分配了连续的1000个块，却需要映射这1000个块的地址。而采用extent的方案，连续地址的映射只需要一个起始地址+长度（ee_len）即可extent tree的访问过程：（图片来源：https://zhuanlan.zhihu.com/p/52052278）从数据结构来看，虽然它的名字叫extent tree，但其实与B-树类似。关于Ext4的详细数据结构信息，可以看最后一节给出的链接地址，这里不再详细介绍。 文件读写的过程看完上面常见文件系统的布局之后，我们还需要清楚open、read等函数背后的IO动作 1.读IO时序假设我们的代码如下： 12int fd = open(&quot;/foo/bar&quot;, O_RDONLY);size = read(fd, buffer, sizeof(buffer)); 它的IO过程如下：假如没有采用任何手段，一句open就要产生5次IO访问，在结合HDD的硬件特性，由于这些block是分散的，因此5次IO意味着5*(Tseek+Trotation),基本上需要50ms以上。 2.写IO时序类似的，写的过程如下： 3.性能优化对于读的性能优化，最常用的方案自然是缓存，通过把常用的inode节点缓存起来，就可以大大的减少访问次数。如前面读IO时序中的图，如果把bar inode节点缓存起来，就可以减少后面3次的读写，而常见的缓存策略自然是LRU。写的性能优化，可以通过缓冲buffer来实现，一般的缓冲的设计从时间与空间角度出发，比方每5s写入磁盘一次，或者buffer满了就写一次磁盘。但buffer应该设计成多大呢？这里我们假设一次Tseek+Trotation的时间是10ms，传输速率为40MB/s如果我们想要达到50%的传输宽带，buffer的大小应该是 40*1024*10/1000 = 409 KB虽然使用缓冲虽然能提高传输效率，但如果突然宕机了，就存在数据丢失的风险。 异常恢复-文件系统一致性文件系统在写入数据时，需要修改多个块数据(bitmap、inode、数据块等)，但这个过程并不是原子的。因此如果在写入的过程中突然宕机，就会产生文件系统不一致的情况，这时候就需要进行修复。这里我们仅讨论对元数据的修复，因此像数据块丢失、不一致的问题可以在数据库事务中再讨论。 1.fsck这是在linux系统中自带的工具，它的原理就是扫描bitmap表和inode table，把它们分别记录在2张表中，如下图A:图A表示数据一致，不需要修复。图B表示实际数据块已经分配，但bitmap表无记录，因此只需要把bitmap表的对应位置0(已用)即可。图D的情况比较复杂，可能是某一个文件X刚删除了一个数据块，同时把bitmap表置1(空闲)，但紧接着另一个文件Y申请到了相同的块，于是又把bitmap置0，但还没来的及修改A的inode就宕机了。这种情况fsck也无法修复，因为不知道这个数据块到底属于谁（这时候可以咨询用户，由用户自己决定）。也有一些问题无法修复，比如inode指向错误的数据块，fsck仅能确保元数据的一致性 2.通过日志恢复通过fsck修复文件系统存在一个问题：太慢了。（之前我做的一个项目就是在SD卡挂载之前调用fsck来恢复文件系统的，导致用户插入SD卡的体验非常差，可能需要等20s才能看到SD卡挂载成功）下面我们介绍ext3、ext4(ext2不支持)文件系统所使用的方法，Write Ahead Log策略：每次更新将数据记录到日志文件中，然后在修改实际数据，如果宕机了，通过日志文件对数据进行恢复。日志的数据格式如下：TxB和TxE表示这条日志的开始和结束，它记录了这条日志的ID。按照上图的格式，如果是先一次性写日志，在写实际数据，这样存在3个问题： 写日志的操作不是原子的，一次性写这条数据，可能出现头和尾都写了，但中间数据缺失，但恢复的时候由于头尾已经存在就认为数据完整，但其实是不完整的。 不停的写日志，日志满了怎么办。 数据要写2次，对磁盘空间的利用率以及性能都有影响。 为了解决第一个问题，我们要对日志的写入(日志的写入也采用缓冲)顺序做调整： 先写TxB + 日志数据 等到步骤1完成，在写入TxE (思路类似于多线程中的内存 barrier) 最后再写入实际的元数据与数据块，这个过程也叫checkpoint 基于这个写入顺序，在恢复的时候，只要看TxB和TxE是否匹配就能知道日志中的数据是否完整，这个过程其实也就是ext3、ext4的journal模式。 第二个问题则可以通过采用环形队列的数据结构来解决:在journal的头部增加一个超级块，在超级块中标记最新的日志和最老的日志（理解成2个指针）,在数据满的情况下，每次新写入的日志都覆盖最老的日志。 最后一个问题我们可以让实际数据的写入最先执行来实现，因为我们的目标是保证元数据的一致性。如果写入了数据块，但元数据没写入，最多也只是丢失本次的数据而已，而不会破坏文件系统的结构。因此，日志写入顺序的最终版本如下： 先写实际的数据，即文件内容 写日志中的TxB + 元数据 必须等到步骤2完成，在写入TxE 更新元数据（实际数据的写入已经在第一步完成） 等步骤4完成之后，更新日志超级块的2个指针（最新和最旧） 用图表示：这个过程就是ext3、ext4的ordered模式（默认的模式，可能还存在一些细微差别） 命令与资料命令： 查看是HDD还是SSD的命令：lsblk -d -o name,rota （1表示HDD，0表示SSD） 查看block size：tune2fs -l /dev/sda1 | grep “Block size”书籍：《Operating Systems: Three Easy Pieces》(线上书籍)《Modern Operating Systems》（第四版） HDD/SSD基础知识及工作原理：https://blog.csdn.net/qq_23929673/article/details/103429583SSD程序员需要知道的SSD基本原理：https://zhuanlan.zhihu.com/p/104995703Ext4的详细信息：https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"花最小的学习成本部署web服务","slug":"pythonOther/deployWeb","date":"2021-07-05T11:51:02.000Z","updated":"2021-07-05T11:51:02.000Z","comments":true,"path":"2021/07/05/pythonOther/deployWeb/","link":"","permalink":"https://liji53.github.io/2021/07/05/pythonOther/deployWeb/","excerpt":"","text":"用httpd给程序搭个web界面当你写完程序，需要做推广时，必不可少的需要有个界面。基于这么一个简单背景，花了5天的时间，给自己的程序搞了个web界面，由于之前没有web的实战经验，又不能花大量精力在学习web上，因此有了这篇学习记录 预备知识主要储备知识还是在前端这块： 了解html、css、js，html和js可以在实际过程中边学边用 了解http协议，主要是出问题的时候，可以抓包快速确定是前端还是后端的问题 了解httpd、cgi，主要是要部署web服务器，以及写后端脚本 总体思路1.明确web做什么既然是花最小的学习成本部署web服务，那就需要清楚页面要做什么事，然后针对性的去学习。例如我这次web要做的是读写后台的配置文件。理想的服务端目录结构是这样的： 12345678&#123; &quot;系统1&quot;:&#123; &quot;子系统1&quot;:&#123; &quot;业务1&quot;:&quot;配置文件1&quot;, &quot;业务2&quot;:&quot;配置文件2&quot; &#125; &#125;&#125; web要修改的就是“配置文件1，配置文件2”。基于这个结构，web页面需要3层导航，分别表示 “系统”、‘’子系统“、“业务”，还需要一个能显示配置，同时能修改配置的地方。 2.找一个静态web页面模板找静态的web页面是为了让我们后续动态生成html有参考模板，同时网上的web页面会比自己从零开始写的要好看，不需要自己搞CSS。 3.部署服务器这里采用httpd作为服务器，使用cgi进行交互。httpd部署过程忽略(建议直接用docker) 4.确定交互协议找到合适的模板，部署好服务之后，就要考虑如何与服务器交互了，一般采用http协议，交互的数据格式为json。具体协议设计忽略 5.动态生成html页面这里主要是通过ajax来动态更新页面。 找静态web页面模板我的情况比较简单，只要能体现3层导航的web页面即可，可以从官网的demo中找 地址：https://getbootstrap.com/docs/5.0/getting-started/download/ 其他专业模板(太高端，没玩过)：https://www.w3cschool.cn/msv2es/qmaj1pyd.html 由于我没有经验，找了1个小时才找到合适的模板，模板长这样： 接着去掉内容，只留下html骨架代码。可以看到三个地方留了id属性，用于后续动态生成html 123456789101112131415161718192021&lt;!-- 最上面的导航 --&gt;&lt;div class=&quot;navbar navbar-fixed-top&quot;&gt; &lt;div class=&quot;navbar-inner&quot;&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;!-- id后面动态生成的时候用到 --&gt; &lt;div class=&quot;nav-collapse&quot; id=&#x27;header_system&#x27;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row-fluid&quot;&gt; &lt;!-- 左边的导航栏 --&gt; &lt;div class=&quot;span3&quot;&gt; &lt;div class=&quot;well sidebar-nav&quot; id=&#x27;left_config&#x27;&gt;&lt;/div&gt; &lt;/div&gt; &lt;!-- 右边配置展示 --&gt; &lt;div class=&quot;span7&quot;&gt; &lt;div style=&quot;padding: 10px 10px 10px;&quot; id=&#x27;right_config&#x27;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 部署服务下载httpd的镜像，启动容器，命令如下： 123456docker pull centos/httpddocker run --name=myHttpd -it -p 192.168.0.1:8089:80 \\ -v /home/liji/apache/html:/var/www/html/ \\ -v /home/liji/apache/cgi-bin:/var/www/cgi-bin/ \\ -v /home/liji/apache/conf:/etc/httpd/conf \\ centos/httpd 修改httpd.conf，前面已经做好路径映射，直接修改/home/liji/apache/conf/httpd.conf 123456&lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None SetHandler cgi-script Options ExecCGI Require all granted&lt;/Directory&gt; 重启httpd容器 1docker restart myHttpd cgi脚本可以用shell，也可以用python， 如果用python则还需要在容器内安装python，可以参考上一篇博客 测试CGI在html中随便加个能发请求的button，用于测试 1&lt;button type=&quot;button&quot; onclick=&quot;cgiHttp(&#x27;test&#x27;)&quot;&gt;测试CGI&lt;/button&gt; js发送请求代码如下： 1234567891011function cgiHttp(func)&#123; url = window.location.href + &#x27;cgi-bin/&#x27; + func + &#x27;.cgi&amp;arg=test&#x27; var request = new XMLHttpRequest() request.onreadystatechange = function() &#123; if (request.readyState==4 &amp;&amp; request.status==200)&#123; alert(request.responseText) &#125; &#125; request.open(&quot;GET&quot;, url, true) request.send(null)&#125; web服务端，在/home/liji/apache/cgi-bin目录下新建test.cgi，内容如下： 12345678import cgi, cgitbimport jsonform = cgi.FieldStorage()# 获取数据site_arg = form.getvalue(&#x27;arg&#x27;)print(&quot;Content-type:text/html&quot;)print()print(&quot;cgi test success! arg = %s&quot; % site_arg) 遇到问题的时候首先抓包，如果返回的是500内部服务错误，直接到/etc/httpd/logs/目录下，查看error_log文件 典型的3种错误有： 1.权限问题 1(13)Permission denied: exec of &#x27;/var/www/cgi-bin/test.cgi&#x27; failed 这种可能是test.cgi 没有执行权限，chmod +x test.cgi 解决 如果你写的cgi脚本需要修改其他目录下的文件，则还需要修改相应目录的权限，参考命令 chown -R apache:apache /home/test 2.执行失败 1(2)No such file or directory: exec of &#x27;/var/www/cgi-bin/previousPick.cgi&#x27; failed 检查test.cgi 是否存在windows字符，这个问题我当时花了半小时才找到。vi -b test.cgi，进入文件看有没有 ^M 字符 3.字符编码 1UnicodeEncodeError: &#x27;ascii&#x27; codec can&#x27;t encode characters in position 4-9: ordinal not in range(128) 这个问题比较恶心，在实际的环境中，脚本需要修改其他目录下的配置文件，而这个目录存在中文，就会报错。我用的是python3.6版本，直接运行脚本不会出错，但用apache用户运行就有问题，即使我在httpd.conf中加入环境变量SetEnv PYTHONIOENCODING utf-8依然没有解决，最后只能不用中文的目录来规避 协议交互假设现在设计了4个协议，对应服务端有4个脚本，分别是getSystem.cgi、getBusiness.cgi、getConfig.cgi、setConfig.cgi，js代码如下： 12345678910111213141516171819202122232425262728/// 根据协议的设计，拼装http请求，为了展示效果不冗余，只拼装1个协议function _get_url(func)&#123; url = window.location.href + &#x27;cgi-bin/&#x27; + func + &#x27;.cgi&#x27; if(func == &#x27;getSystem&#x27;)&#123; url += (&quot;?system=&quot; + g_system) &#125;else&#123; alert(&quot;功能尚未实现，敬请期待！&quot;) return null &#125; return url&#125;function cgiHttp(func)&#123; url = _get_url(func) if (url == null)&#123; return &#125; var request = new XMLHttpRequest() request.onreadystatechange = function() &#123; if (request.readyState==4 &amp;&amp; request.status==200)&#123; response_config = JSON.parse(request.responseText) /// 动态加载html页面 load_func = &#x27;_load&#x27; + func + &#x27;Response(response_config)&#x27; eval(load_func) &#125; &#125; request.open(&quot;GET&quot;, url, true) request.send(null)&#125; 动态更新页面根据前面的协议交互，我们已经能收到服务器的响应了，下面就是拼装html。先确定我们的目标长什么样： 1234567891011&lt;div class=&quot;nav-collapse&quot; id=&quot;header_system&quot;&gt; &lt;ul class=&quot;nav&quot;&gt; &lt;li class=&quot;active&quot; id=&quot;system_system1&quot;&gt; &lt;a onclick=&quot;systemClick(&#x27;system1&#x27;)&quot;&gt;system1&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;disabled&quot; id=&quot;system_system2&quot;&gt; &lt;a onclick=&quot;systemClick(&#x27;system2&#x27;)&quot;&gt;system2&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;disabled&quot; id=&quot;system_system3&quot;&gt; &lt;a onclick=&quot;systemClick(&#x27;system3&#x27;)&quot;&gt;system3&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p class=&quot;navbar-text pull-right&quot;&gt;contract liji37951&lt;/p&gt;&lt;/div&gt; 重点是class=”active” 、 id=”system_system1”、systemClick(‘system1’) 这几个字段是动态的。 1234567891011121314151617function _loadgetSystemResponse(systemConfig)&#123; headerInnerHtml = &#x27;&lt;ul class=&quot;nav&quot;&gt;&#x27; for (var i = 0; i &lt; systemConfig.length; i++)&#123; if (i == 0)&#123; headerInnerHtml += &#x27;&lt;li class=&quot;active&quot;&#x27; g_system = systemConfig[i] &#125;else&#123; headerInnerHtml += &#x27;&lt;li class=&quot;disabled&quot;&#x27; &#125; headerInnerHtml += &#x27; id=&quot;system_&#x27; + systemConfig[i] + &#x27;&quot;&gt;&lt;a onclick=&quot;systemClick(\\&#x27;&#x27; + systemConfig[i] + &#x27;\\&#x27;)&quot;&gt;&#x27; + _toChinese(systemConfig[i])+&#x27;&lt;/a&gt;&lt;/li&gt;&#x27; &#125; headerInnerHtml += &#x27;&lt;/ul&gt;&lt;p class=&quot;navbar-text pull-right&quot;&gt;contract liji&lt;/p&gt;&#x27; document.getElementById(&quot;header_system&quot;).innerHTML=headerInnerHtml&#125; 下面就是实现systemClick这个函数。 123456789function systemClick(system)&#123; if (document.getElementById(&quot;system_&quot;+system).className == &#x27;disabled&#x27;)&#123; document.getElementById(&quot;system_&quot;+g_system).className=&#x27;disabled&#x27; g_system = system document.getElementById(&quot;system_&quot;+system).className=&#x27;active&#x27; cgiHttp(&#x27;getBusiness&#x27;, g_system) cgiHttp(&#x27;getConfig&#x27;, g_business) &#125;&#125; 其他左边的导航栏，右边的配置内容， 方法是一致的。 总结这篇文章，无法直接拷贝代码，帮你完成web的搭建。但我写这篇文章，是为了下次遇到类似问题时提供一个思路，这次花5天时间搞定，下次能2天时间搞定，这就是这篇文章的价值。","categories":[],"tags":[]},{"title":"os-并发","slug":"operatingSystem/os-concurrency","date":"2021-06-29T15:54:28.000Z","updated":"2021-06-29T15:54:28.000Z","comments":true,"path":"2021/06/29/operatingSystem/os-concurrency/","link":"","permalink":"https://liji53.github.io/2021/06/29/operatingSystem/os-concurrency/","excerpt":"","text":"并发 底层原子操作 test-and-set compare-and-swap fetch-and-add load 和 store 互斥锁 1.自旋锁 2.nptl互斥锁的实现 3.futex机制 4.nptl读写锁的实现 5.提高并发性能 条件变量 1.用法 2.生产者-消费者模型 3.nptl的实现 信号量 nptl中的实现 并发问题 Non-Deadlock DeadLock 线程模型 资料 并发在现在的操作系统环境下，进程、线程是并发执行，因此不同的进程、线程之间存在着互相制约的关系，为了协调进程、线程的制约关系，于是有了同步、互斥的概念。先简单过一下相关的概念：同步：线程按照一定的先后顺序来执行互斥：线程不能同时访问有共享资源的代码。原子操作：将多个步骤合成一个操作，这个操作要么成功，要么失败。 底层原子操作我们先从底层实现开始说起，要实现临界区的互斥，即可以通过软件方法(感兴趣的可以了解下peterson算法)，也可以通过硬件方法。当然现代的软件系统基本都是靠硬件来实现的，也就是说计算机提供了特殊的机器指令。 在阅读同步、互斥相关的源码时，我们会经常看到类似atomic_compare_exchange，atomic_fetch_add等类似的函数，其实这些函数就是封装了底层的原子指令。因此熟悉底层原子操作对阅读理解pthread等相关的库十分重要。下面我们看下4种基本的原子操作(不是真的实现，只是用代码的方式表述它的功能) test-and-set返回旧值，设置新值 12345int TestAndSet(int *ptr, int new) &#123; int old = *ptr; // fetch old value at ptr *ptr = new; // store ’new’ into ptr return old; // return the old value&#125; compare-and-swap返回旧值，如果旧值与期望值一致，则设置新值 123456int CompareAndSwap(int *ptr, int expected, int new) &#123; int actual = *ptr; if (actual == expected) *ptr = new; return actual;&#125; fetch-and-add返回旧值，更新值 12345int FetchAndAdd(int *ptr, int add_value) &#123; int old = *ptr; *ptr = old + add_value; return old;&#125; 利用fetch-and-add我们可以实现基于ticket的自旋锁,ticket lock能保证执行顺序，实现先来先拿锁： 12345678910111213141516171819typedef struct __lock_t &#123; int ticket; int turn;&#125; lock_t;void lock_init(lock_t *lock) &#123; lock-&gt;ticket = 0; lock-&gt;turn = 0;&#125;void lock(lock_t *lock) &#123; int myturn = FetchAndAdd(&amp;lock-&gt;ticket, 1); while (lock-&gt;turn != myturn) ; // spin&#125;void unlock(lock_t *lock) &#123; FetchAndAdd(&amp;lock-&gt;turn, 1);&#125; load 和 storeload指每次读最新的值store如果没有人写ptr则更新ptr，并返回成功，否则返回失败 1234567891011int LoadLinked(int *ptr) &#123; return *ptr;&#125;int StoreConditional(int *ptr, int value) &#123; if (如果没有人更新ptr) &#123; *ptr = value; return 1; // success! &#125; else &#123; return 0; // failed to update &#125;&#125; 互斥锁了解了硬件提供的几种原子操作之后，我们可以基于这些原子操作实现一些互斥功能。首先来看下互斥锁，但在了解它的实现之前，我们心中需要有一把尺子来衡量锁的优劣，主要从以下2方面考虑： 公平性，主要看是否可能存在“饥饿”、“饿死”现象 性能，需要结合实际环境来评估，如cpu是否多核，线程数，临界区的长度等 1.自旋锁这个实现比较简单，利用前面的4种原子操作都能实现，如利用compare-and-swap： 1234void lock(lock_t *lock) &#123; while (CompareAndSwap(lock-&gt;flag, 0, 1) == 1) ; // spin&#125; 而它的优劣势也比较明显：从公平性角度来看，无法保证先到先拿锁。从性能角度来看，对于单核cpu来说，采用自旋锁，必然是浪费cpu的，参考虚拟cpu的进程调度但是对于多核的cpu来说，当线程数接近cpu核数，如果临界区很短(立马就释放锁)采用自旋锁，性能将比普通的锁更好(省去了线程切换的开销) 2.nptl互斥锁的实现自旋锁会一直占用cpu，浪费资源，如何让出cpu，让程序更高效。下面我们通过glibc的源码，来看下pthread_mutex实现，pthread_mutex_lock的代码(删除了部分代码)： 1234567891011121314151617181920212223242526272829int __pthread_mutex_lock (pthread_mutex_t *mutex)&#123; // 普通锁 if (type == PTHREAD_MUTEX_TIMED_NP)&#123; LLL_MUTEX_LOCK(mutex); &#125; // 嵌套锁/递归锁，允许同一个线程多次加锁 elif (type == PTHREAD_MUTEX_RECURSIVE_NP)&#123; pid_t id = THREAD_GETMEM(THREAD_SELF, tid); // 获取线程id if (mutex-&gt;__data.__owner == id)&#123;return;&#125; // 已经持有锁直接返回 LLL_MUTEX_LOCK(mutex); &#125; // 适应锁，跟自旋锁类似，尝试获取，但过一段时间仍然获取不到，就放弃，并让出CPU elif (type == PTHREAD_MUTEX_ADAPTIVE_NP)&#123; if (LLL_MUTEX_TRYLOCK (mutex) != 0)&#123; do&#123; // 一直尝试获取 if (++cnt &gt; max_cnt)&#123; // 过一段时间仍然获取不到，则放弃，让出CPU LLL_MUTEX_LOCK(mutex); break; &#125; &#125;while(LLL_MUTEX_TRYLOCK(mutex) != 0); &#125; &#125; // PTHREAD_MUTEX_ERRORCHECK_NP 检错锁，如果一个线程2次获取同一个锁则，返回失败 else&#123; pid_t id = THREAD_GETMEM (THREAD_SELF, tid); if (__glibc_unlikely (mutex-&gt;__data.__owner == id))&#123;return EDEADLK;&#125; LLL_MUTEX_LOCK(mutex); &#125;&#125; 代码展示了4种锁的上层实现策略，而最关键的LLL_MUTEX_LOCK的实现，需要我们先知道futex。 3.futex机制先简单介绍下futex，futex机制在linux2.5.7之后开始使用(fast Userspace mutexes)。它的主要优势是在加锁的时候根据共享内存里的futex变量，判断该变量是否有竞争，如果没有竞争则通过原子操作把共享的futex变量置1，这样不需要进入内核态，就可以完成加锁了。而如果有竞争则执行系统调用futex_wait，将需要等待的进程(线程)加入到futex的等待队列中，直到通过futex_wake进行唤醒。futex的结构维护在内核中.它的数据结构大概如下：futex把线程加入等待队列以及唤醒的基本接口如下： 1234// uaddr代表futex word的地址，val代表这个地址期待的值，当*uaddr==val时，才会进行waitint futex_wait(int *uaddr, int val);// 唤醒n个在uaddr指向的锁变量上挂起等待的进程int futex_wake(int *uaddr, int n); 好了现在我们可以看LLL_MUTEX_LOCK函数的实现了（参考lowlevellock.h）： 1234567891011void LLL_MUTEX_LOCK(pthread_mutex_t *mutex)&#123; // mutex-&gt;__data.__lock 也就是所谓的futex word // 对futex word的操作需要原子操作，如果等于0则置为1，表示没有锁竞争 if（atomic_compare_and_exchange_bool_acq(mutex-&gt;__data.__lock, 0, 1)）&#123; return; &#125; /// 有竞争，则阻塞，加入到futex等待队列 else&#123; futex_wait(mutex-&gt;__data.__lock， 1); &#125;&#125; 了解完futex的机制之后，我们再来评估下pthread_mutex的好坏： 公平性：通过futex来管理等待线程，并不能保证它绝对的唤醒先后顺序，取决于OS的调度策略。 性能：无竞争时，不需要进程(线程)切换，性能极好；但存在锁冲突时，需要线程切换，存在性能浪费，但好在提供了自适应锁这种兼容spin lock优势的参数 4.nptl读写锁的实现在读操作频繁，写操作少的情况下，使用读写锁能提高性能，下面我们看下pthread中读写锁的实现(来自glibc-2.35)： 123456789101112131415161718192021222324252627282930313233343536373839___pthread_rwlock_rdlock (pthread_rwlock_t *rwlock)&#123; ... // 原子操作，让reader + 1 r = (atomic_fetch_add_acquire (&amp;rwlock-&gt;__data.__readers, (1 &lt;&lt; PTHREAD_RWLOCK_READER_SHIFT)) + (1 &lt;&lt; PTHREAD_RWLOCK_READER_SHIFT)); // 如果当前为读阶段(即没有写)，则直接返回成功，不阻塞 if (__glibc_likely ((r &amp; PTHREAD_RWLOCK_WRPHASE) == 0))&#123;return 0;&#125; // 如果处于写阶段，但并没有占有锁 while ((r &amp; PTHREAD_RWLOCK_WRPHASE) != 0 &amp;&amp; (r &amp; PTHREAD_RWLOCK_WRLOCKED) == 0)&#123; // 尝试改成读阶段 if (atomic_compare_exchange_weak_acquire (&amp;rwlock-&gt;__data.__readers, &amp;r, r ^ PTHREAD_RWLOCK_WRPHASE))&#123; // 更新写阶段的futex变量，设置为0意味着解锁 if ((atomic_exchange_relaxed (&amp;rwlock-&gt;__data.__wrphase_futex, 0) &amp; PTHREAD_RWLOCK_FUTEX_USED) != 0)&#123; // 唤醒其他阻塞的读线程 int private = __pthread_rwlock_get_private (rwlock); futex_wake (&amp;rwlock-&gt;__data.__wrphase_futex, INT_MAX, private); &#125; return 0; &#125;else&#123;// 不停的重新尝试&#125; &#125; for (;;) &#123; // 处于写阶段，并且锁已经被其他线程占有 while (((wpf = atomic_load_relaxed (&amp;rwlock-&gt;__data.__wrphase_futex)) | PTHREAD_RWLOCK_FUTEX_USED) == (1 | PTHREAD_RWLOCK_FUTEX_USED)) &#123; int private = __pthread_rwlock_get_private (rwlock); // 如果中途 锁已经释放了 if (((wpf &amp; PTHREAD_RWLOCK_FUTEX_USED) == 0) &amp;&amp; (!atomic_compare_exchange_weak_relaxed (&amp;rwlock-&gt;__data.__wrphase_futex, &amp;wpf, wpf | PTHREAD_RWLOCK_FUTEX_USED))) &#123; continue; // 继续尝试，看锁是否又被写进程占有了 &#125; // futex_wait,加入到futex的等待队列 int err = __futex_abstimed_wait64 (&amp;rwlock-&gt;__data.__wrphase_futex, 1 | PTHREAD_RWLOCK_FUTEX_USED, clockid, abstime, private); &#125; ...&#125; 上面的代码如果理解有困难，可以参考源码标注的对于各种情况下读写锁的各种状态： 12345678910111213141516171819// WP 指的是读阶段还是写阶段，WL 指的是写锁， // R 指的是读的线程数(也代表读锁)， RW 指的是是否有读线程在等待State WP WL R RW Notes---------------------------#1 0 0 0 0 Lock is idle (and in a read phase).#2 0 0 &gt;0 0 Readers have acquired the lock. #3 0 1 0 0 Lock is not acquired; a writer will try to start a write phase. #4 0 1 &gt;0 0 Readers have acquired the lock; a writer is waiting and explicit hand-over to the writer is required. #4a 0 1 &gt;0 1 Same as #4 except that there are further readers waiting because the writer is to be preferred.#5 1 0 0 0 Lock is idle (and in a write phase).#6 1 0 &gt;0 0 Write phase; readers will try to start a read phase (requires explicit hand-over to all readers that do not start the read phase).#7 1 1 0 0 Lock is acquired by a writer.#8 1 1 &gt;0 0 Lock acquired by a writer and readers are waiting; explicit hand-over to the readers is required. 读不占用锁，只有写才占用锁，#3，#4，#4a 这三个阶段 为wrlock加锁的情况，需要等R的个数为0，才能进行写。关于读写锁饿死的情况, 在rdlock源码中并没有看到处理，因此如果写频繁，请不要使用读写锁。最后引用一句话“Big and dumb is better”，无特殊情况，使用普通的锁就可以了。 5.提高并发性能这里仅指优化锁的开销，从而提高并发性能从前面的futex机制中，我们知道如果出现锁冲突，就会有进程(线程)切换的开销(上下文切换、进程调度)，因此如何优化锁，核心在于如何减少锁的冲突： 减少锁的持有时间，在锁的过程中不要使用会阻塞的接口，从时间颗粒度的角度考虑。 减少锁的空间颗粒度，将临界数据打散，每个分散后的临界数据各使用一把锁，代替全局的锁。因为数据分散之后，访问某一个数据的概率就减少了，锁冲突也就减少了。 避免使用锁,使用线程本地存储(比方TLS)。思路就是把临界数据变成线程局部数据，一段时间之后再更新回临界数据中。 在读操作频繁，写操作少的数据结构中，使用读写锁;在临界区短，冲突频繁的场景中使用自旋锁。 放弃用锁，使用wait-free的思路，比方使用无锁的数据结构。 下面针对第二点，我们看下常见的数据结构如何从空间颗粒度角度，减少锁的开销： 双向队列，使用2把锁代替1把锁123456typedef struct __queue_t &#123; node_t *head; node_t *tail; pthread_mutex_t headLock; pthread_mutex_t tailLock;&#125; queue_t; 哈希表，每个哈希桶一把锁，哈希值不冲突就不会存在锁冲突1234typedef struct __hash_t &#123; list_t lists[BUCKETS]; pthread_mutex_t bucketLock[BUCKETS];&#125; hash_t; 针对第三点采用TLS数据，看个多线程计数器的列子：123456789101112131415typedef struct __counter_t &#123; int global; // global count pthread_mutex_t glock; // global lock int local[NUMCPUS]; // 每个线程单独访问，不存在冲突 int threshold; // update frequency&#125; counter_t;void update(counter_t *c, int threadID, int amt) &#123; c-&gt;local[threadID] += amt; // assumes amt &gt; 0 if (c-&gt;local[threadID] &gt;= c-&gt;threshold) &#123; // transfer to global pthread_mutex_lock(&amp;c-&gt;glock); c-&gt;global += c-&gt;local[threadID]; pthread_mutex_unlock(&amp;c-&gt;glock); c-&gt;local[threadID] = 0; &#125;&#125; 条件变量条件变量用于线程的同步，保证线程的先后执行顺序 1.用法条件变量的使用虽然容易犯错，但它的套路其实比较固定： 1234567891011// 场景：A线程先执行，再执行B线程// A线程：Pthread_mutex_lock(&amp;m);设置条件Pthread_cond_signal(&amp;c);Pthread_mutex_unlock(&amp;m);// B线程：Pthread_mutex_lock(&amp;mutex); while (条件不满足) Pthread_cond_wait(&amp;cond, &amp;mutex);Pthread_mutex_unlock(&amp;mutex); 常见的错误就是： 没有和锁一起配合使用，或者锁顺序有问题，牢记条件变量要传锁的原因，即Pthread_cond_wait内部实现： 1.先释放锁，2.加入等待队列，3.唤醒之后再加锁 Pthread_cond_wait在等待条件满足时，要用while 不要用if， Pthread_cond_wait可能存在虚假唤醒(被信号中断唤醒);也有可能同时唤醒2个线程，但另一个线程执行很快，又把值改回去了(ABA) 该使用2个条件变量，却只使用了一个条件变量，参考下面的消费者-生产者的错误案例：123456789101112131415161718192021222324pthread__cond_t cond;pthread__mutex_t mutex;void *producer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // p1 while (count == 1) // p2 Pthread_cond_wait(&amp;cond, &amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(&amp;cond); // p5 Pthread_mutex_unlock(&amp;mutex); // p6 &#125;&#125;void *consumer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(&amp;cond, &amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(&amp;cond); // c5 Pthread_mutex_unlock(&amp;mutex); // c6 &#125;&#125; 这一段代码，如果只有1个消费者和1个生产者没有问题，但如果consumer(消费者)的线程数是2个就有问题了。错误原因：如果consumer1 发出signal ，但唤醒的不是producer，而是consumer2，consumer2由于条件不满足，又睡眠了（并没有发signal），这时候三个线程就将永远睡眠。 2.生产者-消费者模型作为线程同步的最经典的例子，其实真的有必要再三review。该模型正确的代码如下： 123456789101112131415161718192021222324cond_t empty, fill;mutex_t mutex;void *producer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // p1 while (count == MAX) // p2 Pthread_cond_wait(&amp;empty, &amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(&amp;fill); // p5 Pthread_mutex_unlock(&amp;mutex); // p6 &#125;&#125;void *consumer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(&amp;fill, &amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(&amp;empty); // c5 Pthread_mutex_unlock(&amp;mutex); // c6 &#125;&#125; 3.nptl的实现pthread_cond_wait的实现（来自glibc-2.35） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647int __pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)&#123; ... // wseq低位是group的索引，因此需要加2才表示seq加1 uint64_t wseq = __condvar_fetch_add_wseq_acquire (cond, 2); unsigned int g = wseq &amp; 1; // g是group[1]的索引 uint64_t seq = wseq &gt;&gt; 1; // seq 为序列号 // __wrefs 低3位有其他用处，+8 表示等待者计数 +1 unsigned int flags = atomic_fetch_add_relaxed (&amp;cond-&gt;__data.__wrefs, 8); // 【用户锁，解锁】 err = __pthread_mutex_unlock_usercnt (mutex, 0); // 需要唤醒的等待者个数，__g_signals + g表示当前group unsigned int signals = atomic_load_acquire (cond-&gt;__data.__g_signals + g); do&#123; while (1)&#123; // 如果有信号 if (signals != 0) &#123;break;&#125; // __g_refs 当前组的引用计数+1 atomic_fetch_add_acquire (cond-&gt;__data.__g_refs + g, 2); // 【futex_wait 加入等待队列，阻塞】 err = __futex_abstimed_wait_cancelable64 (cond-&gt;__data.__g_signals + g, 0, clockid, abstime, private); // 重新加载信号个数，被唤醒之后，signal有变化 signals = atomic_load_acquire (cond-&gt;__data.__g_signals + g); &#125; &#125; // 当前有需要唤醒的等待者，尝试获取signal while (!atomic_compare_exchange_weak_acquire (cond-&gt;__data.__g_signals + g, &amp;signals, signals - 2)); // 当前group的起始序列号 uint64_t g1_start = __condvar_load_g1_start_relaxed (cond); // 优先消费之前被wait的等待者，而不是本次的等待者 if (seq &lt; (g1_start &gt;&gt; 1))&#123; if (((g1_start &amp; 1) ^ 1) == g)&#123; // 再次更新信号量 unsigned int s = atomic_load_relaxed (cond-&gt;__data.__g_signals + g); while (__condvar_load_g1_start_relaxed (cond) == g1_start)&#123; if (((s &amp; 1) != 0) || atomic_compare_exchange_weak_relaxed(cond-&gt;__data.__g_signals + g, &amp;s, s + 2))&#123; // 优先唤醒其他等待者 futex_wake (cond-&gt;__data.__g_signals + g, 1, private); break; &#125; &#125; &#125; &#125;done: // 【用户锁，加锁】 err = __pthread_mutex_cond_lock (mutex); return (err != 0) ? err : result;&#125; 上面的代码把异常处理、group的处理等都给省去了，即使如此，阅读这个代码可能依然有困难。建议去glibc阅读源码（里面的注释很详细），搞清楚pthread_cond_t的每个字段的含义之后，阅读就轻松多了。其实我们简化成以下伪代码就好理解了： 1234567891011pthread_cond_wait(cond_t* t, mutex_t* m)&#123; unlock(m); if(atomic_load(t-&gt;futex_signal) == 0)&#123; //如果signal为0，则进入等待队列 futex_wait(t-&gt;futex_signal, 0); &#125; lock(m);&#125;pthread_cond_signal(cond_t* t)&#123; atmoic_ftech_and_add(t-&gt;futex_signal，1); // signal 原子加1 futex_wake(t-&gt;futex_var, 1); // 唤醒一个等待者&#125; 信号量nptl中的实现1234567891011121314int __new_sem_post (sem_t *sem)&#123; unsigned int v = atomic_load_relaxed (&amp;isem-&gt;value); do&#123; // 溢出 if ((v &gt;&gt; SEM_VALUE_SHIFT) == SEM_VALUE_MAX)&#123; __set_errno (EOVERFLOW); return -1; &#125; &#125;/// 原子+1，如果有其他post导致value变换，则循环尝试 while (!atomic_compare_exchange_weak_release(&amp;isem-&gt;value, &amp;v, v + (1 &lt;&lt; SEM_VALUE_SHIFT))); // 如果有等待的线程，则唤醒一个线程 if ((v &amp; SEM_NWAITERS_MASK) != 0) futex_wake (&amp;isem-&gt;value, 1, private);&#125; 信号量的源码实现比读写锁、条件变量好理解多了，其实基本上就是对futex封装了一下。 并发问题在多线程项目的开发过程中，我们首先要确认有哪些线程、这些线程的执行顺序是怎么样的、哪些是临界资源，然后才能通过互斥、同步来解决这些问题。很多人可能错误的认为并发问题是指死锁问题，但其实在实际软件项目中，没有考虑前者导致的问题(非死锁导致的问题)比死锁导致的问题更多。 Non-Deadlock下面我们看看，因为我们的不重视而导致的常见的两种非死锁并发问题： 违背原子性：简单来说就是对于临界数据没有加锁 违背执行顺序：在多线程中由于执行顺序不正确导致的问题，需要通过条件变量、信号量来保证同步 这类问题看起来很简单，但解决起来却非常困难，因为不像死锁，你能肉眼看到问题发生，而这类问题你需要对代码很深入的理解才能解决。同时这类问题还具有很强的隐藏性，偶然性。 DeadLock死锁产生的条件与解决方案： 互斥：资源是独占的且排他使用解决（实现复杂）：不使用互斥锁，而采用wait-free的方案。 请求和保持：进程每次申请它所需要的一部分资源，在申请新的资源的同时，继续占用已分配到的资源。解决（会导致性能差）：在线程获取多个锁之前，先加一把大范围的锁。 不可剥夺：进程所获得的资源在未使用完毕之前，不被其他进程强行剥夺，而只能由获得该资源的进程资源释放。解决（可读性差，异常处理复杂）：使用trylock，尝试获取锁，如果获取锁失败，则释放已经占用的锁，从而让其他进程能获取锁，但释放锁的时候需要考虑资源释放与重新申请的问题。 循环等待：比方A进程占用a锁，同时请求b锁，B进程占用b锁，请求a锁，导致AB进程互相等待解决（比较常用的方法）：保持获取锁的顺序一致性。 介绍完死锁的原因以及解决方案之后，我们还是不能杜绝死锁的产生，究其原因，一是因为软件的复杂度很高(组件之间的互相依赖、接口的封装等)，二是所谓的解决方案无法通过技术手段实现。因此从死锁预防的角度来看： 要从提升软件质量上下手，比如适当的接口使用说明、代码评审、测试覆盖以及代码漏洞检测等。 降低软件复杂度，及时对耦合度高、难以理解的模块进行重构。 线程模型下面我们了解下在《Modern Operating Systems》中提到的线程模型：在linux的pthread库中采用的是1对1的线程模型，即一个用户对应一个内核线程，内核负责每个线程的调度，这种一对一的模型存在用户态/内核态切换频繁的问题。因此为提升效率，由用户层实现支持多对一的定时器模型，能提高一定的效率，但这种模型调度的任务不能阻塞，否则会导致其他任务也不能执行。 最后，我们简单总结下进程与线程的区别：进程是资源分配(除cpu)的基本单位，线程是CPU调度的基本单位。线程有独立的线程栈、寄存器。 资料书籍：《Operating Systems: Three Easy Pieces》(线上书籍)《Modern Operating Systems》（第四版：有介绍futex,线程模型）glibc源码地址：http://ftp.gnu.org/gnu/glibc/","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"OS-虚拟memory","slug":"operatingSystem/os-menoryVirtual","date":"2021-06-19T16:42:07.000Z","updated":"2021-06-19T16:42:07.000Z","comments":true,"path":"2021/06/19/operatingSystem/os-menoryVirtual/","link":"","permalink":"https://liji53.github.io/2021/06/19/operatingSystem/os-menoryVirtual/","excerpt":"","text":"虚拟memory我们知道每个进程都有自己的连续内存空间，比方在64位系统中进程的内存布局：让进程误以为自己拥有完整的内存空间，这就是虚拟内存。而实现虚拟内存技术主要从以下几个角度考虑： 透明，不应该让用户进程感知到物理内存（基本功能） 高效，每一条指令都会跟内存打交道，效率是最重要的指标之一 保护，不光是进程间的保护，还包括内部数据的保护比方代码段只读属性 类似虚拟cpu的实现，虚拟内存也需要一些底层机制与上层策略 分页分页是实现虚拟内存的基本机制，简单来说就是把虚拟地址及物理地址分成诺干个固定大小的页(一般4K)，每个页会被OS(或MMU)映射到实际的物理内存，被映射的物理内存页称为页框(page frame)。 1. 页表和页表项承载这个映射关系的数据结构叫做页表(page Table)(数组)，页表的每一项数据即页表项(page table entry)它的结构如下：其中PFN代表page frame number(页框号) 即实际物理地址的页号其他位的含义这里简单介绍下：present bit(P)：表示这个页是否在物理内存中，如果为0表示在硬盘中（缺页用到）accessed bit(A)：表示这个页是否最近被访问（缺页用到）dirty bit(D)：表示这个页是否写入过数据，如果为1则需要定时写入硬盘read/write bit(R/W)：表示这个页是否可写user/supervisor bit(U/S)：表示这个页属于用户模式还是内核模式能访问PWT,PCD,PAT,G：跟硬件缓存相关 2. 如何映射虚拟地址由2部分(后面讲多级页表时再更新)组成： VPN：virtual page number 即虚拟页号 offset：页内偏移 将虚拟地址转为物理地址，如下图(这里假设6位的地址空间，16byte的页大小)：图中Address Translation就是从页表中获取数据得到PFN再进行转换，但这里有2个问题需要搞清楚： Address Translation由谁来完成 页表到底在哪里 现代的操作系统Address Translation一般由MMU这个硬件来完成，我们先来看地址转化的伪代码（这段伪代码后面还会继续完善）： 123456789101112131415161718// 从虚拟地址中提取VPNVPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT// PTBR指的是页表的基地址，PTE指页表项// 从页表中找到当前虚拟地址的页表项的地址PTEAddr = PTBR + (VPN * sizeof(PTE))// 获取当前页表项（注意：这里需要访问内存）PTE = AccessMemory(PTEAddr)// 检查访问的虚拟地址是否合法if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT)else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT)else // 转化成物理地址 offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (PTE.PFN &lt;&lt; PFN_SHIFT) | offset // 访问实际的物理内存 Register = AccessMemory(PhysAddr) 如果Address Translation这个动作由操作系统来完成，意味着每次访问内存都需要2次，性能直接下降了一半以上。而通过MMU则可以缓存常用的页表项，因此大部分时候只需访问一次内存。页表位于内存中，只需要告诉MMU页表的基地址，MMU就可以自动根据VPN计算出页表的偏移从而取到PTE。页表不需要通过虚拟地址映射，由OS告诉硬件页表的物理地址。(在进程切换时，通过设置CR3寄存器来告诉页表地址) 3.遗留问题根据上面的算法，我们的内存管理存在两个严重的问题： 正如前面所说，地址转化的时候需要访问2次内次，效率低下 页表如果采用1维数组的方式实现，在32位系统中1个进程的虚表就占据了4M，而如果是64位系统，则。。。 TLB第一个问题是如何如何让mmu的转化更快，这就需要缓存(TLB)进行帮助. 1.什么时候用缓存我们再来看下上面的伪代码：PTE = AccessMemory(PTEAddr) 如果这次的内存访问，能提前通过硬件缓存起来，这样就能减少一次内存访问了，这就是TLB的作用。缓存作为一种常用技术，它的有效性常常依赖局部性原理： 时间局部性：最近使用的数据大概率再次使用 空间局部性：数据附近的数据很可能被使用 TLB正是基于这2个局部性原理，从而加快页表的查询 2.更新算法现在基于TLB，来更新地址转化的算法： 12345678910111213141516171819202122VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT// 从TLB中查找页表项(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // 缓存命中 if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &lt;&lt; SHIFT) | Offset AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT)else // TLB 没找到 PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else // 更新TLB TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) // 重新执行指令 RetryInstruction() 这个算法中，如果TLB miss，则通过页表查找页表项，找到之后再更新TLB，并重新执行指令。TLB miss的过程其实即可以由MMU完成也可以由OS来完成，比方RISC指令集的MIPS就是通过OS完成的，而像X86这些CISC指令集的架构则通过硬件完成TLB miss因此，如果由OS完成TLB miss，则是以下算法： 12345678910111213VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT// 从TLB中查找页表项(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // 缓存命中 if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &lt;&lt; SHIFT) | Offset AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT)else // TLB 没找到 // 通过产生中断，让OS来查找页表项，并更新TLB RaiseException(TLB_MISS) 3.TLB项TLB其实也是一个数组，一般有32、64或者128项，它的每一项内容如下：VPN：虚拟页号,这里只有19位，因为操作系统的虚拟地址占了一半(MIPS架构)PFN：物理页号，有24位，因此最高可以支持64G的物理内存G：全局共享位，如果为1表示这个虚拟地址被所有进程共享（可以用于共享库）ASID：用于区分哪个进程，OS在进程切换时通过上下文切换，设置ASID的寄存器，这样MMU就能区分进程了。C：内存页是如何被缓存的(跟硬件相关)D：这个内存页是否被写入过V：表示这个页的转化是否合法(PTE的V表示的这个页OS有没有分配) 看到这里，其实我自己有几个未解之谜： 硬件是如何根据VPN来查找TLB entry的？从它的数据结构来看，它需要一项一项的比较才行 ASID只有8位，如果进程超过256个，怎么表示？ 不管如何，TLB作为底层机制，它的核心作用就是缓存部分PTE，从而加快MMU的地址转化 多级页表多级页表用于解决一维线性页表占用内存大的问题。 1.新的数据结构这部分内容个人觉得存粹就是数据结构的知识了，通过增加一层页目录，从而让大部分无用的虚拟地址不在占用页表空间。这里仅仅展示了2级的页表，在实际linux内核中，为了支持64位地址空间，会有4级页表。 2.新的转化由于页表的数据结构改变，因此映射的方式也需要做细微调整。内核在设计时一个页表、页目录的大小应该要刚好等于页大小。这里我们以2级页表、4K页大小、32位地址空间做示例，如果页表项的大小为4byte，则页目录刚好占10位。 它的虚拟地址结构如下：它的MMU地址转化伪代码： 12345678910111213141516171819202122232425VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // TLB Hit ... //参考上一节的代码else // TLB Miss // 页目录的索引 PDIndex = (VPN &amp; PD_MASK) &gt;&gt; PD_SHIFT // 找到对应页目录项 PDEAddr = PDBR + (PDIndex * sizeof(PDE)) PDE = AccessMemory(PDEAddr) if (PDE.Valid == False) RaiseException(SEGMENTATION_FAULT) else // 页表的索引 PTIndex = (VPN &amp; PT_MASK) &gt;&gt; PT_SHIFT // 从页目录项中找到页表的基地址，在加上页内偏移地址，得到页表项的地址 PTEAddr = (PDE.PFN &lt;&lt; SHIFT) + (PTIndex * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() 缺页从前面的分页机制中，我们已经实现了虚拟内存的功能，让用户感知不到物理内存，但物理内存空间毕竟是有限的，如果进程，把物理空间用完了，这怎么办呢？这就需要再制造一个假象，让进程误以为有无穷大的物理内存。内核通过将物理内存的页置换到硬盘，实现这个假象。 缺页处理如果发生TLB miss，并且虚拟地址映射的物理页不存在时(或物理页满)，则需要缺页处理，新的伪代码如下： 123456789101112131415161718VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // TLB Hit ... //参考前面的代码else // TLB Miss PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else if (PTE.Present == True) TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() else if (PTE.Present == False) // 触发缺页中断，由OS处理中断 RaiseException(PAGE_FAULT) 一旦没有找到物理页，硬件就会触发page fault，于是OS就去处理缺页中断，它的伪代码如下： 12345678// 找一个空闲的物理页。PFN = FindFreePhysicalPage()if (PFN == -1) // no free page found PFN = EvictPage() // 通过页置换算法，淘汰页 DiskRead(PTE.DiskAddr, pfn) // 从硬盘中读取代码、数据 PTE.present = True // 表示在物理内存中了 PTE.PFN = PFN // RetryInstruction() // 从新执行指令 前面PTE中提到的present bit在这里终于有用武之地了 页置换策略前面讲了缺页的处理，但哪个内存页置换出去呢？这关乎到进程的内存访问效率，因此页置换算法至关重要。 LRU算法如果OS能知道进程未来需要访问哪个内存页，就可以根据哪个内存页最后使用就把这个页置换出去，这种算法无疑是最好的，但这就跟进程调度算法一样，OS并不知道未来是怎么样的。虽然未来不可知，但我们可以通过历史来推断未来，经典的算法LRU和LFU就是基于历史的使用情况来推断未来的，其实它的思想跟前面讲TLB缓存的局部性思想是一致的。 由于要实现精准的LRU算法，效率往往比较低下，因此一种近似LRU的算法在OS中更加常见：这种算法需要硬件和OS配合，当访问内存页时，由MMU硬件设置页表项的access bit(reference bit)为1，表示这个页最近被访问了。当OS在处理缺页中断时，会遍历环形链表，如果reference bit位为0，则说明最近没有使用，因此可以置换，如上图所示。进一步完善这个算法：如果页面写入过数据，则最好不要置换，因为OS后面会再次把页写入到磁盘，如果加上dirty bit，有以下优先级： reference bit为0，且dirty bit为0。优先级最高 reference btt为0，且dirty bit为1 reference btt为1，且dirty bit为1。优先级最低，需要经过一轮循环之后 参考资料书籍：《Operating Systems: Three Easy Pieces》 线上书籍","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"OS-虚拟CPU","slug":"operatingSystem/os-virtualization","date":"2021-06-15T21:54:20.000Z","updated":"2021-06-15T21:54:20.000Z","comments":true,"path":"2021/06/15/operatingSystem/os-virtualization/","link":"","permalink":"https://liji53.github.io/2021/06/15/operatingSystem/os-virtualization/","excerpt":"","text":"虚拟CPU面试的时候，我们经常会被问道线程与进程的区别(进程是操作系统进行资源分配(除了cpu)的基本单位，线程是进行cpu调度的基本单位)。但这次我不是唠嗑线程与进程的区别，而是聚焦到进程能够实现并发（迷惑我们以为拥有完整cpu）的相关技术-即虚拟CPU。实现虚拟CPU的技术，主要靠几种底层机制(时钟中断、软中断、上下文切换)以及一种上层策略(进程调度策略)来实现。首先我们看下进程的状态转化图(实际不止3种)：这张图里红色的内容就是我们要唠叨的重点了。 进程切换对于进程切换，初学者可能会理所当然的认为是操作系统在管理、切换进程，这当然没错。但是否有过这样的疑问：一个执行中的进程，如果占据了CPU，那操作系统是如何夺回CPU的，要知道CPU只会干“PC=PC+1” 中断计算机靠中断来实现从用户进程到内核的切换，中断在计算机里的重要性无可替代，简单来说中断就是打断运行中的cpu，并告诉cpu先去处理其他紧急的事情。如果继续研究下去，就又产生2个问题，中断是如何打断cpu的，cpu怎么知道要去处理该中断的紧急事件？中断分为： 内中断：系统调用(trap)、各种异常(如缺页、地址越界)等内部事件。 外中断：由外部设备产生的事件，如磁盘完成数据准备，时钟设备的一个时钟周期已到，等等。 1.内中断-系统调用为了能够顺利进入到内核，主要有2种方式(软中断和硬中断)，我们先介绍主动进入内核的办法-系统调用(通过各种异常也能进入)，通过系统调用也解决了上面权限的问题。 之前在《c/c++反汇编》已经对应用层的系统调用汇编代码做过一波分析了。现在我们再简单讲下后面的流程：通过syscall指令使执行逻辑从用户态切换到内核态，在进入到内核态之后，cpu会从指定的寄存器中读取内核代码的入口地址，进入内核代码之后，自然就可以通过rax读取系统调用号，再从system call table转到对应的处理函数中。 到这里我们就会产生一些困惑，因为从用户态到内核态，硬件到底做了什么呢？在《Operating Systems: Three Easy Pieces》写道：硬件会把cpu的模式从用户模式切换到内核模式，同时会保存寄存器到内核栈，但实际呢？其实最好的答案还是亲自到官方上找相应cpu架构的指令集。比方intel，从Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 2B: Instruction Set Reference, M-U这一章节就有syscall的描述 最后我们再来理解下这个流程： 2.时钟中断而另一种被动的进入内核的方法就是时钟中断，一旦时钟中断产生，cpu就会自动运行到内核态，怎么知道去哪里运行内核呢，跟前面的做法一样，在启动时给硬件设置对应的处理时钟中断地址。依靠这个中断，我们就能把进程按照时间段进行切分(进程运行的基本时间单位)，一个进程运行一段时间，然后硬件定时器发生一个时钟中断，于是进程就被动的进入内核，内核再根据调度策略决定下面运行哪个程序，如此反复。简单看下来自xv6的源码： 1234567891011121314151617181920212223timerinit()&#123; ... // prepare information in scratch[] for timervec. // scratch[0..2] : space for timervec to save registers. // scratch[3] : address of CLINT MTIMECMP register. // scratch[4] : desired interval (in cycles) between timer interrupts. uint64 *scratch = &amp;timer_scratch[id][0]; scratch[3] = CLINT_MTIMECMP(id); scratch[4] = interval; // 把定时器的参数写入到mscratch寄存器，timervec中需要读取对应的参数，并设置定时器。 w_mscratch((uint64)scratch); // set the machine-mode trap handler. //在启动时给硬件设置对应的处理时钟中断的地址。 w_mtvec((uint64)timervec); // enable machine-mode interrupts. w_mstatus(r_mstatus() | MSTATUS_MIE); // enable machine-mode timer interrupts. w_mie(r_mie() | MIE_MTIE);&#125; 进程的切换主要靠时钟中断、系统调用，流程图： 上下文切换从上面的进程切换中，我们已经了解底层实现的机制，但我们知道寄存器只有这么一些，切换后进程如何回到一开始的状态呢？上下文切换主要分为2部分(其实还应该包括页表的切换等)： 硬件自动保存的寄存器 当OS决定切换时，手动保存的寄存器 其中通过软件保存的寄存器，我们看下xv6的代码： 123456789101112131415161718192021222324252627.globl swtchswtch: /// a0寄存器保存了c-&gt;context的地址 sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) ... /// a1寄存器保存了p-&gt;context的地址 ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ... ret// Saved registers for kernel context switches.// 上下文的结构体struct context &#123; uint64 ra; uint64 sp; // callee-saved uint64 s0; uint64 s1; ...&#125;;/// 参数1: 当前进程的上下文/// 参数2: 切换进程的上下文swtch(&amp;c-&gt;context, &amp;p-&gt;context); 进程调度策略(MLFQ)在讲调度策略之前，我们需要先了解下OS进行进程切换时根据什么来选择哪个进程： 周转时间： Tturnaround = Tcompletion − Tarrival 响应时间： Tresponse = Tfirstrun − Tarrival 2种基本算法最短作业优先(Shortest Job First):这是一种周转时间最好的算法，它的策略就是根据程序运行时间(最短优先)来决定运行哪个程序，但这种算法有几个问题： OS并不知道进程的运行时长是多少 响应时间长，需要等最短作业的程序运行完，才响应，可能存在饿死现象 轮询调度算法(Round Robin):这种算法就是通过定时器进行时间切片，轮换的切换进程，进程都是平等的。这种算法拥有最好的响应时间与公平性。但它最大的问题就是周转时间太长，每个进程都是最长运行时间 多级反馈队列(现代OS的主流)这种算法就是结合了SJF和RR算法的优点，使程序有较好的周转时间和响应时间。 首先看下这个算法怎么结合SJF算法的：通过对进程进行优先级分类，把进程放到不同的优先级的队列中。再看它怎么结合RR算法的：对于同一优先级的程序，使用RR算法，轮换运行进程，就可保证它们的响应时间因此它的快照长这样：根据这张图，我们得到MLFQ的2条基本规则：一. 如果Ａ的优先级大于Ｂ的优先级，运行Ａ，不运行Ｂ二. 如果Ａ的优先级等于Ｂ的优先级，论转运行Ａ和Ｂ 但之前在讲SJF算法时，它还存在一个问题即OS并不知道进程的运行时间是多长,如果不知道他的运行时间，我们怎么对进程进行分类呢？其实OS会根据观察进程的行为，来动态调整它的优先级．比方如果进程一直占用CPU，OS就认为它的优先级低，而如果一个进程在用完时间片之前就放弃cpu则认为它是高优先级。 因此我们再得到MLFQ的2条基本规则：三. 进程第一次加载，把该进程放在最高优先级四. 如果进程用完时间片则降低优先级；如果没用完就放弃cpu则保持当前优先级 再优化下MLFQ基于上面的MLFQ算法，我们思考下MLFQ这个算法还存在什么问题？ 存在饥饿现象，即如果有很多的高优先级进程，那么低优先级的进程很可能长时间得不到运行 用户可以操控调度器，简单来说就是进程可以在时间片结束之前，假装放弃cpu，从而让进程一直保持在高优先级 我们先来看怎么解决第一个问题，即MLFQ的又一条规则：五. 一段时间之后，将所有进程都放到最高优先级（重置） 例子如图所示： 下面我们再看如何解决第二个问题，这个问题的根源是时间片是固定的，因此进程只要计算出计算片的时长就能利用了，解决办法就是优化第四条规则：四. 给进程分配不固定的时间，一旦进程用完时间，就降低优先级。例子如图所示： MLFQ的进阶如何让MLFQ工作更高效，更公平，这就需要根据环境调整它的参数，主要涉及到以下的参数： 优先级队列的个数 每个队列，分到的时间片长度 多久时间重置进程优先级 这里给出书中提到的solaris系统的参数 60个队列 高先级的进程分到的时间最短20ms，低优先级的进程时间片最长几百毫秒 每隔1秒重置一次进程优先级 参考资料书籍：《Operating Systems: Three Easy Pieces》线上书籍《Modern Operating Systems》（第四版）xv6代码：https://github.com/mit-pdos/xv6-riscv.gitPS：对于新手特别推荐阅读《Operating Systems: Three Easy Pieces》英文原版","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"c/c++反汇编","slug":"compileAssemblyLink/disassembly","date":"2021-06-10T19:51:03.000Z","updated":"2021-06-10T19:51:03.000Z","comments":true,"path":"2021/06/10/compileAssemblyLink/disassembly/","link":"","permalink":"https://liji53.github.io/2021/06/10/compileAssemblyLink/disassembly/","excerpt":"","text":"c/c++反汇编有人说编程的最高境界是人机合一，为了达到这个境界，我们开始学习反汇编，做到写一段代码，脑中就自动反射出相应的汇编代码本文我们分析c/c++常用的语句，看它的汇编代码是怎样的，下面例子都是linux上编译的（对新手来说，直接用vs看反汇编，缺少了思考的过程） 基本语句反汇编编译器不同、优化选项不同会导致生成的汇编代码不一致，接下来的汇编代码是gcc在没有优化的情况下编译出来的。 1.全局变量与局部变量123456789101112131415// 没有指令，编译器会把这个全局变量放到.data段/*Hex dump of section &#x27;.data&#x27;: 0x00601020 00000000 11000000 ........*/int g = 0x11;int main()&#123; // 计算过程：0x4004d1 + 0xa(指令长度) + 0x200b49 = 0x601024（g的地址） /* 指令： 4004d1: c7 05 49 0b 20 00 88 mov DWORD PTR [rip+0x200b49],0x88 # 601024 &lt;g&gt; 4004d8: 00 00 00 */ g = 0x88; // mov DWORD PTR [rbp-0x4],0x1 int a = 1;&#125; 全局变量放在数据段中，在链接时修改引用它的指令的地址，可参考《静态链接》局部变量放在栈中。 2.引用与指针12345678// mov DWORD PTR [rbp-0x14],0x1int a = 1;// lea rax,[rbp-0x14]// mov QWORD PTR [rbp-0x8],raxint* p = &amp;a;// lea rax,[rbp-0x14]// mov QWORD PTR [rbp-0x10],raxint&amp; r = a; 从底层实现来看，引用和指针完全没有区别，引用也占用栈空间。 3.const变量12345678910// mov DWORD PTR [rbp-0x10],0x88const int c = 0x88;// lea rax,[rbp-0x10]// mov QWORD PTR [rbp-0x8],raxint* a= (int*)&amp;c;// mov rax,QWORD PTR [rbp-0x8]// mov DWORD PTR [rax],0x22*a = 0x22;// mov DWORD PTR [rbp-0xc],0x88int b = c; 被const修饰之后的变量其实与普通变量没有任何区别，只不过编译器在遇到const修饰的变量时会直接优化成常量值。 4.if和switch1234567// cmp DWORD PTR [rbp-0x4],0x0// jne 4004e7 &lt;main+0x1a&gt; ; else的地址if(a == 0)&#123;...;&#125;// cmp DWORD PTR [rbp-0x4],0x1// jne 4004f6 &lt;main+0x29&gt; ; else的地址else if(a == 1)&#123;...;&#125;else&#123;...;&#125; 有多少个if分支，就有多少个cmp指令 12345678910111213/*cmp DWORD PTR [rbp-0x4],0x5 ja 400518 &lt;main+0x4b&gt; mov eax,DWORD PTR [rbp-0x4] mov rax,QWORD PTR [rax*8+0x4005b0]*/switch(i)&#123; case 1: ...;break; case 2: ...;break; case 3: ...;break; case 4: ...;break; case 5: ...;break; default: break;&#125; switch 不管case分支多少(根据我的测试要5个分支及以上)，采用数组索引的方式，直接跳转，相比if语句不仅占用空间小，而且耗时上是O(1)的算法。如果case 不连续怎么办？按照《老码识途》所说，自己多动手思考下吧。 5.数组与结构体12345678// mov QWORD PTR [rbp-0x20],0x0// mov QWORD PTR [rbp-0x18],0x0// mov DWORD PTR [rbp-0x10],0x0int a[5] = &#123;0&#125;;// mov DWORD PTR [rbp-0x30],0x1// mov DWORD PTR [rbp-0x2c],0x2typedef struct cStruct&#123;int a; int b;&#125;cStruct;cStruct c = &#123;1,2&#125;; 数组和结构体的内存布局一样，无非就是编译器给我们提供了一个自动求取偏移量的方法。 函数的反汇编每个函数的开头和结尾大部分都有这么一段code（它的含义就不介绍了),应该做到看到类似代码本能的就想到这是一个函数： 123456789101112 push rbp mov rbp,rsp ... pop rbp ret # 或者 push rbp mov rbp,rsp sub rsp,0x10 ... leave ret 1.函数调用1234567891011121314151617181920// 调用方// mov esi,0x4// mov edi,0x2// call 4004cd &lt;add&gt;// mov DWORD PTR [rbp-0x4],eaxint s = add(2, 4);// 被调用函数/* push rbp mov rbp,rsp mov DWORD PTR [rbp-0x4],edi mov DWORD PTR [rbp-0x8],esi mov eax,DWORD PTR [rbp-0x8] mov edx,DWORD PTR [rbp-0x4] add eax,edx pop rbp ret */int add(int a, int b)&#123;return a+b;&#125; 没有亲自动手反汇编之前，或者仅从老的书本了解，你可能以为是通过栈传递参数的。但x86-64通过寄存器传递参数(参数个数小于等于6，超过6个的通过栈传递)。你可能知道这跟fastcall一样，但其实x86-64中只有一种调用约定：调用方清理堆栈。一般你可能要记住： e[r]di 是第一个参数，e[r]si 是第二个参数，剩下的参数用到的时候百度 看到rbp-xxx 的时候，你要知道这是参数，遇到rbp+xxx的时候，知道这是函数内部变量 2.系统调用我们拿mmap做为例子： 1234567891011/* 4005d0: 41 b9 00 00 00 00 mov r9d,0x0 4005d6: 41 b8 ff ff ff ff mov r8d,0xffffffff 4005dc: b9 22 00 00 00 mov ecx,0x22 4005e1: ba 03 00 00 00 mov edx,0x3 4005e6: be 00 00 02 00 mov esi,0x20000 4005eb: bf 00 00 00 00 mov edi,0x0 4005f0: e8 9b fe ff ff call 400490 &lt;mmap@plt&gt; 4005f5: 48 89 45 f8 mov QWORD PTR [rbp-0x8],rax*/char* p=(char*)mmap(0, 128*1024, PROT_READ|PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); 其中&lt;mmap@plt&gt;是什么，可以看我之前写的《动态链接》nmmap的用户层入口在glibc中，通过符号表，找到mmap的地址,并反汇编： 1234567891011121314151617181920[liji@null disassembly]$ readelf -s /usr/lib64/libc.so.6 | grep &quot;mmap&quot; 321: 00000000000f8d10 183 FUNC WEAK DEFAULT 13 mmap64@@GLIBC_2.2.5 661: 00000000000f8d10 183 FUNC WEAK DEFAULT 13 mmap@@GLIBC_2.2.5 874: 00000000000751b0 320 FUNC LOCAL DEFAULT 13 _IO_wfile_underflow_mmap ...[liji@null disassembly]$ objdump -d --start-address=0xf8d10 --stop-address=0xf8e00 /usr/lib64/libc.so.6 -M intel00000000000f8d10 &lt;mmap&gt;: ... # 系统调用号，在unistd.h中定义 f8d43: b8 09 00 00 00 mov eax,0x9 # 系统调用中断，在i386中是 int 80 f8d48: 0f 05 syscall f8d4a: 48 3d 00 f0 ff ff cmp rax,0xfffffffffffff000 f8d50: 77 52 ja f8da4 &lt;mmap+0x94&gt; ... # 设置errno，在多线程中errno是线程局部变量 f8da4: 48 8b 15 a5 e0 2c 00 mov rdx,QWORD PTR [rip+0x2ce0a5] # 3c6e50 &lt;.got+0x100&gt; f8dab: f7 d8 neg eax f8dad: 64 89 02 mov DWORD PTR fs:[rdx],eax ... 系统调用号(mmap的系统调用号是9)放在eax中，其他参数放在其他通用寄存器中(可以百度)，返回值通过rax。关于系统调用的原理，参考这张流程图：《Operating_Systems_Three_Easy_Pieces》 3.类成员函数123456789101112131415struct A&#123; int a; // mov QWORD PTR [rbp-0x8],rdi ; this指针 // mov rax,QWORD PTR [rbp-0x8] ; rax = this // mov DWORD PTR [rax],0x1 ; *this = 1 void func()&#123;a=1;&#125;&#125;;int main()&#123; // mov DWORD PTR [rbp-0x10],0x0 A a = A(); // lea rax,[rbp-0x10] ; rax = &amp;a // mov rdi,rax ; 传参 // call 400520 &lt;_ZN1A4funcEv&gt; a.func();&#125; 从这段汇编代码可以看出：1.编译器不一定给每个类都生成默认构造函数和析构函数；2.类成员函数会隐藏参数this，通过把对象的首地址传进去，从而实现访问对象的数据进一步：类成员函数放在代码段，也就是说每个对象共享这个代码段，对象拥有的是数据的副本 4.虚函数虚函数的反汇编就不在这里分析了，可看《静态链接》对虚表反汇编的分析 c++11新特性的反汇编我们选择比较简单的进行分析，而像std:function、智能指针的反汇编限于篇幅不在本次分析中。反汇编的基础学完之后，大家可以好好利用vs和IDA，因为到目前为止，所有的分析都是静态的，而实际中动态的分析更加实用。 1.右值引用和移动语义记得编译时加上-fno-elide-constructors，强制生成对应的构造函数，否则编译器很可能优化掉无用的构造函数 1234567891011121314151617181920212223242526272829struct A&#123; int* a; A():a(new int(1))&#123;&#125; ~A()&#123;delete a;&#125;/* 400910: mov QWORD PTR [rbp-0x8],rdi # this指针 400914: mov QWORD PTR [rbp-0x10],rsi # right对象的地址 400918: mov edi,0x4 # new的参数 40091d: call 400690 &lt;_Znwm@plt&gt; # operateor new 400922: mov rdx,QWORD PTR [rbp-0x10] 400926: mov rdx,QWORD PTR [rdx] # rdx = *right 400929: mov edx,DWORD PTR [rdx] # edx = right.a 40092b: mov DWORD PTR [rax],edx # new出来的空间 = right.a 40092d: mov rdx,QWORD PTR [rbp-0x8] # 400931: mov QWORD PTR [rdx],rax # this.a = new返回的地址*/ A(const A&amp; right):a(new int(*right.a))&#123;&#125;/* 40093a: mov QWORD PTR [rbp-0x8],rdi # this 40093e: mov QWORD PTR [rbp-0x10],rsi # right 400942: mov rax,QWORD PTR [rbp-0x10] 400946: mov rdx,QWORD PTR [rax] 400949: mov rax,QWORD PTR [rbp-0x8] 40094d: mov QWORD PTR [rax],rdx # a(right.a) 400950: mov rax,QWORD PTR [rbp-0x10] 400954: mov QWORD PTR [rax],0x0 # right.a = nullptr*/ A(A&amp;&amp; right):a(right.a)&#123;right.a = nullptr;&#125;&#125;; 从汇编来看，右值引用与普通引用是一回事，进一步来说如果引动构造函数和拷贝构造函数的实现一样，两者的汇编也一样。 2.lambda匿名函数12345678910111213141516171819/* 400540: mov DWORD PTR [rbp-0x4],0x1 400547: mov eax,DWORD PTR [rbp-0x4] 40054a: mov DWORD PTR [rbp-0x10],eax 40054d: lea rdx,[rbp-0x10] ; 变量s的地址 400551: lea rax,[rbp-0x20] ; lambda对象的地址 400555: mov rsi,rdx 400558: mov rdi,rax 40055b: call 40051e &lt;`_ZZ4mainENUliiE_C1EOS_`&gt; ; 构造函数 400560: lea rax,[rbp-0x20] 400564: mov edx,0x3 400569: mov esi,0x2 40056e: mov rdi,rax 400571: call 4004fe &lt;_ZZ4mainENKUliiE_clEii&gt; ; 仿函数 400576: mov DWORD PTR [rbp-0x8],eax*/int s = 1;auto f = [=](int a, int b)-&gt;int &#123;return s + a + b; &#125;;int c = f(2, 3); 这里调用了2个函数：_ZZ4mainENUliiE_C1EOS_ 和_ZZ4mainENKUliiE_clEii我们用c++filt来看下他们到底是什么？ 1234_ZZ4mainENUliiE_C1EOS_main::&#123;lambda(int, int)#1&#125;::main(&#123;lambda(int, int)#1&#125;&amp;&amp;)_ZZ4mainENKUliiE_clEiimain::&#123;lambda(int, int)#1&#125;::operator()(int, int) const 第一个是构造函数？还是移动构造函数？，第二个是仿函数，下面分别看下它们的实现： 12345678910111213141516171819202100000000004004fe &lt;_ZZ4mainENKUliiE_clEii&gt;: ... 400502: mov QWORD PTR [rbp-0x8],rdi ; this 400506: mov DWORD PTR [rbp-0xc],esi ; 2 400509: mov DWORD PTR [rbp-0x10],edx ; 3 40050c: mov rax,QWORD PTR [rbp-0x8] ; 400510: mov edx,DWORD PTR [rax] ; 捕获的变量s 400512: mov eax,DWORD PTR [rbp-0xc] ; 400515: add edx,eax ; edx=s+2 400517: mov eax,DWORD PTR [rbp-0x10] 40051a: add eax,edx ; eax = edx+3 ...000000000040051e &lt;_ZZ4mainENUliiE_C1EOS_&gt;: ... 400522: mov QWORD PTR [rbp-0x8],rdi ; this 400526: mov QWORD PTR [rbp-0x10],rsi ; 变量s的地址 40052a: mov rax,QWORD PTR [rbp-0x8] 40052e: mov rdx,QWORD PTR [rbp-0x10] 400532: mov edx,DWORD PTR [rdx] ; 值传递捕获变量s 400534: mov DWORD PTR [rax],edx ; 捕获到的变量值放lamdba对象的第一项 ... 看完反汇编，让我们来反推下它的数据结构与实现代码(这部分仅个人猜测的代码，并无验证)： 1234567891011namespace main&#123; class lambdaIntInt&#123; private: int s; public: lambdaIntInt(int cap):s(cap)&#123;&#125; int operator()(int a, int b) const&#123; return s + a + b; &#125; &#125;;&#125; 看到这里，大家应该对编译器实现的lambda已经了然于心，至于lambda的其他用法的原理，大家自己反汇编即可。 3.初始化列表看到现在，我们应该对反汇编已经有点感觉了，因此找了初始化列表做例子(够简单)，通过仅阅读汇编代码，看看能不能猜出对应的数据结构与实现算法 12345678910111213141516171819202122template&lt;class _E&gt;class initializer_list&#123; // 40072e: mov QWORD PTR [rbp-0x8],rdi // 400732: mov rax,QWORD PTR [rbp-0x8] // 400736: mov rax,QWORD PTR [rax+0x8] size_t size(); // 400740: mov QWORD PTR [rbp-0x8],rdi // 400744: mov rax,QWORD PTR [rbp-0x8] // 400748: mov rax,QWORD PTR [rax] const_iterator begin(); //400757: mov QWORD PTR [rbp-0x18],rdi //40075b: mov rax,QWORD PTR [rbp-0x18] //40075f: mov rdi,rax //400762: call 40073c &lt;_ZNKSt16initializer_listIiE5beginEv&gt; //400767: mov rbx,rax //40076a: mov rax,QWORD PTR [rbp-0x18] //40076e: mov rdi,rax //400771: call 40072a &lt;_ZNKSt16initializer_listIiE4sizeEv&gt; //400776: shl rax,0x2 //40077a: add rax,rbx const_iterator end();&#125;; 函数原型已经给出，函数开头和结尾的汇编代码去掉了。看完反汇编代码，可以自己去linux上找源码，注意：vs的实现跟gnu的实现并不一致。 参考资料书籍：《老码识途 从机器码到框架的系统观逆向修炼之路》《C++反汇编与逆向分析技术揭秘》《汇编语言》《程序员的自我修养》","categories":[{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]},{"title":"定制docker镜像","slug":"pythonOther/dockerBuild","date":"2021-06-10T02:38:06.000Z","updated":"2021-06-10T02:38:06.000Z","comments":true,"path":"2021/06/10/pythonOther/dockerBuild/","link":"","permalink":"https://liji53.github.io/2021/06/10/pythonOther/dockerBuild/","excerpt":"","text":"定制docker镜像如果你写出来的应用，领导要求要考虑部署简单、可维护，这时候你应该想到docker，以我工作中的环境为例，部署需要用到httpd、mongodb、svn、python3等。但去hub docker上找相应的镜像，往往只能找到基础镜像，因此需要我们定制自己的镜像 。 准备工作1. 下载docker首先需要下载docker，我的环境是centos 7.6 由于是公司服务器环境，使用curl会连接失败，但好在yum能用 123456sudo yum install -y yum-utils device-mapper-persistent-data lvm2# 更新源地址sudo yum-config-manager --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 安装Docker Engine-Communitysudo yum install docker-ce docker-ce-cli containerd.io 安装完成之后，启动docker 1sudo systemctl start docker 2. 准备基础镜像我选的基础镜像是centos/httpd 1docker pull centos/httpd 但由于环境问题，会出现连接失败，因此需要手动打包镜像 先从能上网的地方下载镜像，比方先在windows上下载镜像，并打包 1234567C:\\Users\\liji&gt;docker pull centos/httpdC:\\Users\\liji&gt;docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 300e315adb2f 6 months ago 209MBliji1211/hexo V1 f03e20ea2889 11 months ago 289MBspurin/hexo latest f03e20ea2889 11 months ago 289MBcentos/httpd latest 2cc07fbb5000 2 years ago 258MB 12# 打包镜像C:\\Users\\liji&gt;docker save -o centos_httpd.tar 2cc07fbb5000 把本地打包的centos_httpd.tar 上传到服务器，并加载镜像 12# 加载镜像docker load -i centos_httpd.tar 定制镜像定制镜像，有2种方法: 第一种是基于基础镜像，在容器中直接修改下载各种软件，然后再把容器保存成镜像即可。另一种是通过Dockerfile来定制镜像，有点像写makefile，最后通过docker build来创建镜像。下面分别介绍： 使用Dockerfile定制 从网上下载mongodb的安装包，放在与Dockerfile同一级目录下 下载地址：https://www.mongodb.com/try/download/community?jmp=nav 新建Dockerfile，文件内容如下： 123456789101112131415161718FROM centos/httpdENV LANG en_US.UTF-8COPY mongodb-org-* /home/RUN mkdir /root/.pip/COPY pip.conf /root/.pip/RUN cd /etc/yum.repos.d/ \\ &amp;&amp; curl -O http://mirrors.aliyun.com/repo/Centos-7.repo \\ &amp;&amp; rm CentOS-Base.repo; mv Centos-7.repo CentOS-Base.repo \\ &amp;&amp; yum makecache; yum clean all; yum makecache; yum -y update \\ &amp;&amp; yum install -y openssl \\ &amp;&amp; yum install -y openssl-devel \\ &amp;&amp; yum install -y python36 \\ &amp;&amp; pip3 install lxml \\ &amp;&amp; yum install -y subversion \\ &amp;&amp; cd /home/ \\ &amp;&amp; rpm -ivh mongodb-org-server-4.0.24-1.el6.x86_64.rpm \\ &amp;&amp; rpm -ivh mongodb-org-shell-4.0.24-1.el6.x86_64.rpm \\ &amp;&amp; mkdir /home/data; mkdir /home/log; touch /home/log/mongod.log Dockerfile命令解释： FROM：指定基础镜像，会先从本地镜像仓库搜索，如果本地没有，则会网上搜索 ENV：设置系统环境变量 RUN：执行在系统里的命令，注意：有多条命令时，尽量写成一条命令 COPY：把本地文件拷贝到镜像里，这里pip.config内容如下 123[global]trusted-host=mirrors.aliyun.comindex-url=http://mirrors.aliyun.com/pypi/simple/ 构建镜像 1docker build -t test:v1 . 至此，一个安装了httpd、python3.6、mongodb、Svn的镜像就完成 手动修改容器镜像 基于前面的准备工作，我们先启动、进入容器 1docker run -it centos/httpd /bin/bash 进入容器之后，首先更新yum源 1234cd /etc/yum.repos.d/ curl -O http://mirrors.aliyun.com/repo/Centos-7.repo rm CentOS-Base.repo -f; mv Centos-7.repo CentOS-Base.repoyum makecache;yum clean all;yum makecache;yum -y update 下载openssl、python3.6、svn 1234yum install -y opensslyum install -y openssl-devel yum install -y python36yum install -y subversion 更新pip源 123456mkdir /root/.pip/cat &gt; /root/.pip/pip.conf &lt;&lt; EOF[global]trusted-host=mirrors.aliyun.comindex-url=http://mirrors.aliyun.com/pypi/simple/EOF 退出容器，按Ctrl+P，再按Ctrl+Q；然后把mongodb的安装包拷贝到容器中 123# 356e587e2f04是容器iddocker cp mongodb-org-server-4.0.24-1.el6.x86_64.rpm 356e587e2f04:/homedocker cp mongodb-org-shell-4.0.24-1.el6.x86_64.rpm 356e587e2f04:/home 再次进入容器，安装mongodb，并启动mongodb 123456789# 进入容器docker exec -it 356e587e2f04 /bin/bash# 安装mongodbcd /home/ rpm -ivh mongodb-org-server-4.0.24-1.el6.x86_64.rpm rpm -ivh mongodb-org-shell-4.0.24-1.el6.x86_64.rpm mkdir /home/data; mkdir /home/log; touch /home/log/mongod.log# 启动mongodb，但一旦重启容器、新建容器，mongodb需要重新启动mongod --dbpath /home/data/ --logpath /home/log/mongod.log --fork 退出容器，并制作镜像 1docker commit 356e587e2f04 test:v2 至此，镜像制作完成 比较2种方式1234[root@null mongo]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest v2 3cd3fd149fd0 45 seconds ago 1.17GBtest v1 150221daf971 4 hours ago 934MB dockerfile的优势： 镜像的体积会更小 可复用","categories":[],"tags":[]},{"title":"动态链接","slug":"compileAssemblyLink/dynamicLd","date":"2021-05-26T20:04:45.000Z","updated":"2021-05-26T20:04:45.000Z","comments":true,"path":"2021/05/26/compileAssemblyLink/dynamicLd/","link":"","permalink":"https://liji53.github.io/2021/05/26/compileAssemblyLink/dynamicLd/","excerpt":"","text":"动态链接静态链接存在2个主要问题：1.内存、磁盘空间浪费严重，每个进程都有自己的独立内存空间，需要对每个共享库都分配内存空间2.更新、发布需要重新编译，假如软件中其中一个库是第三方提供的，一旦更新这个库需要将整个程序重新编译链接。 动态库为了解决上面的两个问题，它的核心思想就是将链接过程推迟到运行时，并且将指令共享给多个进程。 动态库的文件格式首先回看下前文静态链接中给出的一张elf格式图： 1.program header table只有可执行文件和动态库才有这个table，链接时会把相同属性的section合并在一起，合并后就叫segment，这么做的好处是减少内存页的碎片。通过readelf -l [目标文件] 即可查看program header table，如下图：绿色指的是会映射到虚拟内存中 2.interp section 和 INTERP segment首先看下.interp section 是什么？ – 动态链接器的路径 123456789[liji@null dynamic]$ readelf -S a......[ 1] .interp PROGBITS 0000000000400238 00000238 000000000000001c 0000000000000000 A 0 0 1......[liji@null dynamic]$ readelf -x .interp aHex dump of section &#x27;.interp&#x27;: 0x00400238 2f6c6962 36342f6c 642d6c69 6e75782d /lib64/ld-linux- 0x00400248 7838362d 36342e73 6f2e3200 x86-64.so.2. 动态链接器用于程序运行时的重定位，与静态链接器(ld)不是一个东西。动态链接器的位置并不是环境变量决定的，而是由ELF文件决定的，在加载动态链接器时首先会寻找.interp指向的路径。理解了.interp section之后，INTERP segment 其实就是 .interp section。 3.dynamic section通过readelf -d [可执行文件] 即可查看.dynamic段，如下图：dynamic段描述了动态链接时相关的内容，比方动态链接器就是通过该段寻找动态符号表、依赖的动态库通过ldd命令还可以获取到更全的依赖库信息 12345[liji@null dynamic]$ ldd a linux-vdso.so.1 =&gt; (0x00007ffc3751e000) libmy.so =&gt; not found libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fb64b20d000) /lib64/ld-linux-x86-64.so.2 (0x00007fb64b5db000) 4.dynsym 动态符号表 &amp; .dynstr &amp; .rela.xxx这三种section 在静态链接时我们已经讲过类似的了，他们的功能其实差不多。但动态符号表只保存了动态链接相关的符号，而静态符号表则保存了所有的符号与静态符号表一样，动态符号表也需要dynstr(动态符号字符串表辅助)，即符号表只保存符号的索引，实际的内容保存在字符串表。.rela.plt和.rela.dyn重定位表分别用于函数引用的修正和数据引用的修正，如下图：重定位的实现与静态重定位类似，都是从全局符号表中去查找，找到之后，直接修改.got表中的地址(关于got后面再讲) 5.动态库相关的段下面我们梳理下跟动态库相关的section： 名称 属性 含义 .dynamic 动态库的整体信息 .dynstr alloc 用于辅助动态符号表，保存符号的字符串 .dynsym alloc 动态符号表 .got alloc+write 全局偏移表(后面讲) .got.plt alloc+write 全局偏移表，用于plt .interp 记录动态编译器的位置 .plt alloc procedure linkage table(后面讲) .rela.plt 对函数引用的修正，修正.got.plt .rela.dyn 对数据引用的修正，主要修正.got 动态链接的过程文章开头我们提到了静态链接的问题，那么动态链接是如何解决多进程内存共享的呢？ – PIC 1.PIC技术-地址无关代码在生成so的时候，需要加上-fPIC，就是为了生成地址无关代码。它的核心思想是把指令分成需要被修改的，和不需要被修改的，进程间共享的是不需要修改的指令，而需要修改的指令(其实是需要重定位的地址)则放到数据段，并且每个进程都有一个数据段的副本。接下来的问题就是如何进行地址访问，原理看下图：当需要访问外部模块的变量、函数时，通过数据段里的全局偏移表(got)进行间接访问。而got全局偏移表在静态链接时使用-fPIC的时候生成，同时静态链接器会修改引用的全局数据(函数)的地址（修改成引用got表的地址）got存储了需要重定位的地址列表，这个地址列表需要等程序运行由动态链接器进行修正got section以及动态重定位表的内容如下：再次强调下，静态链接中.rela直接修改的是指令和数据段引用的地址，而在动态链接中.rela修改的是got表中的地址列表。这里还有.got.plt 也属于全局偏移表，具体有什么区别等会讲。got表的数据结构类似于c++的虚函数表，只不过c++的虚表在静态链接期间就确定了。 2.PLT技术-延迟绑定动态库也存在缺点，主要是对性能的影响: PIC技术，每次对函数、数据的访问都需要先经过got表，再寻址，相当于中间加了一层 当程序启动时需要动态链接器进行链接，这过程需要装载用到的动态库，然后进行符号查找，并进行重定位。 而PLT技术用于优化第二项，加快启动的速度 ：它的核心思想是当函数第一次被调用的时候才绑定它有专门的section用于实现它的技术，也就是.plt，我们先看它的内存布局图：plt叫过程连接表，你也可以把它理解成一个函数指针数组，每个需要调用的动态库函数都会有自己的plt条目，如上面的printf就叫printf@plt每个plt项它的长度都固定16字节，它靠汇编来实现。汇编代码： 123456789101112131415161718Disassembly of section .plt:0000000000000550 &lt;.plt&gt;: 550: ff 35 b2 0a 20 00 push QWORD PTR [rip+0x200ab2] # .got.plt 的第二项，即moduleid，参数2 556: ff 25 b4 0a 20 00 jmp QWORD PTR [rip+0x200ab4] # .got.plt 的第三项，即_dl_runtime_resolve() 55c: 0f 1f 40 00 nop DWORD PTR [rax+0x0]# printf的入口,第一次调用时printf地址还没确定，需要_dl_runtime_resolve()进行绑定0000000000000560 &lt;printf@plt&gt;: 560: ff 25 b2 0a 20 00 jmp QWORD PTR [rip+0x200ab2] # &lt;printf@GLIBC_2.2.5&gt; 566: 68 00 00 00 00 push 0x0 # 需要决议的函数下标，即.rela.plt的下标，参数1 56b: e9 e0 ff ff ff jmp 550 &lt;.plt&gt;Disassembly of section .plt.got:0000000000000570 &lt;.plt.got&gt;: 570: ff 25 6a 0a 20 00 jmpq *0x200a6a(%rip) # 200fe0 &lt;__gmon_start__&gt; 576: 66 90 xchg %ax,%ax 578: ff 25 7a 0a 20 00 jmpq *0x200a7a(%rip) # 200ff8 &lt;__cxa_finalize@GLIBC_2.2.5&gt; 57e: 66 90 xchg %ax,%ax 来看下它的地址计算过程：560(printf@plt) + 6(指令大小) + rip(当前地址) + 0x200ab2 = 0x201018 + rip(当前地址)550 + 6(指令大小) + rip(当前地址) + 0x200ab2 = 0x201008 + rip(当前地址)556 + 6(指令大小) + rip(当前地址) + 0x200ab4 = 0x201010 + rip(当前地址).got.plt的地址为： 1234[22] .got PROGBITS 0000000000200fd8 00000fd8 0000000000000028 0000000000000008 WA 0 0 8[23] .got.plt PROGBITS 0000000000201000 00001000 0000000000000020 0000000000000008 WA 0 0 8 正好是.got.plt的2，3，4项，而第一项保存了.dynamic段的地址。rela.plt用于修正.got.plt的地址：可以看到它的地址指向.got.plt的第四项 总结现在我们再来看.got 和 .got.plt 的区别：.got 用来保存全局变量的地址以及不需要用plt技术的函数，如__gmon_start__.got.plt 用来保存函数引用的地址对于全局数据的引用，参考这张图： 对于全局函数的引用，参考这张动态图：这个过程比全局数据的引用要复杂的多，因此需要再简单聊下它的过程： 代码段中调用类似printf的动态库函数，汇编：callq 590 &lt;printf@plt&gt; &lt;printf@plt&gt;会跳转到.got.plt的对应项，汇编：jmp QWORD PTR [rip+0x200ab2] 由于第一次运行.got.plt的项为空，因此，&lt;printf@plt&gt;继续执行后面的语句，汇编：jmp 550 &lt;.plt&gt; &lt;.plt&gt; 是.plt的第一项，用于调用_dl_runtime_resolve()，汇编：jmp QWORD PTR [rip+0x200ab4] &lt;_dl_runtime_resolve&gt; _dl_runtime_resolve的实现在ld-xx.so库中，这个函数作用就是根据需要重定位哪个函数(参数)、moduleid(参数)查找全局的动态符号表，查到之后就把函数地址填到.got.plt对应项中。 第二次调用的时候，只需执行1，2步骤即可，后面的无需再执行 内核装载elf的过程1.静态链接程序的装载 2.动态链接程序的装载动态链接器的运行过程： 命令&amp;资料 readelf -l [可执行文件] 查看program header table readelf -d [可执行文件] 查看.dynamic section参考资料书籍：《程序员的自我修养》博客: https://luomuxiaoxiao.com/?p=578","categories":[{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]},{"title":"静态链接","slug":"compileAssemblyLink/staticLd","date":"2021-05-20T14:44:02.000Z","updated":"2021-05-20T14:44:02.000Z","comments":true,"path":"2021/05/20/compileAssemblyLink/staticLd/","link":"","permalink":"https://liji53.github.io/2021/05/20/compileAssemblyLink/staticLd/","excerpt":"","text":"静态链接当程序编译成可执行文件，需要经历4个步骤，预处理，编译，汇编，链接。本文我们来看看静态链接的原理。 elf文件格式elf文件可以分4种，包括可执行文件、可重定位文件(.o .a)、共享目标文件(.so)、核心转储文件(core dump) 1.文件结构一个elf文件由4部分组成，文件头(elf header)、程序头部表(program header table)、节(section)或段(segment)、节区头部表(section header table),如下图：下图描绘了可重定位文件的格式，也是本次讲的重点: 2.elf header通过readelf -h [目标文件] 就可以查看elf文件头，它描绘了整个文件的基本属性。entry point address对于可重定位文件为0；对于可执行文件指向C库中的_start由于可重定位文件没有program header，因此相关的参数都为0 3.section header table通过readelf -S [目标文件] 可以查看完整的信息（通过objdump -h 只能看到重要信息）。它描绘了elf各个section的信息。每个section的name字段，需要通过.shstrtable来获取。同时也可以看到可重定位文件的虚拟地址还没有分配，等链接之后才能确定。 4.sectionsection的数目比较多，也可以自定义section，这里列举了系统保留的重要section，还有其他的section在动态链接的时候再讲 name 属性 含义 .text alloc+exec 代码段 .init alloc+exec 调用mian函数之前执行的代码段，如c++中全局对象的构造函数 .data alloc+write 数据段-初始化的全局数据 .bss alloc+write bss段-未初始化的全局数据，在装载时分配空间，不占文件空间 .rodata alloc 只读数据段 .symtab 符号表 .strtab 字符串表，保存了符号表用到的符号名，如函数名、变量名 .shstrtab section header table的字符串表，保存了section名 .rel.xxx 重定位表，对代码段或数据段需要重定位才有 .line 行号信息，描述了源程序与机器指令之间的对应关系 .note 注释信息 5.符号表符号表作为一项section，在开发中会经常用到，符号的收集一般发生在编译的词法、语法分析阶段。通过readelf -s [目标文件] 即可以查看符号表，如下图：WEAK表示弱符号，指的是那些通过__attribute__((weak))定义的弱符号，未初始化的全局变量也属于弱符号，但显示的是GLOBAL和COM。弱符号可以被定义多次，因此可以用来hook，比方可以hook malloc、new来定位内存问题。COM用于重定位，当存在多个相同名字的弱符号，重定位时以占用空间最大的那个为准。这也可以说明为什么未初始化的全局变量不放在BSS段，因为大小还没有确定，在重定位完成之后，该变量最终还是放到BSS段 静态链接的过程从原理上来讲，链接器的工作就是： 将属性相同的section合并成一个段(这个过程大家自己补脑) 为每个段确定虚拟地址， 把一些指令的地址引用(比方对某一个函数、全局变量的引用)加以修正。 测试的源文件如下: 1234567extern int shared;extern void swap(int* a, int* b);int c = 1;int main()&#123; int a = 100; swap(&amp;a, &amp;shared);&#125; 编译后链接前读取section header table可以看到虚拟地址都是0读取汇编代码之后，可以看到对外部引用的函数与变量地址都为0再次重申编译的工作就是修改上面2张图的地址而编译器也为地址分配做出了贡献，比方确定了定义在源文件中的函数、数据、指令的相对地址(即本文件中的地址) 修正相对地址(地址分配)首先会对属性相同的段进行合并，比方.init和.text进行合并，这里以数据段为例，如下图:在合并的过程中会计算大小、位置，再根据程序的入口地址，以及偏移地址、相对地址就可以确定虚拟地址同时根据已经确定下来的虚拟地址更新符号表(上面符号表一节，我们可以看到符号的地址大部分为0) 引用符号的重定位经过上一步的修正，函数、变量的虚拟地址已经更新到全局符号表了，剩下的就是将引用这些全局变量、函数的地址修正。但链接器怎么知道哪些函数、变量需要修正呢？– 靠重定位表通过objdump -r [目标文件] 我们看下.rel.text重定位表(如果数据段需要修正,则是.rel.data)的内容其中R_X86_64_32 表示通过绝对寻址修正R_X86_64_PC32 通过相对寻址修正 修改之后，结果如下： 流程图最后把自己绘制的流程图献上 实验：c++虚表的内存布局利用上面学的知识，我们现学现用，看下c++虚表比方，有下面源文件： 1234567891011121314151617struct t_base&#123; int a; virtual void f_call()&#123;&#125; virtual void f_show()&#123;&#125;&#125;;struct t_derive:public t_base&#123; void f_call()&#123;a=1;&#125; void f_show()&#123;a=2;&#125;&#125;;int main()&#123; t_base* a = new t_derive(); a-&gt;f_call(); a-&gt;f_show(); t_base* b = new t_base(); b-&gt;f_call(); b-&gt;f_show();&#125; 符号表找函数地址通过符号表，我们看下相关的地址 123456789101112131451: 000000000040074a 37 FUNC WEAK DEFAULT 14 _ZN8t_deriveC2Ev58: 0000000000400870 24 OBJECT WEAK DEFAULT 16 _ZTI8t_derive64: 000000000040071e 21 FUNC WEAK DEFAULT 14 _ZN8t_derive6f_showEv66: 0000000000400820 32 OBJECT WEAK DEFAULT 16 _ZTV8t_derive67: 0000000000400860 10 OBJECT WEAK DEFAULT 16 _ZTS8t_derive68: 0000000000400708 21 FUNC WEAK DEFAULT 14 _ZN8t_derive6f_callEv71: 000000000040074a 37 FUNC WEAK DEFAULT 14 _ZN8t_deriveC1Ev48: 0000000000400890 16 OBJECT WEAK DEFAULT 16 _ZTI6t_base53: 00000000004006fe 10 FUNC WEAK DEFAULT 14 _ZN6t_base6f_showEv60: 0000000000400840 32 OBJECT WEAK DEFAULT 16 _ZTV6t_base61: 0000000000400734 21 FUNC WEAK DEFAULT 14 _ZN6t_baseC2Ev72: 0000000000400888 8 OBJECT WEAK DEFAULT 16 _ZTS6t_base74: 0000000000400734 21 FUNC WEAK DEFAULT 14 _ZN6t_baseC1Ev77: 00000000004006f4 10 FUNC WEAK DEFAULT 14 _ZN6t_base6f_callEv 上面只截取了跟2个类相关的符号表，如果对c++的符号有疑问，可以通过c++filt直接查看源名 123456[liji@null test]$ c++filt _ZTI8t_derivetypeinfo for t_derive[liji@null test]$ c++filt _ZTV8t_derivevtable for t_derive[liji@null test]$ c++filt _ZTS8t_derivetypeinfo name for t_derive 查看数据段内容我们知道虚表是放在数据段的，而虚表在编译期间就已经确定而且只有一份，实际虚表放在.rodata数据段 1234[16] .rodata PROGBITS 0000000000400800 00000800 00000000000000a0 0000000000000000 A 0 0 32[26] .bss NOBITS 0000000000601040 0000102c 00000000000000c0 0000000000000000 WA 0 0 32 通过查看section header table，可以知道.rodata 的起始虚拟地址是0x400800，同时在可执行文件中的偏移位置是0x800，下面我们就从文件的.rodata段中找下有没有虚表通过命令 readelf -x .rodata [目标文件]，也可以通过hexdump 来查看比对符号表中的地址与rodata中数据，可以得出虚表的内存布局。也可以看到在linux上typeinfo位于虚表的第二项（看前面符号表_ZTI8t_derive的地址正是第二项）而且还能看出typeinfo的内存布局(除了第一项指向了bss段不知道以外，后面分别指向类名，父类的typeinfo地址) 反汇编验证最后看下通过汇编c++是如何实现多态的 123456789101112131415161718192021222324252627282930313233...... 400646: mov edi,0x10 ; 给new传参 40064b: call 400530 &lt;_Znwm@plt&gt; ; 调用 operator new 400650: mov rbx,rax ; new的返回值赋值给rbx 400653: mov QWORD PTR [rbx],0x0 ; 给虚函数指针赋值0，构造时才初始化 40065a: mov DWORD PTR [rbx+0x8],0x0 ; 给成员变量a赋值0 400661: mov rdi,rbx ; 给t_derive构造函数传参 400664: call 40074a &lt;_ZN8t_deriveC1Ev&gt; ; 调用t_derive构造函数 400669: mov QWORD PTR [rbp-0x18],rbx ; 对象地址(也是虚表的地址)放入栈中 40066d: mov rax,QWORD PTR [rbp-0x18] ; rax指向对象的首地址 400671: mov rax,QWORD PTR [rax] ; rax指向虚函数表 400674: mov rax,QWORD PTR [rax] ; rax指向虚函数 400677: mov rdx,QWORD PTR [rbp-0x18] ; 40067b: mov rdi,rdx ; 传参this 40067e: call rax ; 调用f_call() 400680: mov rax,QWORD PTR [rbp-0x18] ; rax指向对象的首地址 400684: mov rax,QWORD PTR [rax] ; rax指向虚函数表 400687: add rax,0x8 ; 虚函数表的第二项 40068b: mov rax,QWORD PTR [rax] ; rax指向虚函数 40068e: mov rdx,QWORD PTR [rbp-0x18] 400692: mov rdi,rdx ; 传参this 400695: call rax ; 调用f_show()......000000000040074a &lt;_ZN8t_deriveC1Ev&gt;: ... 400752: mov QWORD PTR [rbp-0x8],rdi ; 参数，即this指针 400756: mov rax,QWORD PTR [rbp-0x8] ; 对象地址赋值给rax 40075a: mov rdi,rax ; 父类构造传参数 40075d: call 400734 &lt;_ZN6t_baseC1Ev&gt; ; 调用父类的构造函数 400762: mov rax,QWORD PTR [rbp-0x8] ; 400766: mov QWORD PTR [rax],0x400830 ; 关键：给虚函数指针赋值， ; 这里的0x400830正是我们之前看到的地址 ... 写的注释已经够详细了，直接下结论：1.虚函数指针指向的是对应类的虚函数表第一项2.虚函数指针由构造函数初始化 命令&amp;参考资料用到的命令 hexdump [目标文件] 查看二进制内容 readelf -h [目标文件] 查看 elf header readelf -S [目标文件] 查看 section header table objdump -d [目标文件] -M intel 查看 .text 的汇编代码 readelf -s [目标文件] 查看符号表 objdump -r [目标文件] 查看重定位表 readelf -x [section名,如.data] [目标文件] 查看指定段的二进制内容参考资料书籍：《程序员的自我修养》博客：https://blog.csdn.net/mergerly/article/details/94585901","categories":[{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]},{"title":"史上最详细-用docker部署博客","slug":"pythonOther/deployBlog","date":"2021-04-27T11:00:44.000Z","updated":"2021-04-27T11:00:44.000Z","comments":true,"path":"2021/04/27/pythonOther/deployBlog/","link":"","permalink":"https://liji53.github.io/2021/04/27/pythonOther/deployBlog/","excerpt":"","text":"用docker，hexo，github部署博客hexo+github的部署教程，网上详细教程一堆。如果你觉得安装node.js、npm以及再用npm安装各种模块(安装后还会有大量的安装残余)不爽，那欢迎参考本次教程。我们将使用docker来封装运行hexo，hexo镜像非自己制作，我们网上下载 预备知识通过本次教程，虽然可以完成搭建，但还是建议多储备点知识，这样在遇到环境差异时，能快速排查问题。 了解docker，会用常用命令；参考：https://www.runoob.com/docker/docker-tutorial.html 了解hexo，会用常用命令；参考：https://hexo.io/zh-cn/docs/ 了解git、github、markdown docker安装这里只讲win10安装docker，其他环境，请参考其他博客，网上资料很多，不怕搞不定 启用Hyper，Hyper是win10自带的虚拟化技术，docker会在Hyper虚拟出来的环境上运行 安装docker，下载地址：https://docs.docker.com/docker-for-windows/install/ 一路next即可 安装完成之后，cmd下执行docker version，如下所示，说明安装成功 1234567891011C:\\Users\\hspcadmin&gt;docker versionClient: Docker Engine - Community Cloud integration: 1.0.12 Version: 20.10.5 API version: 1.41 Go version: go1.13.15 Git commit: 55c4c88 Built: Tue Mar 2 20:14:53 2021 OS/Arch: windows/amd64 Context: default Experimental: true 修改镜像仓库的配置，最好自己申请一个阿里云的镜像，速度最快 docker启动hexohexo的镜像，从Docker官方的公共仓库找，网址：https://hub.docker.com/search?q=hexo 我选的是spurin/hexo (100K+下载量，说明用的人挺多的) 下载spurin/hexo镜像(我已经提前下载，所以打印提示已经是最新版本) 123456C:\\Users\\hspcadmin&gt;docker pull spurin/hexoUsing default tag: latestlatest: Pulling from spurin/hexoDigest: sha256:4f8a4d8133d5b29d60b86782237673511b3c3b2081b767064d2b922b53bc2ef5Status: Image is up to date for spurin/hexo:latestdocker.io/spurin/hexo:latest 创建容器，命令如图所示 12C:\\Users\\hspcadmin&gt;docker create --name=liji53.github.com -e HEXO_SERVER_PORT=4001 -e GIT_USER=&quot;liji53&quot; -e GIT_EMAIL=&quot;liji_1211@163.com&quot; -v E:/blog:/app -p 4001:4001 spurin/hexo666891af8d09cdc0443cfe157c3fcf10ab3f9739e72673cdf201a030c66d4c75 详细参数说明： –name 给容器指定名称，方便多个博客的管理(非必须) -e HEXO_SERVER_PORT 指定hexo server的端口(注意这个是容器内部的hexo server端口) -e GIT_USER github账户的账户名称(必须与github上的账号保持一致，还没有的赶紧注册) -e GIT_EMAIL github的注册email -v 路径映射，把hexo的app文件夹映射到本地 -p 将容器内部使用的网络端口随机映射到我们使用的主机上 启动容器，需要一段时间。会自动初始化hexo、下载依赖的插件、创建SSH密钥等。(启动的打印很多，我这里仅展示部分) 123456789101112C:\\Users\\hspcadmin&gt;docker start liji53.github.com &amp;&amp; docker logs --follow liji53.github.comliji53.github.com***** App directory exists and has content, continuing ********** App directory contains a requirements.txt file, installing npm requirements ********** App .ssh directory exists and has content, continuing ********** Running git config, user = liji53, email = liji_1211@163.com ********** Copying .ssh from App directory and setting permissions ********** Contents of public ssh key (for deploy) - ********** Starting server on port 4001 *****INFO Validating configINFO Start processingINFO Hexo is running at http://localhost:4001 . Press Ctrl+C to stop. 检查–本地预览效果，出现以下图片说明部署成功了 ，网址：http://localhost:4001/ 替换hexo主题hexo的主题，我们用的是hueman，地址：https://github.com/ppoffice/hexo-theme-hueman 进入容器（也可以不进入容器，后续步骤可直接在windows的映射路径上操作） 12C:\\Users\\hspcadmin&gt;docker exec -it liji53.github.com bashroot@666891af8d09:/app# 下载主题 123456789root@666891af8d09:/app/themes# git clone https://github.com/ppoffice/hexo-theme-hueman.git themes/huemanCloning into &#x27;themes/hueman&#x27;...remote: Enumerating objects: 2272, done.remote: Counting objects: 100% (11/11), done.remote: Compressing objects: 100% (11/11), done.remote: Total 2272 (delta 1), reused 2 (delta 0), pack-reused 2261Receiving objects: 100% (2272/2272), 5.77 MiB | 37.00 KiB/s, done.Resolving deltas: 100% (1216/1216), done.Checking out files: 100% (241/241), done. 如果出现下面这个问题(fatal: unable to access ‘https://github.com/ppoffice/hexo-theme-hueman.git/&#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated.) 则该改成 1git clone git://github.com/ppoffice/hexo-theme-hueman.git themes/hueman 修改hueman的默认配置名称 1root@666891af8d09:/app# mv themes/hueman/_config.yml.example themes/hueman/_config.yml 修改hexo的全局配置，使用hueman的主题，在windows上修改，本例的文件路径是E:\\blog\\_config.yml（在容器中修改，没有vim，需要下载，下载命令 apt update &amp;&amp; apt -y install vim） 打开_config.yml，找到theme这一行，改成hueman，其他_config.yml的用法参考官网 https://hexo.io/zh-cn/docs/configuration 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: hueman 检查–本地预览效果，出现以下图片说明部署成功了，网址：http://localhost:4001/ 如果效果不对，试试重启容器，命令： 1docker restart liji53.github.com &amp;&amp; docker logs --follow liji53.github.com 搭建github博客首先，要注册一个github的账号，注册的邮箱必须要验证，这步就不贴图了 创建仓库 仓库的名字必须是username.github.io，其中username是你的用户名 配置SSH Key当你本地写完博客，提交代码时，必须有github权限才可以，直接使用用户名和密码每次都要输入，很不方便。因此我们使用ssh key来解决这个问题 前面搭建docker+hexo的过程中，已经提到hexo容器帮我们生成了ssh密钥，不需要调用ssh-keygen 密钥的路径在本地映射路径下，参考： 记事本打开.ssh\\id_rsa.pub文件，复制里面的内容，打开你的github主页，进入个人设置-&gt;SSH and GPG keys -&gt; New SSH key, 将刚复制的内容粘贴到key哪里，title随便填 用hexo写博客并上传到这一步，环境已经搭建完成了，只剩考虑该写啥了。。。接下来我们简单验证下 在容器环境下，用命令生成文件；在到windows环境下，打开test.md随便写几句 123root@666891af8d09:/app# hexo new testINFO Validating configINFO Created: /app/source/_posts/test.md 进入容器，用hexo生成博客静态网页(会生成public目录，里面就是生成的网页) 1234567891011root@666891af8d09:/app# hexo gINFO Validating configINFO Start processingDeprecated as of 10.7.0. highlight(lang, code, ...args) has been deprecated.Deprecated as of 10.7.0. Please use highlight(code, options) instead.https://github.com/highlightjs/highlight.js/issues/2277INFO Files loaded in 2.6 sINFO Generated: content.jsonINFO Generated: archives/index.htmlINFO Generated: archives/2021/index.htmlINFO Generated: index.html 上传博客(用hexo d命令只会上传public目录，其他不会上传) 123456789root@666891af8d09:/app# hexo dINFO Validating configINFO Start processingDeprecated as of 10.7.0. highlight(lang, code, ...args) has been deprecated.Deprecated as of 10.7.0. Please use highlight(code, options) instead.https://github.com/highlightjs/highlight.js/issues/2277INFO Files loaded in 2.48 sINFO Generated: content.jsonINFO Generated: archives/index.html 检查–网站预览效果 常见问题及参考 github访问慢、访问失败 参考：https://zhuanlan.zhihu.com/p/15893854 博客图片路径加载失败 参考：https://blog.csdn.net/xjm850552586/article/details/84101345 其他参考 https://spurin.com/2020/01/04/Creating-a-Blog-Website-with-Docker-Hexo-Github-Free-Hosting-and-HTTPS/ https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html","categories":[],"tags":[]}],"categories":[{"name":"LLVM","slug":"LLVM","permalink":"https://liji53.github.io/categories/LLVM/"},{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"},{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"},{"name":"密码学","slug":"密码学","permalink":"https://liji53.github.io/categories/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"数据库","slug":"数据库","permalink":"https://liji53.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]}