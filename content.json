{"meta":{"title":"么么博客","subtitle":"","description":"程序猿个人随记","author":"Liji","url":"https://liji53.github.io","root":"/"},"pages":[],"posts":[{"title":"LLVM(1)","slug":"C++Project/LLVM","date":"2022-02-23T02:11:25.000Z","updated":"2022-02-23T02:11:25.000Z","comments":true,"path":"2022/02/23/C++Project/LLVM/","link":"","permalink":"https://liji53.github.io/2022/02/23/C++Project/LLVM/","excerpt":"","text":"Clang Static Analyzer 安装和运行最近在利用业余时间学习和研究代码检查，经过比对了几种代码检查工具之后，决定把Clang Static Analyzer作为学习的对象，原因是开源+扩展性。本文我将重点围绕llvm环境搭建，以及实现第一个static analyzer checker 文档资料学习CSA绕不开LLVM、Clang，好在LLVM的文档非常全面，以下全是官方文档链接：LLVM主页面(有提到三者的关系)：https://llvm.org/LLVM介绍(有跟gcc相比的优势)：https://llvm.org/pubs/2008-10-04-ACAT-LLVM-Intro.htmlLLVM向导(有通过LLVM编写新语言的官方教程)：https://llvm.org/docs/tutorial/index.htmlLLVM开发手册(项目结构等资料)：https://llvm.org/doxygen/Clang主页面：https://clang.llvm.org/Clang文档列表：https://clang.llvm.org/docs/index.htmlClang开发手册：https://clang.llvm.org/doxygen/CSA已有检查项：https://clang.llvm.org/docs/analyzer/checkers.htmlCSA开发教程：https://clang-analyzer.llvm.org/checker_dev_manual.html 除了上面的官方文档，还有这些优秀的文章：CSA开发教程(16年写的，可与上面结合看)：https://github.com/haoNoQ/clang-analyzer-guide/releases/download/v0.1/clang-analyzer-guide-v0.1.pdf符号执行(符号执行的原理、面临的挑战)：https://arxiv.org/pdf/1610.00502.pdf VS中构建LLVM参考资料：https://llvm.org/docs/GettingStartedVS.html 环境准备 Visual Studio 2019+，我用2017的试过，反正构建失败了，于是下载了最新的2022版本 Cmake python3.6+ pip install psutil vs打开LLVM项目 下载LLVM项目： 1git clone https://github.com/llvm/llvm-project.git 用cmake生成vs文件，再用vs代开LLVM.sln文件 12cd llvm-projectcmake -S llvm -B build -DLLVM_ENABLE_PROJECTS=&quot;clang&quot; -DLLVM_TARGETS_TO_BUILD=X86 -DCMAKE_INSTALL_PREFIX=&quot;D:\\Program Files (x86)\\llvm&quot; -Thost=x64 项目内容如下： 编译Clang默认是debug模式，编译clang需要很长时间，建议改成release模式编译完之后会在build目录下生成Debug目录，记得加入到环境变量中 添加第一个检查器参考资料：https://github.com/haoNoQ/clang-analyzer-guide/releases/download/v0.1/clang-analyzer-guide-v0.1.pdf由于参考资料是16年的，里面的例子需要修改才能使用 检查目标c++标准中有这么一条：main函数不应该在程序中被调用。目标代码如下： 123456typedef int (*main_t)(int, char**);int main(int argc, char** argv)&#123; main_t foo = main; int exit_code = foo(argc, argv); // actually calls main()! return exit_code;&#125; 常规的方法可能只能查找显式的调用main，而这个例子中通过函数指针隐式调用mian。 添加checker定义打开llvm-project\\clang\\include\\clang\\StaticAnalyzer\\Checkers\\Checkers.td，在alpha.core包中添加下面内容： 12345678910111213def FixedAddressChecker : Checker&lt;&quot;FixedAddr&quot;&gt;, HelpText&lt;&quot;Check for assignment of a fixed address to a pointer&quot;&gt;, Documentation&lt;HasAlphaDocumentation&gt;;/// addeddef MainCallChecker : Checker&lt;&quot;MainCall&quot;&gt;, HelpText&lt;&quot;Check for calls to main&quot;&gt;, Documentation&lt;HasAlphaDocumentation&gt;;def PointerArithChecker : Checker&lt;&quot;PointerArithm&quot;&gt;, HelpText&lt;&quot;Check for pointer arithmetic on locations other than array &quot; &quot;elements&quot;&gt;, Documentation&lt;HasAlphaDocumentation&gt;; 添加源文件在llvm-project\\clang\\lib\\StaticAnalyzer\\Checkers目录下新增文件MainCallChecker.cpp 123456789101112131415161718192021222324252627282930313233343536373839#include &quot;clang/StaticAnalyzer/Checkers/BuiltinCheckerRegistration.h&quot;#include &quot;clang/StaticAnalyzer/Core/BugReporter/BugType.h&quot;#include &quot;clang/StaticAnalyzer/Core/Checker.h&quot;#include &quot;clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h&quot;#include &quot;clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h&quot;using namespace clang;using namespace clang::ento;namespace &#123;class MainCallChecker : public Checker&lt;check::PreCall&gt; &#123; mutable std::unique_ptr&lt;BugType&gt; BT;public: void checkPreCall(const CallEvent &amp;Call, CheckerContext &amp;C) const;&#125;;&#125;void MainCallChecker::checkPreCall(const CallEvent &amp;Call, CheckerContext &amp;C) const &#123; if (const IdentifierInfo *II = Call.getCalleeIdentifier()) if (II-&gt;isStr(&quot;main&quot;)) &#123; if (!BT) BT.reset(new BugType(this, &quot;Call to main&quot;, &quot;Example checker&quot;)); ExplodedNode *N = C.generateErrorNode(); auto Report = std::make_unique&lt;PathSensitiveBugReport&gt;( *BT, BT-&gt;getDescription(), N); C.emitReport(std::move(Report)); &#125;&#125;void ento::registerMainCallChecker(CheckerManager &amp;Mgr) &#123; Mgr.registerChecker&lt;MainCallChecker&gt;();&#125;bool ento::shouldRegisterMainCallChecker(const CheckerManager &amp;mgr) &#123; return true;&#125; CMakeList中添加编译目标在llvm-project\\clang\\lib\\StaticAnalyzer\\Checkers\\CMakeLists.txt 中添加 123VirtualCallChecker.cppMainCallChecker.cppWebKit/NoUncountedMembersChecker.cpp 测试重新编译之后obj.clangStaticAnalyzerCheckers和clang项目之后，测试 12345PS E:\\code&gt; clang -cc1 -analyze -analyzer-checker=&quot;alpha.core&quot; test.cpp.\\test.cpp:4:18: warning: Call to main [alpha.core.MainCall] int exit_code = foo(argc, argv); // actually calls main ()! ^~~~~~~~~~~~~~~1 warning generated. 可以看到结果，确实正确找到了调用main函数的地方","categories":[],"tags":[]},{"title":"atomic","slug":"C++Basic/atomic","date":"2022-02-04T03:24:16.000Z","updated":"2022-02-04T03:24:16.000Z","comments":true,"path":"2022/02/04/C++Basic/atomic/","link":"","permalink":"https://liji53.github.io/2022/02/04/C++Basic/atomic/","excerpt":"","text":"锁与原子操作在c++11中，其中最大的一个变化就是对多线程的支持，而其中最重要的部分就是引入了原子操作和原子类型。关于锁的机制与原理，可以参考os-并发 C++11的atomic原子类型pthread库的锁(包括信号量、条件变量)通过原子操作来实现的，下面我们结合源码来看看c++11的原子类型是怎么实现的（来自vs的atomic.h） 1. atomic自定义对象必须是POD我们知道atomic&lt;T&gt;的类型可以是自定义对象，但自定义对象是有限制的 123/// 模板类中，有一个静态检查，表示T的类型必须是POD类型static_assert(is_trivially_copyable_v&lt;_Ty&gt; &amp;&amp; is_copy_constructible_v&lt;_Ty&gt; &amp;&amp; is_move_constructible_v&lt;_Ty&gt; &amp;&amp; is_copy_assignable_v&lt;_Ty&gt; &amp;&amp; is_move_assignable_v&lt;_Ty&gt;,&quot;...&quot;) 2. 原子变量不能拷贝，赋值因为两个原子类型之间的操作不能保证原子化 12atomic(const atomic&amp;) = delete;atomic&amp; operator=(const atomic&amp;) = delete; 3. 非atomic_flag不一定无锁除了atomic_flag,其他任何原子类型不一定是无锁的,具体跟平台相关。在本例中，只要是1,2,4,8大小的数据类型，就是无锁 1234_NODISCARD bool is_lock_free() const volatile noexcept &#123; constexpr bool _Result = sizeof(_Ty) &lt;= 8 &amp;&amp; (sizeof(_Ty) &amp; sizeof(_Ty) - 1) == 0; return _Result; &#125; 4. 如果不是无锁的原子类型，其实底层实现就是mutex1234567struct _Atomic_storage &#123; void store(const _TVal _Value, const memory_order _Order = memory_order_seq_cst) noexcept &#123; _Check_store_memory_order(_Order); _Guard _Lock&#123;_Spinlock&#125;; _Storage = _Value; &#125;&#125;； 5. 原子操作_Atomic_storage&lt;_Ty, 8&gt; 指的是数据结构大小为8 的原子类型，由于平台不一样，这里用的是windows接口：_InterlockedExchange64 1234567891011121314151617struct _Atomic_storage&lt;_Ty, 8&gt;&#123; void store(const _TVal _Value) noexcept &#123; // store with sequential consistency const auto _Mem = _Atomic_address_as&lt;long long&gt;(_Storage); const long long _As_bytes = _Atomic_reinterpret_as&lt;long long&gt;(_Value);#if defined(_M_IX86) _Compiler_barrier(); __iso_volatile_store64(_Mem, _As_bytes); _STD atomic_thread_fence(memory_order_seq_cst);#elif defined(_M_ARM64) _Memory_barrier(); __iso_volatile_store64(_Mem, _As_bytes); _Memory_barrier();#else // ^^^ _M_ARM64 / ARM32, x64 vvv (void) _InterlockedExchange64(_Mem, _As_bytes);#endif // _M_ARM64 &#125;&#125;； 6. 赋值运算符的默认内存顺序std::memory_order_seq_cst12345678910111213_Ty operator=(const _Ty _Value) noexcept &#123; this-&gt;store(_Value); return _Value;&#125;void store(const _TVal _Value, const memory_order _Order) noexcept &#123; // store with given memory order ...... switch (_Order) &#123; ...... case memory_order_seq_cst: store(_Value); return; &#125;&#125; 7. compare_exchange_weak和compare_exchange_strong的区别weak的意思是允许偶然出乎意料的返回(比如实际值和期待值一样的时候却返回了false)，通常它比起strong有更高的性能。可惜在vs的这个版本中并没有实现，与strong版本是一样的。 12345bool compare_exchange_weak(_Ty&amp; _Expected, const _Ty _Desired) volatile noexcept &#123; // we have no weak CAS intrinsics, even on ARM32/ARM64, so fall back to strong static_assert(_Deprecate_non_lock_free_volatile&lt;_Ty&gt;, &quot;Never fails&quot;); return this-&gt;compare_exchange_strong(_Expected, _Desired);&#125; 8. atomic_flag的实现atomic_flag 不一定是bool，比方这里就是long类型，atomic_flag一般是符合标准的最小的硬件实现类型，所以一定是无锁的 12345678910111213struct atomic_flag &#123; bool test_and_set(const memory_order _Order = memory_order_seq_cst) noexcept &#123; return _Storage.exchange(true, _Order) != 0; &#125; void clear(const memory_order _Order = memory_order_seq_cst) noexcept &#123; _Storage.store(false, _Order); &#125;#if 1 // TRANSITION, ABI atomic&lt;long&gt; _Storage;#else // ^^^ don&#x27;t break ABI / break ABI vvv atomic&lt;bool&gt; _Storage;#endif // TRANSITION, ABI&#125;; 内存顺序程序实际的执行过程可能与我们写的顺序是不一致的，这个不一致来自2个方面： 编译器可以依情况在不影响程序运行结果的前提下，为提高运行效率，调整执行顺序 弱顺序内存模型的多核处理器不一定按照顺序执行要保证CPU顺序执行，就需要加入内存栅栏，就像大坝一样，需要上面的代码执行完，才能执行后面的代码先看结论吧 结论英文解释：https://en.cppreference.com/w/cpp/atomic/memory_order 内存顺序 说明 std::memory_order_relaxed 同一个线程中, 不同原子变量可以是乱序的 std::memory_order_consume no reads or writes in the current thread dependent on the value currently loaded can be reordered before this load. Writes to data-dependent variables in other threads that release the same atomic variable are visible in the current thread. On most platforms, this affects compiler optimizations only std::memory_order_acquire no reads or writes in the current thread can be reordered before this load. All writes in other threads that release the same atomic variable are visible in the current thread std::memory_order_release no reads or writes in the current thread can be reordered after this store. All writes in the current thread are visible in other threads that acquire the same atomic variable std::memory_order_acq_rel 略 std::memory_order_seq_cst 顺序一致性，所有的线程观察到的整个程序中内存修改顺序是一致的 这部分源码其实根本就没有实现。除了relaxed，其他的内存顺序就是加了内存栅栏 原子类型的使用场景无锁编程无锁编程的优势主要是2个： 避免了死锁、饥饿的产生 临界区非常短、竞争激烈的场景，常见的就是无锁的数据结构，在内存数据库领域用的很多。 参考业界应用：https://www.zhihu.com/question/526298931234567891011121314151617template&lt;class T&gt;struct node&#123; T data; node* next; node(const T&amp; data) : data(data), next(nullptr) &#123;&#125;&#125;;template&lt;class T&gt;struct stack&#123; std::atomic&lt;node&lt;T&gt;*&gt; head; void push(const T&amp; data) &#123; node&lt;T&gt;* new_node = new node&lt;T&gt;(data); new_node-&gt;next = head.load(std::memory_order_relaxed); while (!head.compare_exchange_strong(new_node-&gt;next, new_node, std::memory_order_release)); &#125;&#125;;","categories":[{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"利用lex和yacc做代码检查(上)","slug":"C++Project/lexAndYacc","date":"2022-01-13T09:15:34.000Z","updated":"2022-01-13T09:15:34.000Z","comments":true,"path":"2022/01/13/C++Project/lexAndYacc/","link":"","permalink":"https://liji53.github.io/2022/01/13/C++Project/lexAndYacc/","excerpt":"","text":"利用lex和yacc做代码检查(上)这篇文章我们将使用lex和yacc来对公司代码进行扫描检查。背景：公司的业务代码是用伪代码和c++来实现的，再由开发工具翻译成c++语言，本次我们要代码检查的就是这些伪代码以及c++代码组成的业务代码，然后找出其中的类型不一致等问题。 预备知识以下的预备知识，对于理解lex和yacc的程序是必须的，因此如果不清楚，须先自学 编译原理, 要求理c/c++解编译器的整体流程、理解词法分析、语法分析概述(转): https://blog.csdn.net/cprimesplus/article/details/105724168 正则表达式，主要在lex语法中用到，要求至少能看懂入门：https://liji53.github.io/2021/12/03/regxStudy/ lex和yacc的语法，2者语法结构类似，yacc比lex要复杂一些，先理解清楚lex，再去理解yacc会容易很多lex入门(转)：https://www.cnblogs.com/wp5719/p/5528896.htmllex和yacc小结(转)：https://www.daimajiaoliu.com/daima/4717f8908900400 c语言的语法文件，要求能看懂。 这两个文件是本次语法分析的基础文件，后续代码都在此基础上添加的c语言lex的语法文件：http://www.quut.com/c/ANSI-C-grammar-l-1998.htmlc语言yacc的语法文件：http://www.quut.com/c/ANSI-C-grammar-y-1998.html 本次词法、语法分析的目标公司的业务代码长这个样子，这种[xxx]的写法就是伪代码，其本质是宏。c++部分的语法分析由于我只找到c的语法分析，而且用c的语法分析对接下来的语法解析足够了，因此直接使用最新的The ANSI C grammar(上文已经提到)，这个文件后续作为待测试文件记test.cpp 12345678910111213// 1）函数调用基本写法：[函数名][入参][出参][function_name][parameter1=1, parameter2=&quot;test&quot;][output1=@id]// 2）函数调用多行写法[function_name2][ parameter1=1, parameter2=&quot;test&quot;][]// 3）宏调用写法,&lt;A-Z&gt; 可无&lt;A&gt;[marco][marco][variable][]// c++语法for(int i = 0; i &lt; 10; i++)&#123; variable1 = variable2;&#125; 先熟悉流程这一步我们通过生成c语言的语法分析器，来熟悉lex和yacc的流程。下载http://www.quut.com/c/ANSI-C-grammar-l-1998.html, 命名c.l下载http://www.quut.com/c/ANSI-C-grammar-y-1998.html, 命名c.y 1. 编译词法文件, 会生成lex.yy.c12# 编译词法文件lex c.l 2. 编译语法文件, 会生成y.tab.c, y.tab.h1234567891011121314151617# 直接编译会出现yacc: 1 shift/reduce conflict. 错误，先编辑c.y文件# 2.1 在c.y的序幕部分加以下内容%nonassoc LOWER_THAN_ELSE%nonassoc ELSE# 2.2 在c.y的规则部分selection_statement修改成以下内容selection_statement : IF &#x27;(&#x27; expression &#x27;)&#x27; statement %prec LOWER_THAN_ELSE | IF &#x27;(&#x27; expression &#x27;)&#x27; statement ELSE statement | SWITCH &#x27;(&#x27; expression &#x27;)&#x27; statement ;# 2.3 在c.y的最后，增加main函数int main(void) &#123; yyparse(); return 0;&#125;# 2.4 编译语法文件，其中-d用来生成头文件yacc -d c.y 3. 生成语法分析器, 生成a.out1gcc y.tab.c lex.yy.c 4. 测试词法分析器12345678# 4.1 写一个简单的c文件,带上错误echo &quot;int main()&#123;a=b&#125;&quot; &gt; test.cpp # 4.2 测试下分析器能不能检查出错误./a.out &lt; test.cpp# 4.3 程序输出结果如下，perfectint main()&#123;a=b&#125; ^ syntax error 词法分析lex在这里词法分析主要对上面示例中的1,2,3种写法进行解析，这里需要判断是否是伪代码，并返回伪代码的标记。由于c.l源文件内容较多，这里只贴修改部分代码 1. 在定义部分，增加2个伪代码的状态标志123456789%&#123;#include &lt;stdio.h&gt; #include &quot;y.tab.h&quot;void count(void);int marco_flag = 0; //伪代码状态，与MARCO_HEAD类似,表示除第一个[xxx]以外的状态%&#125;/* 状态（或条件）定义- 用来标志伪代码头,即第一个[xxx]部分的状态 */%s MARCO_HEAD%% 2. 在规则部分，增加伪代码的规则解析MARCO_SYMBOL_BEGIN、MARCO_NAME等需要在c.y中定义。 12345678910111213141516171819202122&quot;&lt;&quot;[A-Z]&quot;&gt;[&quot; &#123;count(); BEGIN MARCO_HEAD; return(MARCO_SYMBOL_BEGIN); &#125;[ \\t]*&quot;[&quot; &#123;count(); BEGIN MARCO_HEAD; return(MARCO_SYMBOL_BEGIN); &#125;&lt;MARCO_HEAD&gt;&#123;L&#125;(&#123;L&#125;|&#123;D&#125;)* &#123;count(); return(MARCO_NAME); &#125;&lt;MARCO_HEAD&gt;&quot;][&quot; &#123;count(); BEGIN INITIAL; marco_flag = 1; return(MARCO_SYMBOL_SPLIT); &#125; &lt;MARCO_HEAD&gt;&quot;]&quot; &#123;/*必须 写在&lt;MARCO_HEAD&gt;&quot;][&quot; 之后*/ count(); BEGIN INITIAL; return(MARCO_SYMBOL_END); &#125; &lt;MARCO_HEAD&gt;[ \\t\\v\\n\\f] &#123;count(); &#125;&lt;MARCO_HEAD&gt;. &#123;/* ECHO是一个宏，相当于 fprintf(yyout, &quot;%s&quot;, yytext)*/ ECHO; &#125; &quot;]&quot; &#123; count(); if(marco_flag)&#123; if(input() == &#x27;[&#x27;)&#123; return (MARCO_SYMBOL_SPLIT); &#125; else&#123; marco_flag = 0; return (MARCO_SYMBOL_END); &#125; &#125; else&#123; return(&#x27;]&#x27;); &#125; &#125; 这部分代码至少要放在下面代码之前，否则会因为规则的先后匹配错误 12(&quot;[&quot;|&quot;&lt;:&quot;) &#123; count(); return(&#x27;[&#x27;); &#125;(&quot;]&quot;|&quot;:&gt;&quot;) &#123; count(); return(&#x27;]&#x27;); &#125; 测试lex正确性最后我们测试下词法分析器的正确性，待测试文件即上文提到的test.cpp 1. 在c.y中定义部分添加宏定义后面只用到了c.y生成的头文件 1%token MARCO_SYMBOL_BEGIN MARCO_SYMBOL_SPLIT MARCO_SYMBOL_END MARCO_NAME 2. 在c.l中添加main函数123456789101112131415161718192021222324252627void writeout(int c)&#123; switch(c)&#123; case MARCO_SYMBOL_BEGIN: fprintf(yyout, &quot;(MARCO_SYMBOL_BEGIN, \\&quot;%s\\&quot;) &quot;, yytext);break; case MARCO_SYMBOL_SPLIT: fprintf(yyout, &quot;(MARCO_SYMBOL_SPLIT, \\&quot;%s\\&quot;) &quot;, yytext);break; case MARCO_SYMBOL_END: fprintf(yyout, &quot;(MARCO_SYMBOL_END, \\&quot;%s\\&quot;) &quot;, yytext);break; case MARCO_NAME: fprintf(yyout, &quot;(MARCO_NAME, \\&quot;%s\\&quot;) &quot;, yytext);break; case IDENTIFIER: fprintf(yyout, &quot;(IDENTIFIER, \\&quot;%s\\&quot;) &quot;, yytext);break; case CONSTANT: fprintf(yyout, &quot;(CONSTANT, \\&quot;%s\\&quot;) &quot;, yytext);break; case STRING_LITERAL: fprintf(yyout, &quot;(STRING_LITERAL, \\&quot;%s\\&quot;) &quot;, yytext);break; case SIZEOF: fprintf(yyout, &quot;(SIZEOF, \\&quot;%s\\&quot;) &quot;, yytext);break; default:break; &#125;&#125;int main (int argc, char ** argv)&#123; int c; if (argc&gt;=2)&#123; if ((yyin = fopen(argv[1], &quot;r&quot;)) == NULL)&#123; printf(&quot;Can&#x27;t open file %s\\n&quot;, argv[1]); return -1; &#125; while (c = yylex())&#123; writeout(c); &#125; fclose(yyin); &#125; return 0;&#125; 3. 编译词法分析器1lex lex.l &amp;&amp; yacc -d yacc.y &amp;&amp; gcc lex.yy.c 4. 测试test.cpp12345678910111213[liji@null test_compile]$ ./a.out test.cpp[(MARCO_SYMBOL_BEGIN, &quot;[&quot;) function_name(MARCO_NAME, &quot;function_name&quot;) ][(MARCO_SYMBOL_SPLIT, &quot;][&quot;) parameter1(IDENTIFIER, &quot;parameter1&quot;) =1(CONSTANT, &quot;1&quot;) , parameter2(IDENTIFIER, &quot;parameter2&quot;) =&quot;test&quot;(STRING_LITERAL, &quot;&quot;test&quot;&quot;) ](MARCO_SYMBOL_SPLIT, &quot;]&quot;) output1(IDENTIFIER, &quot;output1&quot;) =id(IDENTIFIER, &quot;id&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) [(MARCO_SYMBOL_BEGIN, &quot;[&quot;) function_name2(MARCO_NAME, &quot;function_name2&quot;) ][(MARCO_SYMBOL_SPLIT, &quot;][&quot;) parameter1(IDENTIFIER, &quot;parameter1&quot;) =1(CONSTANT, &quot;1&quot;) , parameter2(IDENTIFIER, &quot;parameter2&quot;) =&quot;test&quot;(STRING_LITERAL, &quot;&quot;test&quot;&quot;) ](MARCO_SYMBOL_SPLIT, &quot;]&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) &lt;A&gt;[(MARCO_SYMBOL_BEGIN, &quot;&lt;A&gt;[&quot;) marco(MARCO_NAME, &quot;marco&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) [(MARCO_SYMBOL_BEGIN, &quot;[&quot;) marco(MARCO_NAME, &quot;marco&quot;) ][(MARCO_SYMBOL_SPLIT, &quot;][&quot;) xxx(IDENTIFIER, &quot;xxx&quot;) ](MARCO_SYMBOL_SPLIT, &quot;]&quot;) ](MARCO_SYMBOL_END, &quot;]&quot;) for(int i(IDENTIFIER, &quot;i&quot;) = 0(CONSTANT, &quot;0&quot;) ; i(IDENTIFIER, &quot;i&quot;) &lt; 10(CONSTANT, &quot;10&quot;) ; i(IDENTIFIER, &quot;i&quot;) ++)&#123; variable1(IDENTIFIER, &quot;variable1&quot;) = variable2(IDENTIFIER, &quot;variable2&quot;) ; 从上文的第7行， ](MARCO_SYMBOL_SPLIT, “]”)这个内容其实是有问题的。 因为在规则部分，处理”]”的时候，用到了input()来判断下个字符是不是”[“， 因此yytext的值是”]”，其实应该是”][“","categories":[],"tags":[]},{"title":"smart_ptr","slug":"C++Basic/smart-ptr","date":"2022-01-08T21:48:07.000Z","updated":"2022-01-08T21:48:07.000Z","comments":true,"path":"2022/01/08/C++Basic/smart-ptr/","link":"","permalink":"https://liji53.github.io/2022/01/08/C++Basic/smart-ptr/","excerpt":"","text":"智能指针的实现shared_ptr 的实现我们都知道靠引用计数，但引用计数的生命周期是怎么样的，智能指针是否线程安全，weak_ptr是否需要计数？现在我们通过阅读源码，来一探究竟。 shared_ptr的实现代码来自vs的memory.h,用的是c++14标准 构造函数(c++11动态数组，需要显式提供delete functor)在vs中神奇的发现c++17才支持的动态数组，c++14就支持了 12345678910111213141516171819202122template &lt;class _Ty&gt;class shared_ptr : public _Ptr_base&lt;_Ty&gt; &#123; explicit shared_ptr(_Ux* _Px) &#123; // construct shared_ptr object that owns _Px /// 已经能自动选择数组类型的删除器 if constexpr (is_array_v&lt;_Ty&gt;) &#123; _Setpd(_Px, default_delete&lt;_Ux[]&gt;&#123;&#125;); &#125; else &#123; _Temporary_owner&lt;_Ux&gt; _Owner(_Px); /// 由于shared_ptr的生命周期随时可以结束，因此引用计数器必须是在heap上 _Set_ptr_rep_and_enable_shared(_Owner._Ptr, new _Ref_count&lt;_Ux&gt;(_Owner._Ptr)); _Owner._Ptr = nullptr; &#125; &#125; _NODISCARD _Elem&amp; operator[](ptrdiff_t _Idx) const noexcept /* strengthened */ &#123; return get()[_Idx]; &#125;&#125;；// 测试std::cout &lt;&lt; __cplusplus &lt;&lt; std::endl; // 201402std::shared_ptr&lt;int[]&gt; p_list(new int[4]&#123; 1,2,3,4 &#125;); // 本来应该在c++17中才支持的std::cout &lt;&lt; p_list[1] &lt;&lt; std::endl; // 2，同上 拷贝构造/移动构造函数/赋值移动系列的函数，会使原shared_ptr变成空指针赋值会使原shared_ptr引用计数减一 12345678910111213141516171819202122shared_ptr(const shared_ptr&amp; _Other) noexcept &#123; // construct shared_ptr object that owns same resource as _Other this-&gt;_Copy_construct_from(_Other);&#125;void _Copy_construct_from(const shared_ptr&lt;_Ty2&gt;&amp; _Other) noexcept &#123; // implement shared_ptr&#x27;s (converting) copy ctor _Other._Incref(); _Ptr = _Other._Ptr; _Rep = _Other._Rep;&#125;void _Move_construct_from(_Ptr_base&lt;_Ty2&gt;&amp;&amp; _Right) noexcept &#123; // implement shared_ptr&#x27;s (converting) move ctor and weak_ptr&#x27;s move ctor _Ptr = _Right._Ptr; _Rep = _Right._Rep; _Right._Ptr = nullptr; _Right._Rep = nullptr;&#125;/// 减一是因为shared_ptr(_Right)是个临时变量，在swap出作用域之后就析构shared_ptr&amp; operator=(const shared_ptr&lt;_Ty2&gt;&amp; _Right) noexcept &#123; shared_ptr(_Right).swap(*this); return *this;&#125; weak_ptr的实现weak_ptr 类型指针不会导致堆内存空间的引用计数增加或减少。另外weak_ptr没有实现operator-&gt;和operator* 构造函数12345678910111213141516171819template &lt;class _Ty&gt;class weak_ptr : public _Ptr_base&lt;_Ty&gt; &#123; weak_ptr(const weak_ptr&amp; _Other) noexcept &#123; this-&gt;_Weakly_construct_from(_Other); // same type, no conversion &#125; weak_ptr(const shared_ptr&lt;_Ty2&gt;&amp; _Other) noexcept &#123; this-&gt;_Weakly_construct_from(_Other); // shared_ptr keeps resource alive during conversion &#125; /// 不增加shared_ptr的引用计数，增加weak_ptr的引用计数 void _Weakly_construct_from(const _Ptr_base&lt;_Ty2&gt;&amp; _Other) noexcept &#123; // implement weak_ptr&#x27;s ctors if (_Other._Rep) &#123; _Ptr = _Other._Ptr; _Rep = _Other._Rep; _Rep-&gt;_Incwref(); &#125; else &#123; _STL_INTERNAL_CHECK(!_Ptr &amp;&amp; !_Rep); &#125; &#125;&#125; lock函数123456789101112131415_NODISCARD shared_ptr&lt;_Ty&gt; lock() const noexcept &#123; // convert to shared_ptr shared_ptr&lt;_Ty&gt; _Ret; (void) _Ret._Construct_from_weak(*this); return _Ret;&#125;bool _Construct_from_weak(const weak_ptr&lt;_Ty2&gt;&amp; _Other) noexcept &#123; // implement shared_ptr&#x27;s ctor from weak_ptr, and weak_ptr::lock() if (_Other._Rep &amp;&amp; _Other._Rep-&gt;_Incref_nz()) &#123; _Ptr = _Other._Ptr; _Rep = _Other._Rep; return true; &#125; return false;&#125; 引用计数通过前面的源码大家也可以看出来，shared_ptr和weak_ptr在交换指针时并不是线程安全的，但引用计数却是线程安全的shared_ptr的引用计数为0，管理的对象可以销毁，但引用计数对象可能仍然存在，需要weak_ptr的引用计数也为0，才销毁 接口与成员变量12345678910111213141516171819202122232425262728#define _MT_INCR(x) _INTRIN_RELAXED(_InterlockedIncrement)(reinterpret_cast&lt;volatile long*&gt;(&amp;x))#define _MT_DECR(x) _INTRIN_ACQ_REL(_InterlockedDecrement)(reinterpret_cast&lt;volatile long*&gt;(&amp;x))class __declspec(novtable) _Ref_count_base &#123; virtual void _Destroy() noexcept = 0; // destroy managed resource virtual void _Delete_this() noexcept = 0; // destroy self _Atomic_counter_t _Uses = 1; _Atomic_counter_t _Weaks = 1;/// 原子操作 void _Incref() noexcept &#123; // increment use count _MT_INCR(_Uses); &#125; void _Incwref() noexcept &#123; // increment weak reference count _MT_INCR(_Weaks); &#125;/// shared_ptr的引用计数为0，则释放资源对象 void _Decref() noexcept &#123; // decrement use count if (_MT_DECR(_Uses) == 0) &#123; _Destroy(); _Decwref(); &#125; &#125;/// 只有weak_ptr的引用计数为0，才释放引用计数 void _Decwref() noexcept &#123; // decrement weak reference count if (_MT_DECR(_Weaks) == 0) &#123; _Delete_this(); &#125; &#125;&#125;;","categories":[{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"正则表达式入门","slug":"pythonOther/regxStudy","date":"2021-12-03T02:22:13.000Z","updated":"2021-12-03T02:22:13.000Z","comments":true,"path":"2021/12/03/pythonOther/regxStudy/","link":"","permalink":"https://liji53.github.io/2021/12/03/pythonOther/regxStudy/","excerpt":"","text":"正则表达式从入门到工作最近工作中用到了很多正则表达式，多少需要记录下使用心得。但一直犹豫要不要写这篇文章，因为网上的正则表达式太多，但想到，写笔记是为了以后的方便，还是决定做吧，而且除了要写基础的，更要写一些特色出来。 是什么简单来说，正则表达式就是用来对文件(字符串)进行匹配的语言(规则)，匹配到之后呢，就可以对文本进行增删改查，增删改查跟语言相关，因此不涉及这方面知识，当然示例代码用的是python 正则表达式的广泛应用最开始接触正则是在shell命令下的grep、sed、awk，后来用的python、js等语言也都支持(包括C++在C11标准中也支持了正则).擅长用工具的人，还能发现像notepad、Everything等各种工具都支持正则,正则表达式就像基础功能一样，不管在编程语言中，还是工具中都有广泛的应用 学习资料，网站正是如此的广泛的应用，因此网上学习资料是不缺的。 在线测试用具：https://tool.oschina.net/regex 常用正则表达式(转)：https://blog.csdn.net/sirobot/article/details/89478951 正则表达式原理(转)：https://zhuanlan.zhihu.com/p/107836267 正则表达式入门基础语法1. 匹配普通文本12re.search(r&#x27;hello world&#x27;,&#x27;example hello world!&#x27;)# &lt;re.Match object; span=(8, 19), match=&#x27;hello world&#x27;&gt; 匹配任意一个字符.(除了换行符\\n) 12re.search(r&#x27;..llo&#x27;,&#x27;example hello world!&#x27;)#&lt;re.Match object; span=(8, 13), match=&#x27;hello&#x27;&gt; 2. 匹配字符组[]虽然叫字符组，但其实匹配的还是一个字符，只不过这个字符是一个范围 123# 匹配axample，bxample，cxample,[abc]表示a或b或cre.search(r&#x27;[abc]xample&#x27;,&#x27;cxample hello world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;cxample&#x27;&gt; 如果字符很多，可以使用-来表示一个范围的字符 123# 匹配axample，bxample，cxample,[a-c]等价[abc]re.search(r&#x27;[a-c]xample&#x27;,&#x27;cxample hello world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;cxample&#x27;&gt; 还可以用^来表示非的意思 123# 匹配axample，bxample，cxample,[^d-z]等价[abc]re.search(r&#x27;[^d-z]xample&#x27;,&#x27;cxample hello world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;cxample&#x27;&gt; 3. 转义字符 \\转义字符主要是为了匹配一些无法表达的特殊字符，如\\t,\\n等。转义字符跟字符集一样，仅匹配一个字符 123# 这里\\t匹配制表符re.search(r&#x27;\\texample&#x27;,&#x27; example hello world!&#x27;)#&lt;re.Match object; span=(0, 8), match=&#x27;\\texample&#x27;&gt; 转义字符也可以用来表示一类字符，如\\w,\\d,\\s等 123# 这里\\w 等价[a-z0-9_]re.search(r&#x27;\\w&#x27;,&#x27; example hello world!&#x27;)# &lt;re.Match object; span=(1, 2), match=&#x27;e&#x27;&gt; 数量词前面的基础语法都只能匹配一个字符，如果需要匹配多次，下面的数量词就派上用场了,数量词需要在字符之后 1. 基础数量词匹配0次或者无限次*匹配1次或者无限次+匹配0次或者1次？ 123456# 匹配至少一个空白字符 后接 至少一个[a-z0-9_]字符 re.search(r&#x27;\\s+\\w+&#x27;,&#x27;example hello_world!&#x27;)# &lt;re.Match object; span=(7, 19), match=&#x27; hello_world&#x27;&gt;# 匹配0个或一个空白字符 后接 至少一个[a-z0-9_]字符re.search(r&#x27;\\s?\\w+&#x27;,&#x27;example hello_world!&#x27;)# &lt;re.Match object; span=(0, 7), match=&#x27;example&#x27;&gt; 2. 匹配诺干次{m} 匹配前一个字符m次{n,m} 匹配前一个字符n至m次 123# 匹配数字 4到5次re.search(r&#x27;\\d&#123;4,5&#125;&#x27;,&#x27;1 22 333 4444&#x27;)# &lt;re.Match object; span=(9, 13), match=&#x27;4444&#x27;&gt; 字符边界(位置匹配)字符边界简单来说就是匹配字符在哪个位置, 但除了^和$常用，平常用的比较少。对于边界字符的理解，可以把位置看成空字符，即”” 1. 简单常用位置符号^表示开头$表示结尾 123# 不匹配&#x27;11 21&#x27;re.search(r&#x27;^\\d+ 22$&#x27;,&#x27;11 22&#x27;)# &lt;re.Match object; span=(0, 5), match=&#x27;11 22&#x27;&gt; 2. 其他位置符号\\b是单词边界，就是\\w和\\W之间的位置\\B是\\b的反面，即非单词边界 123# 从结果可以看到，还包括\\w和^、$之间的位置re.sub(r&#x27;\\b&#x27;,&quot;@&quot;,&#x27;1.Hello world&#x27;)# &#x27;@1@.@Hello@ @world@&#x27; 3. 先行断言(?=exp) 其中exp是一个子表达式，即exp前面的位置。(?!exp) 与上面相反 12345# 把位置理解成&quot;&quot;,这里就是在ll字符前面的空字符替换成@re.sub(r&#x27;(?=ll)&#x27;,&quot;@&quot;,&#x27;1.Hello worlld&#x27;)# &#x27;1.He@llo wor@lld&#x27;re.sub(r&#x27;(?!ll)&#x27;,&quot;@&quot;,&#x27;1.Hello worlld&#x27;)# &#x27;@1@.@H@el@l@o@ @w@o@rl@l@d@&#x27; 分组和引用前面讲了字符组[ab], 但这只能表示一个字符, 如果想要匹配ab或者cd就无能为力了；又或者ab*, *只作用于一个字符，你想要把ab作为一个整体匹配多次，同样无能为力。分组用于解决这些问题，分组也可以认为是子表达式 1. 分组(exp) 其中exp是子表达|式 表示左右任意匹配一个 123# 匹配&#x27;.&#x27;前面是数字或者字母的re.search(r&#x27;(\\d+|[a-zA-Z]+)\\.&#x27;,&#x27;1.hello&#x27;)# &lt;re.Match object; span=(0, 2), match=&#x27;1.&#x27;&gt; 2. 引用引用是为了对重复出现的文本进行匹配，要引用需要先分组(exp) 会自动产生编号，从1开始;&lt;number&gt; 引用编号为number的分组匹配到的字符串(?:exp) 不会捕获，即不会有编号(?P&lt;name&gt;exp) 定义一个命名分组;(?P=name)引用别名为name的分组匹配到的字符串 123456789# 常用于匹配html标签re.search(r&#x27;&lt;([a-z]+)&gt;.*&lt;/\\1&gt;&#x27;,&#x27;&lt;span&gt;xxx&lt;/span&gt;&#x27;)# &lt;re.Match object; span=(0, 16), match=&#x27;&lt;span&gt;xxx&lt;/span&gt;&#x27;&gt;# (?:span) 不捕获，没有编号re.search(r&#x27;&lt;(?:span)&gt;&lt;(div)&gt;.*&lt;/\\1&gt;&#x27;,&#x27;&lt;span&gt;&lt;div&gt;xxx&lt;/div&gt;&#x27;)# &lt;re.Match object; span=(0, 20), match=&#x27;&lt;span&gt;&lt;div&gt;xxx&lt;/div&gt;&#x27;&gt;# 使用别名re.search(r&#x27;&lt;(?P&lt;name1&gt;\\w+)&gt;&lt;(?P&lt;name2&gt;h[1-5])&gt;.*&lt;/(?P=name2)&gt;&lt;/(?P=name1)&gt;&#x27;,&#x27;&lt;html&gt;&lt;h1&gt;xxx&lt;/h1&gt;&lt;/html&gt;&#x27;)# &lt;re.Match object; span=(0, 25), match=&#x27;&lt;html&gt;&lt;h1&gt;xxx&lt;/h1&gt;&lt;/html&gt;&#x27;&gt; 正则表达式不能干的事几乎所有讲正则表达式的博客，都是在说正则表达式无所不能，这里我结合实际，把实际中无法直接用正则匹配的情况说下，当然也可能是我水平不够，写不出来。 1. 不能(^abc)字符集可以[^abc]，表示非abc的字符；但没有表示非abc字符串的表达式，(^abc),^表示的是开头 2. 不能就近匹配比方“select a from select a into b”, 我希望匹配离into最近的select，但事与愿违 总结我写的内容虽然没有覆盖全正则表达式的所有语法，但作为入门足够了。正如前面写的，正则表达式在工具中也有广泛应用，在平常工作中可以多用正则表达式来查找文件，查找奇奇怪怪的内容，对工作效率提升up","categories":[],"tags":[]},{"title":"allocator","slug":"C++Basic/stl-allocator","date":"2021-10-11T19:04:04.000Z","updated":"2021-10-11T19:04:04.000Z","comments":true,"path":"2021/10/11/C++Basic/stl-allocator/","link":"","permalink":"https://liji53.github.io/2021/10/11/C++Basic/stl-allocator/","excerpt":"","text":"分配器杂谈分配器在stl的容器中用于空间的分配与释放，以及对象的初始化与析构，下面我们简单了解下stl 6大组件中的allocator 分配器的思想与接口分配器将内存的分配与对象的构造行为分离出来，一是为了提高效率对于已分配好的内存可以反复利用，避免内存碎片，但更重要的是为了泛型编程的可复用性，降低内存分配与构造行为的耦合性。 1.基本接口12345678template &lt;class T&gt;T* allocator&lt;T&gt;::allocate(size_type n);template &lt;class T&gt;void allocator&lt;T&gt;::deallocate(T* ptr);template &lt;class T&gt;void allocator&lt;T&gt;::construct(T* ptr);template &lt;class T&gt;void allocator&lt;T&gt;::destroy(T* ptr) allocate和deallocate 在gcc中的实现就是::operator new和delete而construct 用到了placement new，为的是调用对象的构造函数。而destroy 自然是显式调用析构函数 2.rebind在allocator的实现中都会有一个rebind的结构体，它的作用是获得其他类型的内存分配器allocator&lt;other&gt; 12345template &lt;typename _Tp1&gt;struct rebind&#123; typedef allocator&lt;_Tp1&gt; other;&#125;; 因为在stl容器中，除了要给对象分配内存，往往还需要给存数据的节点分配内存，比如list，list节点存放数据和下一个节点，而rebind用来给这个节点分配内存的。 uninitialized的细节uninitialized系列的函数虽然不属于allocator，但提供了大规模元素初始值的设置，能大大提高拷贝的效率 1. uninitialized_copyuninitialized_copy 会把 [first, last)上的内容复制到以result为起始处的空间，返回复制结束的位置由于实际代码嵌套层数太多而且还有各种type_traits的处理，这里写伪代码供参考： 123456789101112131415161718192021222324252627282930313233343536ForwardIter uninitialized_copy(InputIter first, InputIter last, ForwardIter result)&#123; if (is_trivially_copy_assignable(result))&#123; /// 根据result来判断对象的构造函数是否无关紧要(可以理解为是否为POD) if (is_pointer_iterator())&#123; /// 指针版本，实际通过偏特化来实现 std::memmove(result, first, n * sizeof(Up)); /// memmove能够保证源串在被覆盖之前将重叠区域的字节拷贝到目标区域中，比memcpy更安全 &#125; else&#123; /// 迭代器版本 if (is_random_access_iterator_tag())&#123; /// 可以看到，为了性能，stl偏特化了随机访问迭代器版本 for (auto n = last - first; n &gt; 0; --n, ++first, ++result) &#123; *result = *first; &#125; return result; &#125; else&#123; for (; first != last; ++first, ++result) /// 性能比random_access_iterator差，因为需要调用运算符重载函数 &#123; *result = *first; &#125; return result; &#125; &#125; &#125; else&#123; auto cur = result; try&#123; for (; first != last; ++first, ++cur)&#123; std::construct(&amp;*cur, *first); /// 使用了replacement new &#125; &#125; catch (...)&#123; /// commit or rollback 构造出所有元素，要么不构造出任何一个 for (; result != cur; --cur) std::destroy(&amp;*cur); /// 调用析构函数 &#125; return cur; &#125;&#125; 2. uninitialized_filluninitialized_fill 会在 [first, last) 区间内填充元素值value伪代码实现如下： 1234567891011121314151617181920212223void uninitialized_fill(ForwardIter first, ForwardIter last, const T&amp; value)&#123; if (is_trivially_copy_assignable(first))&#123; /// 根据first的类型判断构造函数是否无关紧要 if (is_random_access_iterator_tag())&#123; n = last - first; /// 类型萃取difference_type if is_pointer_iterator()&#123; std::memset(first, (unsigned char)value, (size_t)(n)); /// 如果迭代器是指针，直接调用memset &#125; else&#123; for (; n &gt; 0; --n, ++first)&#123; *first = value; &#125; &#125; &#125; else&#123; for (; first != last; ++first)&#123; *first = value; &#125; &#125; &#125; else&#123; ...... /// 省略，与uninitialized_copy的实现类似 &#125;&#125; 3. uninitialized_moveuninitialized_move 会把[first, last)上的内容移动到以result为起始处的空间，返回移动结束的位置由于实现上与uninitialized_copy基本一致，大部分内容省略 1234567891011121314151617ForwardIter uninitialized_move(InputIter first, InputIter last, ForwardIter result)&#123; if (is_trivially_copy_assignable(result))&#123; if (is_pointer_iterator())&#123; std::memmove(result, first, n * sizeof(Up)); &#125; else&#123; ...... *result = std::move(*first); ...... &#125; &#125; else&#123; ...... std::construct(&amp;*cur, std::move(*first)); /// 实际调用移动构造函数 ...... &#125;&#125; 内存池版本的allocator弃用1.std::alloc的原理参考：《stl源码剖析》原理图：当申请的内存较大时，直接通过new进行内存分配，当申请小块内存时，使用内存池管理。内存池通过16个数组进行管理，每个数组各自管理大小分别为 8， 16， 24，…128 bytes(8 的倍数)的小额区块，这些区块通过链表的方式链接起来 2.什么时候弃用的，为什么弃用弃用原因参考(官网)：https://gcc.gnu.org/onlinedocs/libstdc++/manual/memory.html#allocator.design_issues弃用版本(官网)：https://gcc.gnu.org/onlinedocs/libstdc++/manual/api.html#table.extension_allocators从gcc3.4版本开始默认使用__gnu_cxx::new_allocator，同时这个版本对分配器做了较大的改动，新增了如bitmap_allocator、mt_allocator等的分配器可是使用内存池的版本比直接使用new进行分配要有优势(减少内存碎片,提高效率)，但为什么GNU要废弃内存池版本呢？通过官网的解释是为了稳定、兼容。（原文：has the advantage of working correctly across a wide variety of hardware and operating systems, including large clusters）同时指出了内存池的缺点：由于内存的创建销毁顺序的不确定，在内存中加载和释放共享对象时可能有问题。（原文：order-of-destruction and order-of-creation for memory pools may be difficult to pin down with certainty, which may create problems when used with plugins or loading and unloading shared objects in memory） Gnu提供的allocator其他版本1.现有版本new_allocator：默认版本，使用new和delete管理malloc_allocator：使用malloc和delete管理debug_allocator：会申请相比于目标值稍大一些的内存，并用额外的内存存储size信息。在deallocate中用一个assert()来检查被存储的size信息和将要被释放的内存的size是否一致throw_allocator：具有内存跟踪和标记的功能__pool_alloc ：即上面的旧版本内存池分配器__mt_alloc ： 多线程内存池分配器bitmap_allocator：内存池的基础上用bitmap标记内存块的使用和释放 2.__mt_alloc的原理资料：https://gcc.gnu.org/onlinedocs/libstdc++/manual/mt_allocator.htmlmt_alloc分为多线程版本和单线程版本，遗憾的是多线程版本只给出了接口，并没有实现。但实现原理其实是在pool_allocator的基础上，从1维数组变成2维数组，第二维指向线程id。 123456789101112131415161718192021222324/// 多线程池版的内存池，数据结构class __pool&lt;true&gt; : public __pool_base&#123; /// 线程id节点，这些节点会组成一个链表，用于从真实线程id映射到内部线程id（1-4096） struct _Thread_record &#123; _Thread_record* _M_next; /// 下一个空闲线程id size_t _M_id; /// 内部使用的线程id，范围是1到4096 &#125;; union _Block_record&#123; _Block_record* _M_next; /// 下一个空闲节点 size_t _M_thread_id; /// 申请该内存的线程id &#125;; struct _Bin_record &#123; _Block_record** _M_first; /// 一维数组，idx为线程id，存free_list的头节点 _Block_address* _M_address; /// 实际内存块的地址 size_t* _M_free; /// 一维数组，idx为线程id，存空闲内存块计数 size_t* _M_used; /// 一维数组，idx为线程id，存使用内存块计数 __gthread_mutex_t* _M_mutex; /// 互斥锁,申请和释放内存小块时用 &#125;; _Bin_record* _M_bin; /// 一维数组，内存池按2的指数对小内存块进行管理，idx为2的指数 size_t _M_bin_size; ///bin的个数 _Thread_record* _M_thread_freelist; /// 线程id的列表&#125;; 3.bitmap_allocator的原理资料：https://gcc.gnu.org/onlinedocs/libstdc++/manual/bitmap_allocator.html网友分析：https://www.jianshu.com/p/425ab2e81b59","categories":[{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"}],"tags":[]},{"title":"没有登录认证下解决文件冲突方案","slug":"pythonOther/fileConflict","date":"2021-10-08T21:37:29.000Z","updated":"2021-10-08T21:37:29.000Z","comments":true,"path":"2021/10/08/pythonOther/fileConflict/","link":"","permalink":"https://liji53.github.io/2021/10/08/pythonOther/fileConflict/","excerpt":"","text":"web、后台解决文件冲突需求背景背景是之前给团队做了几个提升软件质量、提升工作效率的工具，这些工具需要通过web来修改后台程序的配置，但随着使用的人越来越多，并发的问题也越来越突出，今天我们主要解决在没有登录认证的情况下，多个用户同时操作文件冲突的问题。 寻找解决方法多人同时操作文件，如何保证文件的并发控制，拿到这个问题，我们首先想到了以下几种解决方向： 通知的方式：简单来说就是让其他人知道现在有人正在修改文件，请不要修改文件，并及时刷新页面 冲突的方式：修改文件并提交时，判断文件的修改时间，如果读配置的时间在修改时间之后，则不允许修改 文件锁的方式：类似svn提交代码的操作，在修改文件之前先对文件加锁，修改完成之后再解锁，保证原子性 经过技术评估，方案2最简单，方案1和方案3都需要花点精力。但从用户角度来说，方案3最好，因此最终选择3。再回到技术上，要实现方案3，需要考虑以下几个技术要点： 服务端需要知道是哪个client在修改配置文件； 什么情况下加锁，释放锁(切换文件的读写模式、切换到其他文件、关闭刷新网页)； 异常情况下如何保证锁释放（断网、浏览器奔溃、加了文件锁但不在电脑前了） 方案设计上面的几个技术要点，解决如下： 虽然没有用户体系，但要识别客户端，可以通过cookie的方案来解决，client随机生成id，server根据client id来记录文件的锁定情况 正常情况下，切换文件模式、关闭刷新网页 这些自然靠js自己判断 异常情况下，我们可以参考保活机制来实现自动解锁；页面长时间不操作，则可以通过js判断 时序图如下： 代码实现1.识别客户端由于我们不需要鉴权认证，仅仅只要能区别客户端用户就行，因此cookie可以客户端自己生成，只需要确保唯一性。关键代码如下(作为C++开发，写前端的代码，大家将就下): 12345678910111213141516171819// 查询浏览器本地cookiefunction get_local_cookie()&#123; cook_list = document.cookie.split(&#x27;;&#x27;) for (var i = 0; i &lt; cook_list.length; i++)&#123; var arr = cook_list[i].split(&#x27;=&#x27;) if (arr[0] == &#x27;name&#x27; &amp;&amp; arr[1].substring(0, 9) == &#x27;autotest_&#x27;)&#123; return arr[1] &#125; &#125; return &#x27;&#x27;&#125;// 获取cookie，没有则生成cookie，有则获取当前cookieif (get_cookie() == &#x27;&#x27;)&#123; url = window.location.href + &#x27;cgi-bin/login.cgi&#x27; url += &quot;?name=autotest_&quot; + Math.round(Math.random()*10000) + Date.parse(new Date()) var request = new XMLHttpRequest(); request.open(&quot;GET&quot;, url, true); request.send(null);&#125; 其实没必要通过服务器返回set-cookie，js可以直接生成存储cookie。后端代码login.cgi： 123456789101112131415161718&#x27;&#x27;&#x27;http协议交互格式：get请求：http://192.168.0.1:8088/cgi-bin/login.cgi?name=(autotest_random+timestamp)response header:&#x27;Set-Cookie&#x27;: name=autotest_random+timestamp&#x27;&#x27;&#x27;def create_cookie(): # 获取数据 form = cgi.FieldStorage() site_name = form.getvalue(&#x27;name&#x27;) # Path 需要设置为/ 否则js无法获取 return &#x27;Set-Cookie: name=%s; Path=/&#x27; % site_nameprint (&#x27;Content-Type: text/html&#x27;)print (create_cookie())print (&#x27;HTTPOnly: false&#x27;)print () 2.保活机制+页面活动检测保活是为了在断网、网页异常的异常情况下，后台能够检测到client异常，并自动进行解锁。 这里js直接用setInterval，如果页面非活动状态会有问题 1234567891011121314151617181920// 后台启动定时器，发送保活包，如果长时间未保活，后台自动解锁myWorker = new Worker(&quot;js/keeplive.js&quot;);myWorker.postMessage(_get_url(&#x27;keeplive&#x27;));// 检查页面是否有人操作，长时间无人操作，则进行文件解锁function eventFunc()&#123; myWorker.postMessage(&quot;init&quot;);&#125;var body = document.querySelector(&quot;html&quot;);body.addEventListener(&quot;click&quot;, eventFunc);body.addEventListener(&quot;keydown&quot;, eventFunc);body.addEventListener(&quot;mousemove&quot;, eventFunc);body.addEventListener(&quot;mousewheel&quot;, eventFunc);myWorker.onmessage = function(e) &#123; is_timeout = e.data if (is_timeout)&#123; cgiHttp(&#x27;releaseLock&#x27;) alert(&quot;长时间未操作，页面强制刷新！&quot;) location.reload() &#125;&#125; keeplive.js 主要用来发保活包，以及判断页面长时间未操作，代码如下： 1234567891011121314151617181920212223242526var url = &#x27;&#x27;var init = 0var interval = 30 * 1000 // 保活发送间隔30svar pageTimeout = 20 * 60 * 1000 // 页面超时20分钟var is_timeout = falseonmessage = function(e) &#123; if (e.data == &#x27;init&#x27;)&#123; init = 0 &#125; else&#123; url = e.data &#125;&#125;setInterval(function()&#123; if (url == &#x27;&#x27; || is_timeout == true)&#123; return &#125; var request = new XMLHttpRequest(); request.open(&quot;GET&quot;, url, true); request.send(null); init += 1 if (init &gt;= pageTimeout/interval)&#123; postMessage(true); /// 通知主线程刷新页面 is_timeout = true &#125;&#125;, interval); keeplive.cgi 是后台用来接收保活包的，并把包转发给管道，由喂狗程序去判断是否异常并解锁 1234567891011121314151617181920&#x27;&#x27;&#x27;http协议交互格式：get请求：http://10.20.147.33:8088/cgi-bin/keeplive.cgi?cook=autotest_***response:&#x27;&#x27;&#x27;# todo 管道没有加锁保护，并发存在问题def _feed_dog(cookie_name): pipe_name = commVariable.pipe_name + &#x27;feedDog&#x27; if not os.path.exists(pipe_name): os.mkfifo(pipe_name) pipe_fd = os.open(pipe_name, os.O_WRONLY) os.write(pipe_fd, cookie_name.encode())form = cgi.FieldStorage()cookie = form.getvalue(&#x27;cook&#x27;)_feed_dog(cookie)print (&#x27;Content-Type: text/html&#x27;)print () 喂狗程序代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576g_lock_times = 3*60 # 3分钟lock_manager = &#x27;/tmp/filelock_manager&#x27;pipe_name = &quot;/tmp/pipefeedDog&quot;g_mutex = threading.Lock()g_file_lock_variable = &#123;&#125;# 更新内存中文件锁的时间戳def update_lock_timestamp(cookie): g_mutex.acquire() for system in g_file_lock_variable: for business in g_file_lock_variable[system]: if cookie == g_file_lock_variable[system][business][0]: g_file_lock_variable[system][business][1] = int(time.time()) g_mutex.release()# 从文件中更新到内存中def _update_lock_from_file(data): # 删除文件锁已经不存在的 for system in list(g_file_lock_variable.keys()): if not data.__contains__(system): g_file_lock_variable.pop(system) continue for business in list(g_file_lock_variable[system].keys()): if not data[system].__contains__(business): g_file_lock_variable[system].pop(business) # 更新新增的文件锁 for system in data: for business in data[system]: if not g_file_lock_variable.__contains__(system): g_file_lock_variable[system] = &#123;business: [data[system][business], int(time.time())]&#125; continue if not g_file_lock_variable[system].__contains__(business): g_file_lock_variable[system][business] = [data[system][business], int(time.time())]# 删除超时的文件锁def _delete_timeout_lock(): isChange = False for system in g_file_lock_variable: for business in list(g_file_lock_variable[system].keys()): # 超时，删除该文件锁 if (int(time.time()) - g_file_lock_variable[system][business][1]) &gt;= g_lock_times: g_file_lock_variable[system].pop(business) isChange = True return isChange# 把内存中的文件锁状态跟新到文件中def update_file_lock(): if not os.path.exists(lock_manager): return with open(lock_manager, &#x27;r+&#x27;, encoding=&quot;utf-8&quot;) as fd: try: data = json.load(fd) except: data = &#123;&#125; g_mutex.acquire() _update_lock_from_file(data) isChange = _delete_timeout_lock() if isChange: fd.seek(0) fd.truncate() content = &#123;s: &#123;b: g_file_lock_variable[s][0] for b in g_file_lock_variable[s]&#125; for s in g_file_lock_variable&#125; fd.write(json.dumps(content)) g_mutex.release()def check_timeout(): update_file_lock() threading.Timer(int(g_lock_times/3), check_timeout).start()# 启动检查是否文件锁是否过期的定时器check_timeout()# 从管道中读cookie,更新文件锁的最新情况if not os.path.exists(pipe_name): os.mkfifo(pipe_name)while True: pipe_fd = os.open(pipe_name, os.O_RDONLY) # 阻塞 cook = os.read(pipe_fd, 100) update_lock_timestamp(cook) os.close(pipe_fd) 3.关闭刷新页面，解锁靠js判断页面关闭、刷新时发送请求 12345678910111213141516// 关闭页面时，进行文件解锁window.onbeforeunload = function()&#123; url = window.location.href + &#x27;cgi-bin/releaseLock.cgi&#x27; const formData = new FormData(); formData.append(&quot;system&quot;, g_system) formData.append(&quot;subSystem&quot;, g_sub_system) formData.append(&quot;business&quot;, g_business) formData.append(&quot;fileName&quot;, g_fileName) formData.append(&quot;cook&quot;, g_cookie) window.navigator.sendBeacon(url, formData)&#125;// 刷新页面时，则强制解锁该client的所有文件锁if (performance.navigation.type == 1)&#123; cgiHttp(&#x27;releaseLock&#x27;) console.log(g_business)&#125; 4.切换模式配置的编辑使用了jsonEditor，只需要监听mode的切换即可 1234567891011121314151617181920var jsonOptions = &#123; mode: &#x27;view&#x27;, modes: [&#x27;view&#x27;, &#x27;code&#x27;, &#x27;tree&#x27;], onError: function(err) &#123; alert(err.toString()); &#125;, onModeChange: function(newMode,oldMode)&#123; if ((newMode == &#x27;code&#x27; || newMode == &#x27;tree&#x27;) &amp;&amp; oldMode == &#x27;view&#x27;)&#123; cgiHttp(&#x27;getLock&#x27;) if (g_response.hasOwnProperty(&#x27;success&#x27;) &amp;&amp; g_response[&#x27;success&#x27;] != true)&#123; alert(&#x27;本文件已经被锁定，请稍后再试&#x27;) g_jsonEditor.setMode(&#x27;view&#x27;) &#125; &#125; else if (newMode == &#x27;view&#x27; &amp;&amp; ((oldMode == &#x27;code&#x27; || oldMode == &#x27;tree&#x27;)))&#123; cgiHttp(&#x27;releaseLock&#x27;) console.log(g_response) &#125; &#125;&#125;; 最终效果","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"探索difflib(初探匹配算法)","slug":"pythonOther/difflibParse","date":"2021-09-10T08:04:57.000Z","updated":"2021-09-10T08:04:57.000Z","comments":true,"path":"2021/09/10/pythonOther/difflibParse/","link":"","permalink":"https://liji53.github.io/2021/09/10/pythonOther/difflibParse/","excerpt":"","text":"让difflib展示更智能继上一篇文章pytest测试报告自定义比较内容，我们修改了pytest-html的源码，用difflib的html比对方式生成了新的测试报告。但用了之后发现，difflib的行比对效果极差，如果存在几处(测了下3个字符以上)不一致的地方就整行变红色，而不是只显示差异字符。如下图： 我想要的效果是beyond compare这种(只把差异字符标红，而并不是整行变红) 网上百度difflib的实现原理，居然完全空白，于是只能自己看源代码分析原因。 首先我们知道difflib有3种差异模式：”Added “ ; “Changed”; “Deleted”。 现在我们要找为什么我们期望的”Changed”会变成”Added”。 difflib源码分析1. 生成html(table)的源码1234567def make_table(self,fromlines,tolines,fromdesc=&#x27;&#x27;,todesc=&#x27;&#x27;,context=False,numlines=5): # 省略...... return table.replace(&#x27;\\0+&#x27;,&#x27;&lt;span class=&quot;diff_add&quot;&gt;&#x27;). \\ replace(&#x27;\\0-&#x27;,&#x27;&lt;span class=&quot;diff_sub&quot;&gt;&#x27;). \\ replace(&#x27;\\0^&#x27;,&#x27;&lt;span class=&quot;diff_chg&quot;&gt;&#x27;). \\ replace(&#x27;\\1&#x27;,&#x27;&lt;/span&gt;&#x27;). \\ replace(&#x27;\\t&#x27;,&#x27;&amp;nbsp;&#x27;) 2. 匹配度导致的整行变红下面就定位到_fancy_replace 这个函数，这个函数作用是把原字符串替换成标注差异的字符串 1234567891011121314151617181920&quot;&quot;&quot; Example:&gt;&gt;&gt; d = Differ()&gt;&gt;&gt; results = d._fancy_replace([&#x27;abcDefghiJkl\\n&#x27;], 0, 1,... [&#x27;abcdefGhijkl\\n&#x27;], 0, 1)&gt;&gt;&gt; print(&#x27;&#x27;.join(results), end=&quot;&quot;)- abcDefghiJkl? ^ ^ ^+ abcdefGhijkl? ^ ^ ^&quot;&quot;&quot;def _fancy_replace(self, a, alo, ahi, b, blo, bhi): best_ratio, cutoff = 0.74, 0.75 cruncher = SequenceMatcher(self.charjunk) # 省略...... if cruncher.real_quick_ratio() &gt; best_ratio and \\ cruncher.quick_ratio() &gt; best_ratio and \\ cruncher.ratio() &gt; best_ratio: best_ratio, best_i, best_j = cruncher.ratio(), i, j # 省略...... 这里的逻辑是匹配度要达到0.74，就能展示字符差异，而不是整行差异 3. 匹配度与预期不符12345# Where T is the total number of elements in both sequences, and# M is the number of matches, this is 2.0*M / T.def ratio(self): matches = sum(triple[-1] for triple in self.get_matching_blocks()) return _calculate_ratio(matches, len(self.a) + len(self.b)) 按照源码的注释，如果只有个别字符不一样，匹配度应该是很高的。在我自己的例子中，只有5个字符不一样，2个比对的字符串分别有250个字符，按照公式，匹配度应该有2*(250-5)/(250*2)=0.98，但实际却只有0.6多 4. 匹配的块少了这个函数会返回所有匹配的内容。Match(a=3, b=2, size=2)，表示左边字符串第3位开始，右边字符串第2位开始相同，相同字符个数为2个 1234567891011121314151617&quot;&quot;&quot;&gt;&gt;&gt; s = SequenceMatcher(None, &quot;abxcd&quot;, &quot;abcd&quot;)&gt;&gt;&gt; list(s.get_matching_blocks())[Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]&quot;&quot;&quot;def get_matching_blocks(self): # 省略...... while queue: alo, ahi, blo, bhi = queue.pop() i, j, k = x = self.find_longest_match(alo, ahi, blo, bhi) if k: # if k is 0, there was no matching block matching_blocks.append(x) if alo &lt; i and blo &lt; j: queue.append((alo, i, blo, j)) if i+k &lt; ahi and j+k &lt; bhi: queue.append((i+k, ahi, j+k, bhi)) matching_blocks.sort() 期望是所有匹配的子串都能找到返回，但实际却缺少了几个Match 5. 自动垃圾启发式计算惹的祸这个函数看字面意思是找最长的字串，但实际是有条件的。 123456789101112131415161718def find_longest_match(self, alo=0, ahi=None, blo=0, bhi=None): # 省略...... for i in range(alo, ahi): # look at all instances of a[i] in b; note that because # b2j has no junk keys, the loop is skipped if a[i] is junk j2lenget = j2len.get newj2len = &#123;&#125; for j in b2j.get(a[i], nothing): # a[i] matches b[j] if j &lt; blo: continue if j &gt;= bhi: break k = newj2len[j] = j2lenget(j-1, 0) + 1 if k &gt; bestsize: besti, bestj, bestsize = i-k+1, j-k+1, k j2len = newj2len # 省略...... 这个函数里有一个关键变量b2j， 这个变量维护了字符串中频率很低的字符，以及坐标位置。这么做的目的是为了提高运行效率，毕竟如果要比较的字符串很大，每一个字符都比较很影响效率。因此通过比较个别“冷门”字符就能快速匹配。 自动垃圾启发式计算的定义， 引用官方原文： SequenceMatcher支持使用启发式计算来自动将特定序列项视为垃圾。 这种启发式计算会统计每个单独项在序列中出现的次数。 如果某一项（在第一项之后）的重复次数超过序列长度的 1% 并且序列长度至少有 200 项，该项会被标记为“热门”并被视为序列匹配中的垃圾。 这种启发式计算可以通过在创建SequenceMatcher时将 autojunk 参数设为 False 来关闭。 结论原因找到了，只要匹配的字符串长度超过200字符，就可能匹配度变低。比较遗憾的是HtmlDiff类并没有把autojunk参数暴露出来，因此还是要通过修改源码才行, 修改如下： 1234def _fancy_replace(self, a, alo, ahi, b, blo, bhi): best_ratio, cutoff = 0.74, 0.75 #cruncher = SequenceMatcher(self.charjunk) cruncher = SequenceMatcher(self.charjunk, autojunk=False) 注意：这么改，效率会变低 最后上个效果图：","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"pytest测试报告自定义比较内容","slug":"pythonOther/pytestHtml","date":"2021-09-09T08:48:22.000Z","updated":"2021-09-09T08:48:22.000Z","comments":true,"path":"2021/09/09/pythonOther/pytestHtml/","link":"","permalink":"https://liji53.github.io/2021/09/09/pythonOther/pytestHtml/","excerpt":"","text":"pytest-html自定义比较内容pytest通过assert进行断言，而断言产生的错误内容是python自带的错误解释。但这个错误内容长这样，是不是一脸懵。 我想要的效果是像beyond compare那样： 预备知识&amp;资料遇到问题，先从网上找资料，其中有几篇文章对了解pytest还是很有帮助的 资料： https://www.cnblogs.com/yoyoketang/p/9748718.html https://www.cnblogs.com/linuxchao/p/linuxchao-pytest-html.html https://www.cnblogs.com/yoyoketang/p/14108144.html 但这些文章，并不是我想要的，于是只能自己从pytest-html的源码入手，定制测试报告 定位pytest-html源码pytest-html的源码不多，还是很容易理解的，实现都在pytest_html/plugins.py文件中 1. 分析测试报告的html通过下图，可以看到我们要修改的测试报告的内容位于 2.定位源码通过找生成div(class=’log’)的代码，可以定位到以下代码，这部分的代码就是用来生成div标签的html 12345678910111213141516171819def _populate_html_log_div(self, log, report): if report.longrepr: # longreprtext is only filled out on failure by pytest # otherwise will be None. # Use full_text if longreprtext is None-ish # we added full_text elsewhere in this file. text = report.longreprtext or report.full_text if html_log_content is None: for line in text.splitlines(): separator = line.startswith(&quot;_ &quot; * 10) if separator: log.append(line[:80]) else: exception = line.startswith(&quot;E &quot;) if exception: log.append(html.span(raw(escape(line)), class_=&quot;error&quot;)) else: log.append(raw(escape(line))) log.append(html.br()) 生成目标html直接上代码， 这里用到了difflib，不要忘记import difflib 由于代码是通过Full diff来判断的，因此调用pytest的时候不要忘加-vv参数选项 123456789101112@staticmethoddef _my_diy_html_log_div(text): if text.find(&#x27;Full diff&#x27;) != -1: idx1 = text.find(&#x27;AssertionError: assert&#x27;) + len(&#x27;AssertionError: assert&#x27;) idx2 = text.find(&#x27;E At index&#x27;) compare_str = text[idx1:idx2] left = compare_str[:compare_str.find(&#x27;==&#x27;)].replace(&#x27;\\\\n&#x27;,&#x27;\\n&#x27;) right = compare_str[compare_str.find(&#x27;==&#x27;)+len(&#x27;==&#x27;):].replace(&#x27;\\\\n&#x27;,&#x27;\\n&#x27;) diff = difflib.HtmlDiff() diff_content = diff.make_file(left.splitlines(), right.splitlines()) return diff_content return None 调用者代码如下： 12345678910111213141516171819def _populate_html_log_div(self, log, report): if report.longrepr: text = report.longreprtext or report.full_text # add by liji html_log_content = self._my_diy_html_log_div(text) if html_log_content is None: for line in text.splitlines(): separator = line.startswith(&quot;_ &quot; * 10) if separator: log.append(line[:80]) else: exception = line.startswith(&quot;E &quot;) if exception: log.append(html.span(raw(escape(line)), class_=&quot;error&quot;)) else: log.append(raw(escape(line))) log.append(html.br()) else: log.append(raw(html_log_content)) 代码最后一句：log.append(raw(html_log_content))，必须要加raw，否则报告长这样 这是因为log.append(html)，字符串html会被转义，’&lt;’、’&gt;’、’&amp;’等会被转义 通过看py/_xmlgen.py 的源码，可以看到raw不会escape 123456def __object(self, obj): #self.write(obj) self.write(escape(unicode(obj)))def raw(self, obj): self.write(obj.uniobj) 最后效果展示 格式是difflib的html格式，大致满足要求了！","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"oracle数据迁移","slug":"pythonOther/oracleMigration","date":"2021-09-02T06:31:01.000Z","updated":"2021-09-02T06:31:01.000Z","comments":true,"path":"2021/09/02/pythonOther/oracleMigration/","link":"","permalink":"https://liji53.github.io/2021/09/02/pythonOther/oracleMigration/","excerpt":"","text":"数据迁移总结(oracle)此类博客太多的坑，都不完整，要不执行着就报错执行不下去了。总的来说，能不用oracle就不要用，学习成本太高。 方法一:客户端exp/imp(不推荐)1. 环境准备，下载工具下载地址： https://www.oracle.com/cn/database/technologies/instant-client/winx64-64-downloads.html 下载以下2个文件： instantclient-basic-windows.x64-12.2.0.1.0.zip instantclient-tools-windows.x64-12.2.0.1.0.zip 注意：exp和imp工具在tools里，版本12.2.0.1.0 上才有， 2. 环境安装，配置TNS文件解压之后，在exp、imp工具的同级目录下新增Network/Admin/tnsnames.ora文件（环境变量看自己的需求） tnsnames.ora文件内容参考： 123456789ora11g_test = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.1)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = helowinXDB) ) ) 3.使用方法使用之前，需要建立好表空间、用户，这里不详细讲 12exp.exe usr/password@ora11g_test file=usr_export.dmp owner=usrimp.exe usr/password@target_oracle file=usr_export.dmp full=y 4. 存在问题说实在的，报的问题实在太多，很多解决不了，下面是随便罗列的几个，因此放弃这个方法. 123EXP-00113: Feature New Composite Partitioning Method is unsupported. EXP-00107: Feature (BINARY XML) of column XML_CONTENT in tableORA-00904: &quot;DUMMYFLAG&quot;: invalid identifier 方法二：expdp和impdp（不推荐）经历方法一的失败，网上看到有数据泵的方式，因此再次尝试 1. 环境&amp;资料使用数据泵需要10g以上的oracle server版本，同时需要在服务端运行，相关的教程建议看 https://hevodata.com/learn/export-data-from-oracle-using-expdp/#i1 https://docs.oracle.com/cd/E11882_01/server.112/e22490/dp_export.htm#SUTIL200 https://oracle-base.com/articles/10g/oracle-data-pump-10g#TableExpImp 2. 使用方法连接本地数据库 1sqlplus &#x2F; as sysdba 创建连接远程数据库(本地的话不需用)(网上很多教程没有提到这一步，如果不创建，生成的dmp文件在远程的oracle服务器上) 1SQL&gt;create public database link orcl11g connect to system identified by oracle using &#x27;(DESCRIPTION =(ADDRESS_LIST =(ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.2)(PORT = 1521)))(CONNECT_DATA =(SERVICE_NAME = test)))&#x27;; 创建dmp文件本地存储路径，并赋予权限 12SQL&gt;create directory data_dir as &#x27;/home/oracle/back/data&#x27;;SQL&gt;Grant read,write on directory data_dir to test; shell下，导出数据(有多种导出模式：导整个数据库、按表空间导、按用户导、按表名导、按查询条件导) 12mkdir -p /home/oracle/back/dataexpdp system/system dumpfile=export.dmp directory=data_dir network_link=orcl11g schemas=test 导入数据（注意：需要先建表空间、用户，即使按整个数据库模式） 1impdp test/*** dumpfile=export.dmp directory=data_dir schemas=test 3. 问题用了方法二，问题同样很多，有些报错解决不了。因此这个方法也放弃 123ORA-14460ORA-26059....... 方法三: 写脚本也试过用plsql的导出用户对象、导出表的方式，但也是动不动就出问题，而且无法实现自动化，想要灵活的定制只能自己写脚本同步数据。下面是相关代码， 工具：python 1. 整体代码结构123456789101112131415161718192021222324252627282930import cx_Oracleimport osg_table_space_name_list = [[&#x27;TEST1_DATA&#x27;, &#x27;test1dat.dbf&#x27;, 1024], [&#x27;TEST2_DATA&#x27;, &#x27;test2dat.dbf&#x27;, 1024]] grant_privilege = [&quot;CONNECT&quot;,&quot;RESOURCE&quot;,&quot;DBA&quot;,&quot;UNLIMITED TABLESPACE&quot;, &quot;select any table&quot;,&quot;create any table&quot;, &quot;drop any table&quot;]g_user_name_list = [[&quot;LJ_TEST&quot;, &quot;TEST1_DATA&quot;, grant_privilege], [&quot;LJ_TEST2&quot;, &quot;LJ_TEST2&quot;, grant_privilege]]exist_table_space_str = &quot;select count(*) from dual where exists(&quot; \\ &quot;select * from v$tablespace a where a.name = upper(&#x27;%s&#x27;))&quot;create_table_space_str = &quot;CREATE TABLESPACE %s DATAFILE &quot; \\ &quot;&#x27;/home/oracle/app/oracle/oradata/helowin/%s&#x27; &quot; \\ &quot;SIZE %dM EXTENT MANAGEMENT LOCAL SEGMENT SPACE MANAGEMENT AUTO&quot;exist_user_name_str = &quot;select count(*) from dual where exists(&quot; \\ &quot;select * from all_users a where a.username = upper(&#x27;%s&#x27;))&quot;create_user_name_str = &quot;CREATE USER %s IDENTIFIED BY test &quot; \\ &quot;DEFAULT TABLESPACE %s TEMPORARY TABLESPACE TEMP&quot;query_table_data_str = &quot;select * from %s.%s&quot;insert_table_data_str = &quot;insert into %s.%s (%s) values (%s)&quot;delete_table_data_str = &quot;truncate table %s.%s&quot;if __name__ == &#x27;__main__&#x27;: client = OracleClient() client.create_table_space() client.create_user_name() client.create_table() client.sync_data() 2.连接数据库12345678910111213141516class OracleClient: def __init__(self): os.environ[&#x27;NLS_LANG&#x27;] = &#x27;SIMPLIFIED CHINESE_CHINA.utf8&#x27; # 待同步的数据库 dsn = cx_Oracle.makedsn(&quot;192.168.0.1&quot;, &#x27;1521&#x27;, service_name=&#x27;test&#x27;) self.m_client = cx_Oracle.connect(&#x27;system&#x27;, &#x27;oracle&#x27;, dsn) self.m_cursor = self.m_client.cursor() # 数据源 src_dsn = cx_Oracle.makedsn(&quot;192.168.0.2&quot;, &#x27;1521&#x27;, service_name=&#x27;test&#x27;) self.m_src_client = cx_Oracle.connect(&#x27;system&#x27;, &#x27;oracle&#x27;, src_dsn) self.m_src_cursor = self.m_src_client.cursor() def __del__(self): self.m_cursor.close() self.m_client.close() self.m_src_cursor.close() self.m_src_client.close() 3. 建立表空间12345678910def create_table_space(self): for table_space_name in g_table_space_name_list: self.m_cursor.execute(exist_table_space_str % table_space_name[0]) data = self.m_cursor.fetchall() # todo: if table space created, should drop and recreate. if data[0][0] != 0: continue self.m_cursor.execute(create_table_space_str % (table_space_name[0], table_space_name[1], table_space_name[2])) self.m_client.commit() 4. 建用户123456789101112def create_user_name(self): for user_name in g_user_name_list: self.m_cursor.execute(exist_user_name_str % user_name[0]) data = self.m_cursor.fetchall() # todo: if user created, should drop and recreate. if data[0][0] != 0: continue self.m_cursor.execute(create_user_name_str % (user_name[0], user_name[1])) for privilege in user_name[2]: self.m_cursor.execute(&quot;GRANT %s TO %s&quot; % (privilege, user_name[0])) self.m_client.commit() 5. 建表1234567891011121314151617181920212223242526272829 def _get_table_name_list(self): src_table_name_list = &#123;&#125; dst_table_name_list = &#123;&#125; for user_name in g_user_name_list: self.m_src_cursor.execute(query_table_name_str % user_name[0]) src_data = self.m_src_cursor.fetchall() src_table_name_list[user_name[0]] = [x[0] for x in src_data] self.m_cursor.execute(query_table_name_str % user_name[0]) data = self.m_cursor.fetchall() dst_table_name_list[user_name[0]] = [x[0] for x in data] return src_table_name_list, dst_table_name_list def _create_table(self, user_name, table_name): query_table_name_str = &quot;select TABLE_NAME from all_tables where OWNER = &#x27;%s&#x27;&quot;query_create_table_str=&quot;select dbms_metadata.get_ddl(&#x27;TABLE&#x27;,&#x27;%s&#x27;,&#x27;%s&#x27;) from dual&quot; self.m_src_cursor.execute(query_create_table_str % (table_name, user_name)) create_table_obj = self.m_src_cursor.fetchall() create_table_str = create_table_obj[0][0].read() self.m_cursor.execute(create_table_str) self.m_client.commit() def create_table(self): src_table_name_list, dst_table_name_list = self._get_table_name_list() for user_name in src_table_name_list: for table_name in src_table_name_list[user_name]: # todo, if table created, should recreated if table_name in dst_table_name_list[user_name]: continue self._create_table(user_name, table_name) 6. 同步数据123456789101112131415161718192021222324252627def _sync_data(self, user_name, table_name): self.m_src_cursor.execute(query_table_data_str % (user_name, table_name)) titles = &#x27;,&#x27;.join([i[0] for i in self.m_src_cursor.description]) data_placeholder = &#x27;,&#x27;.join([&#x27;:&#x27;+str(i+1) for i in range(len(self.m_src_cursor.description))]) try: all_table_data = self.m_src_cursor.fetchall() except cx_Oracle.DatabaseError as msg: print(&quot;\\033[1;31;40mError[%s.%s]:%s \\033[0m&quot; % (user_name, table_name, msg)) return # if contains old data,should drop self.m_cursor.execute(delete_table_data_str % (user_name, table_name)) self.m_client.commit() try: self.m_cursor.executemany(insert_table_data_str % ( user_name, table_name, titles, data_placeholder), all_table_data) except cx_Oracle.DatabaseError as msg: print(&quot;\\033[1;31;40mError[%s.%s]:%s \\033[0m&quot; % (user_name, table_name, msg)) return self.m_client.commit()def sync_data(self): src_table_name_list, dst_table_name_list = self._get_table_name_list() for user_name in src_table_name_list: for table_name in src_table_name_list[user_name]: if table_name not in dst_table_name_list[user_name]: self._create_table(user_name, table_name) self._sync_data(user_name, table_name)","categories":[{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"}],"tags":[]},{"title":"数据监控(influxDb+grafana)","slug":"pythonOther/deployMonitor","date":"2021-07-30T03:02:02.000Z","updated":"2021-07-30T03:02:02.000Z","comments":true,"path":"2021/07/30/pythonOther/deployMonitor/","link":"","permalink":"https://liji53.github.io/2021/07/30/pythonOther/deployMonitor/","excerpt":"","text":"数据监控方案背景&amp;预备知识​ 经过一个月多月的程序运行，数据沉淀在mongodb中，接下来就要考虑统计报表了，数据统计能最直接的体现你的工作价值！ ​ 从网上找了一些数据监控的解决方案，得益于docker的简单部署，让我们在验证方案可行性上省去了大量时间。整体方案：1.使用docker部署InfluxDb和Grafana；2.用influxDb远程连接Mongodb，并用脚本生成influxdb数据；3.最后通过Grafana的web展示出来。 ​ 预备知识： 了解InfluxDb，会使用python或其他语言读写influxdb数据库 了解Grafana，会简单使用对应的web即可 了解mongodb，由于数据源在mongodb，因此需要会从mongodb中读数据 环境部署1. 下载安装包下载地址： https://dl.grafana.com/oss/release/grafana-8.0.6-1.x86_64.rpm https://dl.influxdata.com/influxdb/releases/influxdb-1.7.10.x86_64.rpm 2. 生成docker镜像这里我把2个软件合成了一个镜像。 启动脚本文件run-tool.sh: 12service grafana-server startinfluxd -config /etc/influxdb/influxdb.conf dockerfile文件： 123456789101112131415FROM centos:7COPY influxdb-1.7.10.x86_64.rpm /home/COPY grafana-8.0.6-1.x86_64.rpm /home/COPY run-tool.sh /RUN cd /etc/yum.repos.d/ \\ &amp;&amp; curl -O http://mirrors.aliyun.com/repo/Centos-7.repo \\ &amp;&amp; rm CentOS-Base.repo; mv Centos-7.repo CentOS-Base.repo \\ &amp;&amp; yum clean all; yum makecache; yum -y update \\ &amp;&amp; yum install -y /sbin/service; yum install -y fontconfig \\ &amp;&amp; yum install -y urw-fonts \\ &amp;&amp; cd /home/ \\ &amp;&amp; rpm -ivh influxdb-1.7.10.x86_64.rpm \\ &amp;&amp; rpm -ivh grafana-8.0.6-1.x86_64.rpm \\ &amp;&amp; chmod +x /run-tool.shCMD /run-tool.sh 生成镜像命令： 1docker build -t tool:monitor . 3. 启动容器1docker run --name monitor --privileged -it -p 192.168.0.1:8086:8086 -p 192.168.0.1:3000:3000 -v /home/liji/docker/tmp:/mnt tool:monitor 验证是否部署成功，登录grafana的web界面查看，存在以下登录界面说明部署成功： 数据生成数据生成这个环节是粘合剂，把业务生成的数据通过某种规则转成直观的统计数据，是最核心的步骤。本环节我是通过python对mongodb里的数据进行统计，仅贴部分代码： 1. 连接mongodb、连接influxdb123456789import datetimeimport pymongofrom influxdb import InfluxDBClient# 连接mongodburl = &quot;mongodb://&quot; + g_mongo_ip + &#x27;:&#x27; + g_mongo_portmongo_client = pymongo.MongoClient(url)# 连接influxdbinflux_client = InfluxDBClient(g_influx_ip, g_influx_port, database=&#x27;test&#x27;)influx_client.create_database(g_influx_database) # 没有则创建 2. 统计mongodb的数据(DIY)12mongo_db = mongo_client[mongo_db_name]mongo_db[mongo_col_name].find(&#123;&quot;xxx&quot;: &#123;&quot;$exists&quot;: True&#125;&#125;).count() 3. 写入influxdb(DIY)123456789points = [&#123; &quot;measurement&quot;: mongo_db_name, &quot;time&quot;: datetime.datetime.utcnow().isoformat(&quot;T&quot;), &quot;fields&quot;: &#123; &quot;current_problem_count&quot;:100, &quot;resolve_problem_count&quot;:20 &#125; &#125;]influx_client.write_points(points) 4. 验证数据是否写入在安装了influxdb的环境中运行influx，具体命令可以百度 123456789[root@123106ce0db7 /]# influxConnected to http://localhost:8086 version 1.7.10InfluxDB shell version: 1.7.10&gt; show databases name: databasesname----_internaltest 界面展示这个环节是对grafana的界面操作，我也是刚入门，基本操作如下： 1. 配置数据源 选择influxdb以及选择连接地址端口 选择要连接的数据库，不用怕错误，点击“save &amp; test”的时候，会自动帮你测试连接情况 2. 配置展示面板 选择要展示的数据 3. 结果呈现这个效果是我的效果，暂时已经符合我的预期了哈 网上盗的图，参考 总结整个数据监控部署实现差不多花了2天半时间，在这个过程中让我第一次接触influxdb时间序列数据库，也第一次体验了数据监控的方案。作为开发，使用了你以前没用过的技术，确实很爽，但也要及时总结、温故而知新。","categories":[],"tags":[]},{"title":"os-文件系统","slug":"operatingSystem/os-fileSystem","date":"2021-07-10T20:11:07.000Z","updated":"2021-07-10T20:11:07.000Z","comments":true,"path":"2021/07/10/operatingSystem/os-fileSystem/","link":"","permalink":"https://liji53.github.io/2021/07/10/operatingSystem/os-fileSystem/","excerpt":"","text":"文件系统文件系统是OS用来组织和分配存储设备的方法，现在linux系统用的基本都是Ext4文件系统，在window上则基本都是NTFS文件系统，接下来我们将学习它们的数据结构与实现原理。 HDD和SSD基础在了解文件系统的实现之前，需要先知道存储介质的特性，因为文件系统(包括很多应用程序，像数据库)正是基于这些特征才设计的。 HDD的硬件特性如上图，你需要清楚的是 扇区：即图中的编号，操作硬盘的基本存储单元，对扇区的读写是原子的， 寻道：图中seek的动作，寻道时间一般在几毫秒到十几毫秒 旋转：图中Rotates的动作，旋转一圈的时间一般也要几毫秒(如10000RPM = 6 R/ms) 以现有的技术发展，寻道、旋转时间的进步比内存、cpu的发展慢的多，甚至是停滞的 一次读写实际花费的时间应该是：T(I/O) = Tseek + Trotation + Ttransfer其中Ttransfer一般是100M/s到几百M/s之间有了这个公式之后，在对文件系统的设计(包括应用程序的设计)，要尽可能的利用这个公式，提高传输效率。在涉及读写的时候，主要考虑二种读写模式： 随机读写：在随机读写中，每次磁头都需要重新定位，它的IO时间为Tseek + Trotation + Ttransfer 顺序读写：在顺序读写中，如果一次性写入一大块的数据，则只需要一次的Tseek和Trotation 即可。但如果是分批次的顺序写入，除了第一次的Tseek和Trotation时间，后面每次读写还需要Trotation时间(因为磁盘是一直在转的，分批次写入会有时间差，导致磁盘转过头) SSD的硬件特性关于SSD，你需要清楚的是： Page: 读写以page为单位，一般4k或8K Block：删除的基本单位，由多个page组成 SSD内部一般会维护一个mapping table，维护逻辑地址到物理地址的映射，不需要寻道和旋转，可以直接计算出物理地址。它的定位时间一般在0.1ms SSD如果损坏了，数据很难恢复，而HDD要容易的多 HDD没有写入次数的限制，SSD存在写入寿命的限制（因此有损耗均衡的机制） 基于这些硬件特性，SSD在随机读写上的性能要远好于HDD，而在顺序读写上一般也比HDD快1倍。（SSD内部的机制如垃圾回收机制，损耗均衡等不再介绍） 文件系统的实现文件系统会把硬盘分割成一个个块，以块为单位进行读写，一般一个块4K大小。每个块只属于一个文件(目录)，如果文件不足block大小，则剩余的容量不再使用 Ext2的布局Ext2文件系统的布局(图片来源：https://blog.csdn.net/gongjiwei/article/details/82025142):MBR: 引导块，常用于启动电脑block group：由诺干个块组成的，为了提高访问同一目录下文件的效率(减少Tseek)，文件系统会把同一个目录下的文件尽量放在一个group中。superblock：记录此文件系统的整体信息，如块大小，容量等，每个block group都有，用于备份。group description table: 块组描述符表，记录了每个块组的块位图、inode位图、inode table等的位置，同样每个block group都有，用于备份。block bitmap：块位图中的每一位表示当前块组中对应的那个块是否被使用。自身占一个块inode bitmap：i节点位图中的每一位表示inode是否可用。自身占一个块data blocks：数据块，用于存放文件、目录的数据inode table:ext2中一个inode占用128byte（记录文件的属性，不包括文件名）,它的属性如下：这里可以看到inode中存储了数据块的地址(block字段)，再结合文件系统布局图，可以看到一共有15个地址。但为什么要设计成12个direct block以及3个一级、二级、三级间接block呢？（细品这些数据结构） 设计成多级间接block是为了支持大容量的文件：(12 + 1024 + 1024^2 + 1024^3) × 4 KB 设计成12个direct block，是因为大多数文件的大小只有2k，这样就可以直接定位到block，而不用去data block间接查找，提高效率 Ext2目录结构data blocks既可以用于存放文件的数据，也可以用于存放目录的数据.其中目录的数据结构如下： 1234567 struct ext2_dir_entry_2 &#123; __le32 inode; // 文件入口的inode号，0表示该项未使用 __le16 rec_len; // 目录项长度 __u8 name_len; // 文件名包含的字符数 __u8 file_type; // 文件类型 char name[255]; // 文件名 &#125;; 目录数据会保存此目录下的所有文件名和目录名，以及文件的入口地址。至于其他的信息则存放在inode节点中 Fat的布局了解完基于inode组织的文件系统之后，我们再来了解下基于链表组织的Fat文件系统。像SD卡的文件系统一般就是Fat32，在Fat文件系统中对应Ext2 Block的描述是簇。它的磁盘布局如下：其中Fat表的位置由DBR来定位，Fat2是Fat1的备份，而Fat表的数据会读到内存中，它的布局如下：它描述了： 簇的分配情况(0表示没有分配)，因此不存在像bitmap这样的数据结构 文件下一个数据块的簇号，因此不需要类似inode的block字段 但从上面的布局中，我们没有找到用于描述文件信息的元数据，其实这些元信息都存放在目录项中，而目录项的数据又存放在数据块中，因此这里看不到。如果想要实际看看文件系统的结构，可以用WinHex可查看存储介质的二进制数据 Ext4的数据管理方式Ext2、Ext3基于表的方式查找数据块;Fat基于链表的方式查找数据块;而Ext4基于extent tree的方式查找数据块。Ext4的数据布局可以直接参考Ext2的布局，下面我们主要看Ext4是如何查找数据块的。Ext4的inode 同样存在i_block[15] 结构，除了可以用于新的Extent tree结构，还可以兼容老的Ext系统。先看Ext2采用表来查找数据块的问题：如果一个文件分配了连续的1000个块，却需要映射这1000个块的地址。而采用extent的方案，连续地址的映射只需要一个起始地址+长度（ee_len）即可extent tree的访问过程：（图片来源：https://zhuanlan.zhihu.com/p/52052278）从数据结构来看，虽然它的名字叫extent tree，但其实与B-树类似。关于Ext4的详细数据结构信息，可以看最后一节给出的链接地址，这里不再详细介绍。 文件读写的过程看完上面常见文件系统的布局之后，我们还需要清楚open、read等函数背后的IO动作 1.读IO时序假设我们的代码如下： 12int fd = open(&quot;/foo/bar&quot;, O_RDONLY);size = read(fd, buffer, sizeof(buffer)); 它的IO过程如下：假如没有采用任何手段，一句open就要产生5次IO访问，在结合HDD的硬件特性，由于这些block是分散的，因此5次IO意味着5*(Tseek+Trotation),基本上需要50ms以上。 2.写IO时序类似的，写的过程如下： 3.性能优化对于读的性能优化，最常用的方案自然是缓存，通过把常用的inode节点缓存起来，就可以大大的减少访问次数。如前面读IO时序中的图，如果把bar inode节点缓存起来，就可以减少后面3次的读写，而常见的缓存策略自然是LRU。写的性能优化，可以通过缓冲buffer来实现，一般的缓冲的设计从时间与空间角度出发，比方每5s写入磁盘一次，或者buffer满了就写一次磁盘。但buffer应该设计成多大呢？这里我们假设一次Tseek+Trotation的时间是10ms，传输速率为40MB/s如果我们想要达到50%的传输宽带，buffer的大小应该是 40*1024*10/1000 = 409 KB虽然使用缓冲虽然能提高传输效率，但如果突然宕机了，就存在数据丢失的风险。 异常恢复-文件系统一致性文件系统在写入数据时，需要修改多个块数据(bitmap、inode、数据块等)，但这个过程并不是原子的。因此如果在写入的过程中突然宕机，就会产生文件系统不一致的情况，这时候就需要进行修复。这里我们仅讨论对元数据的修复，因此像数据块丢失、不一致的问题可以在数据库事务中再讨论。 1.fsck这是在linux系统中自带的工具，它的原理就是扫描bitmap表和inode table，把它们分别记录在2张表中，如下图A:图A表示数据一致，不需要修复。图B表示实际数据块已经分配，但bitmap表无记录，因此只需要把bitmap表的对应位置0(已用)即可。图D的情况比较复杂，可能是某一个文件X刚删除了一个数据块，同时把bitmap表置1(空闲)，但紧接着另一个文件Y申请到了相同的块，于是又把bitmap置0，但还没来的及修改A的inode就宕机了。这种情况fsck也无法修复，因为不知道这个数据块到底属于谁（这时候可以咨询用户，由用户自己决定）。也有一些问题无法修复，比如inode指向错误的数据块，fsck仅能确保元数据的一致性 2.通过日志恢复通过fsck修复文件系统存在一个问题：太慢了。（之前我做的一个项目就是在SD卡挂载之前调用fsck来恢复文件系统的，导致用户插入SD卡的体验非常差，可能需要等20s才能看到SD卡挂载成功）下面我们介绍ext3、ext4(ext2不支持)文件系统所使用的方法，Write Ahead Log策略：每次更新将数据记录到日志文件中，然后在修改实际数据，如果宕机了，通过日志文件对数据进行恢复。日志的数据格式如下：TxB和TxE表示这条日志的开始和结束，它记录了这条日志的ID。按照上图的格式，如果是先一次性写日志，在写实际数据，这样存在3个问题： 写日志的操作不是原子的，一次性写这条数据，可能出现头和尾都写了，但中间数据缺失，但恢复的时候由于头尾已经存在就认为数据完整，但其实是不完整的。 不停的写日志，日志满了怎么办。 数据要写2次，对磁盘空间的利用率以及性能都有影响。 为了解决第一个问题，我们要对日志的写入(日志的写入也采用缓冲)顺序做调整： 先写TxB + 日志数据 等到步骤1完成，在写入TxE (思路类似于多线程中的内存 barrier) 最后再写入实际的元数据与数据块，这个过程也叫checkpoint 基于这个写入顺序，在恢复的时候，只要看TxB和TxE是否匹配就能知道日志中的数据是否完整，这个过程其实也就是ext3、ext4的journal模式。 第二个问题则可以通过采用环形队列的数据结构来解决:在journal的头部增加一个超级块，在超级块中标记最新的日志和最老的日志（理解成2个指针）,在数据满的情况下，每次新写入的日志都覆盖最老的日志。 最后一个问题我们可以让实际数据的写入最先执行来实现，因为我们的目标是保证元数据的一致性。如果写入了数据块，但元数据没写入，最多也只是丢失本次的数据而已，而不会破坏文件系统的结构。因此，日志写入顺序的最终版本如下： 先写实际的数据，即文件内容 写日志中的TxB + 元数据 必须等到步骤2完成，在写入TxE 更新元数据（实际数据的写入已经在第一步完成） 等步骤4完成之后，更新日志超级块的2个指针（最新和最旧） 用图表示：这个过程就是ext3、ext4的ordered模式（默认的模式，可能还存在一些细微差别） 命令与资料命令： 查看是HDD还是SSD的命令：lsblk -d -o name,rota （1表示HDD，0表示SSD） 查看block size：tune2fs -l /dev/sda1 | grep “Block size”书籍：《Operating Systems: Three Easy Pieces》(线上书籍)《Modern Operating Systems》（第四版） HDD/SSD基础知识及工作原理：https://blog.csdn.net/qq_23929673/article/details/103429583SSD程序员需要知道的SSD基本原理：https://zhuanlan.zhihu.com/p/104995703Ext4的详细信息：https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"花最小的学习成本部署web服务","slug":"pythonOther/deployWeb","date":"2021-07-05T11:51:02.000Z","updated":"2021-07-05T11:51:02.000Z","comments":true,"path":"2021/07/05/pythonOther/deployWeb/","link":"","permalink":"https://liji53.github.io/2021/07/05/pythonOther/deployWeb/","excerpt":"","text":"用httpd给程序搭个web界面当你写完程序，需要做推广时，必不可少的需要有个界面。基于这么一个简单背景，花了5天的时间，给自己的程序搞了个web界面，由于之前没有web的实战经验，又不能花大量精力在学习web上，因此有了这篇学习记录 预备知识主要储备知识还是在前端这块： 了解html、css、js，html和js可以在实际过程中边学边用 了解http协议，主要是出问题的时候，可以抓包快速确定是前端还是后端的问题 了解httpd、cgi，主要是要部署web服务器，以及写后端脚本 总体思路1.明确web做什么既然是花最小的学习成本部署web服务，那就需要清楚页面要做什么事，然后针对性的去学习。例如我这次web要做的是读写后台的配置文件。理想的服务端目录结构是这样的： 12345678&#123; &quot;系统1&quot;:&#123; &quot;子系统1&quot;:&#123; &quot;业务1&quot;:&quot;配置文件1&quot;, &quot;业务2&quot;:&quot;配置文件2&quot; &#125; &#125;&#125; web要修改的就是“配置文件1，配置文件2”。基于这个结构，web页面需要3层导航，分别表示 “系统”、‘’子系统“、“业务”，还需要一个能显示配置，同时能修改配置的地方。 2.找一个静态web页面模板找静态的web页面是为了让我们后续动态生成html有参考模板，同时网上的web页面会比自己从零开始写的要好看，不需要自己搞CSS。 3.部署服务器这里采用httpd作为服务器，使用cgi进行交互。httpd部署过程忽略(建议直接用docker) 4.确定交互协议找到合适的模板，部署好服务之后，就要考虑如何与服务器交互了，一般采用http协议，交互的数据格式为json。具体协议设计忽略 5.动态生成html页面这里主要是通过ajax来动态更新页面。 找静态web页面模板我的情况比较简单，只要能体现3层导航的web页面即可，可以从官网的demo中找 地址：https://getbootstrap.com/docs/5.0/getting-started/download/ 其他专业模板(太高端，没玩过)：https://www.w3cschool.cn/msv2es/qmaj1pyd.html 由于我没有经验，找了1个小时才找到合适的模板，模板长这样： 接着去掉内容，只留下html骨架代码。可以看到三个地方留了id属性，用于后续动态生成html 123456789101112131415161718192021&lt;!-- 最上面的导航 --&gt;&lt;div class=&quot;navbar navbar-fixed-top&quot;&gt; &lt;div class=&quot;navbar-inner&quot;&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;!-- id后面动态生成的时候用到 --&gt; &lt;div class=&quot;nav-collapse&quot; id=&#x27;header_system&#x27;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;row-fluid&quot;&gt; &lt;!-- 左边的导航栏 --&gt; &lt;div class=&quot;span3&quot;&gt; &lt;div class=&quot;well sidebar-nav&quot; id=&#x27;left_config&#x27;&gt;&lt;/div&gt; &lt;/div&gt; &lt;!-- 右边配置展示 --&gt; &lt;div class=&quot;span7&quot;&gt; &lt;div style=&quot;padding: 10px 10px 10px;&quot; id=&#x27;right_config&#x27;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 部署服务下载httpd的镜像，启动容器，命令如下： 123456docker pull centos/httpddocker run --name=myHttpd -it -p 192.168.0.1:8089:80 \\ -v /home/liji/apache/html:/var/www/html/ \\ -v /home/liji/apache/cgi-bin:/var/www/cgi-bin/ \\ -v /home/liji/apache/conf:/etc/httpd/conf \\ centos/httpd 修改httpd.conf，前面已经做好路径映射，直接修改/home/liji/apache/conf/httpd.conf 123456&lt;Directory &quot;/var/www/cgi-bin&quot;&gt; AllowOverride None SetHandler cgi-script Options ExecCGI Require all granted&lt;/Directory&gt; 重启httpd容器 1docker restart myHttpd cgi脚本可以用shell，也可以用python， 如果用python则还需要在容器内安装python，可以参考上一篇博客 测试CGI在html中随便加个能发请求的button，用于测试 1&lt;button type=&quot;button&quot; onclick=&quot;cgiHttp(&#x27;test&#x27;)&quot;&gt;测试CGI&lt;/button&gt; js发送请求代码如下： 1234567891011function cgiHttp(func)&#123; url = window.location.href + &#x27;cgi-bin/&#x27; + func + &#x27;.cgi&amp;arg=test&#x27; var request = new XMLHttpRequest() request.onreadystatechange = function() &#123; if (request.readyState==4 &amp;&amp; request.status==200)&#123; alert(request.responseText) &#125; &#125; request.open(&quot;GET&quot;, url, true) request.send(null)&#125; web服务端，在/home/liji/apache/cgi-bin目录下新建test.cgi，内容如下： 12345678import cgi, cgitbimport jsonform = cgi.FieldStorage()# 获取数据site_arg = form.getvalue(&#x27;arg&#x27;)print(&quot;Content-type:text/html&quot;)print()print(&quot;cgi test success! arg = %s&quot; % site_arg) 遇到问题的时候首先抓包，如果返回的是500内部服务错误，直接到/etc/httpd/logs/目录下，查看error_log文件 典型的3种错误有： 1.权限问题 1(13)Permission denied: exec of &#x27;/var/www/cgi-bin/test.cgi&#x27; failed 这种可能是test.cgi 没有执行权限，chmod +x test.cgi 解决 如果你写的cgi脚本需要修改其他目录下的文件，则还需要修改相应目录的权限，参考命令 chown -R apache:apache /home/test 2.执行失败 1(2)No such file or directory: exec of &#x27;/var/www/cgi-bin/previousPick.cgi&#x27; failed 检查test.cgi 是否存在windows字符，这个问题我当时花了半小时才找到。vi -b test.cgi，进入文件看有没有 ^M 字符 3.字符编码 1UnicodeEncodeError: &#x27;ascii&#x27; codec can&#x27;t encode characters in position 4-9: ordinal not in range(128) 这个问题比较恶心，在实际的环境中，脚本需要修改其他目录下的配置文件，而这个目录存在中文，就会报错。我用的是python3.6版本，直接运行脚本不会出错，但用apache用户运行就有问题，即使我在httpd.conf中加入环境变量SetEnv PYTHONIOENCODING utf-8依然没有解决，最后只能不用中文的目录来规避 协议交互假设现在设计了4个协议，对应服务端有4个脚本，分别是getSystem.cgi、getBusiness.cgi、getConfig.cgi、setConfig.cgi，js代码如下： 12345678910111213141516171819202122232425262728/// 根据协议的设计，拼装http请求，为了展示效果不冗余，只拼装1个协议function _get_url(func)&#123; url = window.location.href + &#x27;cgi-bin/&#x27; + func + &#x27;.cgi&#x27; if(func == &#x27;getSystem&#x27;)&#123; url += (&quot;?system=&quot; + g_system) &#125;else&#123; alert(&quot;功能尚未实现，敬请期待！&quot;) return null &#125; return url&#125;function cgiHttp(func)&#123; url = _get_url(func) if (url == null)&#123; return &#125; var request = new XMLHttpRequest() request.onreadystatechange = function() &#123; if (request.readyState==4 &amp;&amp; request.status==200)&#123; response_config = JSON.parse(request.responseText) /// 动态加载html页面 load_func = &#x27;_load&#x27; + func + &#x27;Response(response_config)&#x27; eval(load_func) &#125; &#125; request.open(&quot;GET&quot;, url, true) request.send(null)&#125; 动态更新页面根据前面的协议交互，我们已经能收到服务器的响应了，下面就是拼装html。先确定我们的目标长什么样： 1234567891011&lt;div class=&quot;nav-collapse&quot; id=&quot;header_system&quot;&gt; &lt;ul class=&quot;nav&quot;&gt; &lt;li class=&quot;active&quot; id=&quot;system_system1&quot;&gt; &lt;a onclick=&quot;systemClick(&#x27;system1&#x27;)&quot;&gt;system1&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;disabled&quot; id=&quot;system_system2&quot;&gt; &lt;a onclick=&quot;systemClick(&#x27;system2&#x27;)&quot;&gt;system2&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;disabled&quot; id=&quot;system_system3&quot;&gt; &lt;a onclick=&quot;systemClick(&#x27;system3&#x27;)&quot;&gt;system3&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p class=&quot;navbar-text pull-right&quot;&gt;contract liji37951&lt;/p&gt;&lt;/div&gt; 重点是class=”active” 、 id=”system_system1”、systemClick(‘system1’) 这几个字段是动态的。 1234567891011121314151617function _loadgetSystemResponse(systemConfig)&#123; headerInnerHtml = &#x27;&lt;ul class=&quot;nav&quot;&gt;&#x27; for (var i = 0; i &lt; systemConfig.length; i++)&#123; if (i == 0)&#123; headerInnerHtml += &#x27;&lt;li class=&quot;active&quot;&#x27; g_system = systemConfig[i] &#125;else&#123; headerInnerHtml += &#x27;&lt;li class=&quot;disabled&quot;&#x27; &#125; headerInnerHtml += &#x27; id=&quot;system_&#x27; + systemConfig[i] + &#x27;&quot;&gt;&lt;a onclick=&quot;systemClick(\\&#x27;&#x27; + systemConfig[i] + &#x27;\\&#x27;)&quot;&gt;&#x27; + _toChinese(systemConfig[i])+&#x27;&lt;/a&gt;&lt;/li&gt;&#x27; &#125; headerInnerHtml += &#x27;&lt;/ul&gt;&lt;p class=&quot;navbar-text pull-right&quot;&gt;contract liji&lt;/p&gt;&#x27; document.getElementById(&quot;header_system&quot;).innerHTML=headerInnerHtml&#125; 下面就是实现systemClick这个函数。 123456789function systemClick(system)&#123; if (document.getElementById(&quot;system_&quot;+system).className == &#x27;disabled&#x27;)&#123; document.getElementById(&quot;system_&quot;+g_system).className=&#x27;disabled&#x27; g_system = system document.getElementById(&quot;system_&quot;+system).className=&#x27;active&#x27; cgiHttp(&#x27;getBusiness&#x27;, g_system) cgiHttp(&#x27;getConfig&#x27;, g_business) &#125;&#125; 其他左边的导航栏，右边的配置内容， 方法是一致的。 总结这篇文章，无法直接拷贝代码，帮你完成web的搭建。但我写这篇文章，是为了下次遇到类似问题时提供一个思路，这次花5天时间搞定，下次能2天时间搞定，这就是这篇文章的价值。","categories":[],"tags":[]},{"title":"os-并发","slug":"operatingSystem/os-concurrency","date":"2021-06-29T15:54:28.000Z","updated":"2021-06-29T15:54:28.000Z","comments":true,"path":"2021/06/29/operatingSystem/os-concurrency/","link":"","permalink":"https://liji53.github.io/2021/06/29/operatingSystem/os-concurrency/","excerpt":"","text":"并发并发、互斥、同步在实际开发过程中经常会用到，本文将聚焦于互斥与同步，除了了解底层的互斥原理，还将重点学习glic提供的几种互斥机制。 底层原子操作原子操作：将多个步骤合成一个操作，这个操作要么成功，要么失败。底层原子操作由硬件提供，在阅读同步相关的源码时，会经常看到类似atomic_compare_exchange，atomic_fetch_add等类似的函数，其实这些函数就是封装了这些底层的原子操作指令。因此熟悉这部分原子操作对阅读理解pthread相关的代码十分重要，下面我们看下4种基本的原子操作 test-and-set返回旧值，设置新值 12345int TestAndSet(int *ptr, int new) &#123; int old = *ptr; // fetch old value at ptr *ptr = new; // store ’new’ into ptr return old; // return the old value&#125; compare-and-swap返回旧值，如果旧值与期望值一致，则设置新值 123456int CompareAndSwap(int *ptr, int expected, int new) &#123; int actual = *ptr; if (actual == expected) *ptr = new; return actual;&#125; fetch-and-add返回旧值，更新值 12345int FetchAndAdd(int *ptr, int add_value) &#123; int old = *ptr; *ptr = old + add_value; return old;&#125; 利用fetch-and-add我们可以实现基于ticket的自旋锁,ticket lock能保证执行顺序，实现先来先拿锁： 12345678910111213141516171819typedef struct __lock_t &#123; int ticket; int turn;&#125; lock_t;void lock_init(lock_t *lock) &#123; lock-&gt;ticket = 0; lock-&gt;turn = 0;&#125;void lock(lock_t *lock) &#123; int myturn = FetchAndAdd(&amp;lock-&gt;ticket, 1); while (lock-&gt;turn != myturn) ; // spin&#125;void unlock(lock_t *lock) &#123; FetchAndAdd(&amp;lock-&gt;turn, 1);&#125; load 和 storeload指每次读最新的值store如果没有人写ptr则更新ptr，并返回成功，否则返回失败 1234567891011int LoadLinked(int *ptr) &#123; return *ptr;&#125;int StoreConditional(int *ptr, int value) &#123; if (如果没有人更新ptr) &#123; *ptr = value; return 1; // success! &#125; else &#123; return 0; // failed to update &#125;&#125; 互斥锁了解了硬件提供的几种原子操作之后，我们可以基于这些原子操作实现一些互斥功能。首先来看下mutex，但在看它的实现之前，我么需要清楚如何评估一个锁的好坏，主要从下面2方面考虑： 公平性，主要看是否可能存在“饥饿”现象 性能，从实际环境来评估：cpu是否多核，线程数，临界区的长度 1.自旋锁这个实现比较简单，利用前面的4种原子操作都能实现，如利用compare-and-swap： 1234void lock(lock_t *lock) &#123; while (CompareAndSwap(&amp;lock-&gt;flag, 0, 1) == 1) ; // spin&#125; 下面重点看下它的优劣势：从公平性角度来看，可能存在饥饿现象。（除了上面基于ticket 的spin lock）从性能角度来看，对于单核cpu来说，采用自旋的锁，必然是浪费cpu的，参考虚拟cpu的进程调度但是对于多核的cpu来说（线程数接近cpu核数），如果临界区很短(立马就释放锁)，采用自旋锁，性能将比普通的锁更好 2.nptl互斥锁的实现自旋锁会一直占用cpu，浪费资源，如何让出cpu，让程序更高效。下面我们通过glibc的源码，来看下pthread_mutex的锁实现，pthread_mutex_lock的近似代码： 1234567891011121314151617181920212223242526272829int __pthread_mutex_lock (pthread_mutex_t *mutex)&#123; // 普通锁 if (type == PTHREAD_MUTEX_TIMED_NP)&#123; LLL_MUTEX_LOCK(mutex); &#125; // 嵌套锁/递归锁，允许同一个线程多次加锁 elif (type == PTHREAD_MUTEX_RECURSIVE_NP)&#123; pid_t id = THREAD_GETMEM(THREAD_SELF, tid); // 获取线程id if (mutex-&gt;__data.__owner == id)&#123;return;&#125; // 已经持有锁直接返回 LLL_MUTEX_LOCK(mutex); &#125; // 适应锁，跟自旋锁类似，尝试获取，但过一段时间仍然获取不到，就放弃，并让出CPU elif (type == PTHREAD_MUTEX_ADAPTIVE_NP)&#123; if (LLL_MUTEX_TRYLOCK (mutex) != 0)&#123; do&#123; // 一直尝试获取 if (++cnt &gt; max_cnt)&#123; // 过一段时间仍然获取不到，则放弃，让出CPU LLL_MUTEX_LOCK(mutex); break; &#125; &#125;while(LLL_MUTEX_TRYLOCK(mutex) != 0); &#125; &#125; // PTHREAD_MUTEX_ERRORCHECK_NP 检错锁，如果一个线程2次获取同一个锁则，返回失败 else&#123; pid_t id = THREAD_GETMEM (THREAD_SELF, tid); if (__glibc_unlikely (mutex-&gt;__data.__owner == id))&#123;return EDEADLK;&#125; LLL_MUTEX_LOCK(mutex); &#125;&#125; 代码里清楚的展示了4种锁的上层实现策略，而最关键的LLL_MUTEX_LOCK代码，我们下面讲 3.futex机制先简单介绍下futex，futex机制在linux2.5.7之后开始使用(fast Userspace mutexes)。它的主要优势是在加锁的时候根据共享内存里的futex变量，判断该变量是否有竞争，如果没有竞争则通过原子操作把共享的futex变量置1，这样不需要进入内核态，就可以完成加锁了。而如果有竞争则执行系统调用futex_wait，将需要等待的进程(线程)加入到futex的等待队列中，直到通过futex_wake进行唤醒。futex的结构维护在内核中.它的数据结构大概如下：加入等待队列以及唤醒的基本接口： 1234//uaddr代表futex word的地址，val代表这个地址期待的值，当*uaddr==val时，才会进行waitint futex_wait(int *uaddr, int val);//唤醒n个在uaddr指向的锁变量上挂起等待的进程int futex_wake(int *uaddr, int n); 因此前面pthread_mutex_lock的LLL_MUTEX_LOCK函数如下（参考lowlevellock.h）： 1234567891011void LLL_MUTEX_LOCK(pthread_mutex_t *mutex)&#123; &#x2F;&#x2F; CAS原子操作，如果等于0则置为1，表示没有锁竞争 &#x2F;&#x2F; mutex-&gt;__data.__lock 也就是所谓的futex word if（atomic_compare_and_exchange_bool_acq(mutex-&gt;__data.__lock, 0, 1)）&#123; return; &#125; &#x2F;&#x2F;&#x2F; 有竞争，则阻塞，加入到futex等待队列 else&#123; futex_wait(mutex-&gt;__data.__lock， 1); &#125;&#125; 了解完futex的机制之后，我们再来评估下pthread_mutex的好坏： 公平性：通过futex来管理等待线程，并不能保证它绝对的唤醒先后顺序，取决于OS的调度策略。 性能：无竞争时，不需要进程(线程)切换，性能极好；但存在锁冲突时，需要线程切换，存在性能浪费，但好在提供了自适应锁这种兼容spin lock优势的参数 4.nptl读写锁的实现在读操作频繁，写操作少的情况下，使用读写锁能提高性能，下面我们看下pthread中读写锁的实现(来自glibc-2.35)： 123456789101112131415161718192021222324252627282930313233343536373839___pthread_rwlock_rdlock (pthread_rwlock_t *rwlock)&#123; ... // 原子操作，让reader + 1 r = (atomic_fetch_add_acquire (&amp;rwlock-&gt;__data.__readers, (1 &lt;&lt; PTHREAD_RWLOCK_READER_SHIFT)) + (1 &lt;&lt; PTHREAD_RWLOCK_READER_SHIFT)); // 如果当前为读阶段(即没有写)，则直接返回成功，不阻塞 if (__glibc_likely ((r &amp; PTHREAD_RWLOCK_WRPHASE) == 0))&#123;return 0;&#125; // 如果处于写阶段，但并没有占有锁 while ((r &amp; PTHREAD_RWLOCK_WRPHASE) != 0 &amp;&amp; (r &amp; PTHREAD_RWLOCK_WRLOCKED) == 0)&#123; // 尝试改成读阶段 if (atomic_compare_exchange_weak_acquire (&amp;rwlock-&gt;__data.__readers, &amp;r, r ^ PTHREAD_RWLOCK_WRPHASE))&#123; // 更新写阶段的futex变量，设置为0意味着解锁 if ((atomic_exchange_relaxed (&amp;rwlock-&gt;__data.__wrphase_futex, 0) &amp; PTHREAD_RWLOCK_FUTEX_USED) != 0)&#123; // 唤醒其他阻塞的读线程 int private = __pthread_rwlock_get_private (rwlock); futex_wake (&amp;rwlock-&gt;__data.__wrphase_futex, INT_MAX, private); &#125; return 0; &#125;else&#123;// 不停的重新尝试&#125; &#125; for (;;) &#123; // 处于写阶段，并且锁已经被其他线程占有 while (((wpf = atomic_load_relaxed (&amp;rwlock-&gt;__data.__wrphase_futex)) | PTHREAD_RWLOCK_FUTEX_USED) == (1 | PTHREAD_RWLOCK_FUTEX_USED)) &#123; int private = __pthread_rwlock_get_private (rwlock); // 如果中途 锁已经释放了 if (((wpf &amp; PTHREAD_RWLOCK_FUTEX_USED) == 0) &amp;&amp; (!atomic_compare_exchange_weak_relaxed (&amp;rwlock-&gt;__data.__wrphase_futex, &amp;wpf, wpf | PTHREAD_RWLOCK_FUTEX_USED))) &#123; continue; // 继续尝试，看锁是否又被写进程占有了 &#125; // futex_wait,加入到futex的等待队列 int err = __futex_abstimed_wait64 (&amp;rwlock-&gt;__data.__wrphase_futex, 1 | PTHREAD_RWLOCK_FUTEX_USED, clockid, abstime, private); &#125; ...&#125; 上面的代码如果理解有困难，可以参考下面读写锁各个阶段的情况： 123456789101112131415161718// WP 指的是读写阶段他，WL 指的是写锁， R 指的是读的线程数(也代表读锁)， RW 指的是是否有读线程在等待 State WP WL R RW Notes --------------------------- #1 0 0 0 0 Lock is idle (and in a read phase). #2 0 0 &gt;0 0 Readers have acquired the lock. #3 0 1 0 0 Lock is not acquired; a writer will try to start a write phase. #4 0 1 &gt;0 0 Readers have acquired the lock; a writer is waiting and explicit hand-over to the writer is required. #4a 0 1 &gt;0 1 Same as #4 except that there are further readers waiting because the writer is to be preferred. #5 1 0 0 0 Lock is idle (and in a write phase). #6 1 0 &gt;0 0 Write phase; readers will try to start a read phase (requires explicit hand-over to all readers that do not start the read phase). #7 1 1 0 0 Lock is acquired by a writer. #8 1 1 &gt;0 0 Lock acquired by a writer and readers are waiting; explicit hand-over to the readers is required. 注意：读不占用锁，只有写才占用锁，#3，#4，#4a 这三个阶段 为wrlock加锁的情况，需要等R的个数为0，才能进行写。关于读写锁饿死的情况, 在rdlock源码中并没有看到处理，因此如果写频繁，请不要使用读写锁。引用一句话“Big and dumb is better”，不要过分追求像读写锁这种听起来炫酷，但使用复杂的玩意。 5.提高并发性能这里仅指优化锁的开销，从而提高并发性能从前面的futex机制，我们知道如果出现锁冲突，就会有进程(线程)切换的开销(上下文切换、进程调度)，因此如何优化锁，核心在于减少锁的冲突： 减少锁的持有时间，在锁的过程中不要使用会阻塞的接口，从时间颗粒度的角度考虑。 减少锁的空间颗粒度，将临界数据打散，每个分散后的临界数据各使用一把锁，代替全局的锁。因为数据分散之后，访问某一个数据的概率就减少了，锁冲突也就减少了。 避免使用锁,使用线程本地存储(比方TLS)。思路就是把临界数据变成线程局部数据，一段时间之后再更新回临界数据中。 在读操作频繁，写操作少的数据结构中，使用读写锁;在临界区短，冲突频繁的场景中使用自旋锁。 放弃用锁，使用wait-free的思路，比方使用无锁的数据结构。 下面针对第二点，我们看下常见的数据结构如何从空间颗粒度角度，减少锁的开销： 双向队列，使用2把锁代替1把锁123456typedef struct __queue_t &#123; node_t *head; node_t *tail; pthread_mutex_t headLock; pthread_mutex_t tailLock;&#125; queue_t; 哈希表，每个哈希桶一把锁，哈希值不冲突就不会存在锁冲突1234typedef struct __hash_t &#123; list_t lists[BUCKETS]; pthread_mutex_t bucketLock[BUCKETS];&#125; hash_t; 针对第三点采用TLS数据，看个多线程计数器的列子：123456789101112131415typedef struct __counter_t &#123; int global; // global count pthread_mutex_t glock; // global lock int local[NUMCPUS]; // 每个线程单独访问，不存在冲突 int threshold; // update frequency&#125; counter_t;void update(counter_t *c, int threadID, int amt) &#123; c-&gt;local[threadID] += amt; // assumes amt &gt; 0 if (c-&gt;local[threadID] &gt;= c-&gt;threshold) &#123; // transfer to global pthread_mutex_lock(&amp;c-&gt;glock); c-&gt;global += c-&gt;local[threadID]; pthread_mutex_unlock(&amp;c-&gt;glock); c-&gt;local[threadID] = 0; &#125;&#125; 条件变量条件变量用于线程的同步，保证线程的执行先后顺序 1.用法条件变量的使用虽然容易犯错，但它的套路其实比较固定的： 1234567891011// 场景：A线程先执行，再执行B线程// A线程：Pthread_mutex_lock(&amp;m);设置条件Pthread_cond_signal(&amp;c);Pthread_mutex_unlock(&amp;m);// B线程：Pthread_mutex_lock(&amp;mutex); // p1while (条件不满足) // p2 Pthread_cond_wait(&amp;cond, &amp;mutex); // p3Pthread_mutex_unlock(&amp;mutex); // p6 常见的错误就是： 没有和锁一起配合使用，或者锁顺序有问题，牢记条件变量要传锁的原因：即Pthread_cond_wait内部实现： 1.先释放锁，2.加入等待队列，3.唤醒之后再加锁 Pthread_cond_wait在等待条件满足时，不用while 而用if， Pthread_cond_wait可能存在虚假唤醒(被信号中断唤醒);也有可能同时唤醒2个线程，但另一个线程执行很快，又把值改回去了(ABA问题) 该使用2个条件变量，却只使用了一个条件变量，参考下面的消费者-生产者的错误模型：123456789101112131415161718192021222324pthread__cond_t cond;pthread__mutex_t mutex;void *producer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // p1 while (count == 1) // p2 Pthread_cond_wait(&amp;cond, &amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(&amp;cond); // p5 Pthread_mutex_unlock(&amp;mutex); // p6 &#125;&#125;void *consumer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(&amp;cond, &amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(&amp;cond); // c5 Pthread_mutex_unlock(&amp;mutex); // c6 &#125;&#125; 这一段代码，如果只有1个消费者和1个生产者似乎没什么问题，但如果consumer(消费者)的线程数是2个就有问题了。错误原因：如果consumer1 发出signal ，但唤醒的不是producer，而是consumer2，consumer2由于条件不满足，又睡眠了（并没有发signal），这时候三个线程就将永远睡眠。 2.生产者-消费者模型正确的代码如下： 123456789101112131415161718192021222324cond_t empty, fill;mutex_t mutex;void *producer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // p1 while (count == MAX) // p2 Pthread_cond_wait(&amp;empty, &amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(&amp;fill); // p5 Pthread_mutex_unlock(&amp;mutex); // p6 &#125;&#125;void *consumer(void *arg) &#123; int i; for (i = 0; i &lt; loops; i++) &#123; Pthread_mutex_lock(&amp;mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(&amp;fill, &amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(&amp;empty); // c5 Pthread_mutex_unlock(&amp;mutex); // c6 &#125;&#125; 3.nptl的实现pthread_cond_wait的源码（来自glibc-2.35） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647int __pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)&#123; ... // wseq低位是group的索引，因此需要加2才表示seq加1 uint64_t wseq = __condvar_fetch_add_wseq_acquire (cond, 2); unsigned int g = wseq &amp; 1; // g是group[1]的索引 uint64_t seq = wseq &gt;&gt; 1; // seq 为序列号 // __wrefs 低3位有其他用处，+8 表示等待者计数 +1 unsigned int flags = atomic_fetch_add_relaxed (&amp;cond-&gt;__data.__wrefs, 8); // 【用户锁，解锁】 err = __pthread_mutex_unlock_usercnt (mutex, 0); // 需要唤醒的等待者个数，__g_signals + g表示当前group unsigned int signals = atomic_load_acquire (cond-&gt;__data.__g_signals + g); do&#123; while (1)&#123; // 如果有信号 if (signals != 0) &#123;break;&#125; // __g_refs 当前组的引用计数+1 atomic_fetch_add_acquire (cond-&gt;__data.__g_refs + g, 2); // 【futex_wait 加入等待队列，阻塞】 err = __futex_abstimed_wait_cancelable64 (cond-&gt;__data.__g_signals + g, 0, clockid, abstime, private); // 重新加载信号个数，被唤醒之后，signal有变化 signals = atomic_load_acquire (cond-&gt;__data.__g_signals + g); &#125; &#125; // 当前有需要唤醒的等待者，尝试获取signal while (!atomic_compare_exchange_weak_acquire (cond-&gt;__data.__g_signals + g, &amp;signals, signals - 2)); // 当前group的起始序列号 uint64_t g1_start = __condvar_load_g1_start_relaxed (cond); // 优先消费之前被wait的等待者，而不是本次的等待者 if (seq &lt; (g1_start &gt;&gt; 1))&#123; if (((g1_start &amp; 1) ^ 1) == g)&#123; // 再次更新信号量 unsigned int s = atomic_load_relaxed (cond-&gt;__data.__g_signals + g); while (__condvar_load_g1_start_relaxed (cond) == g1_start)&#123; if (((s &amp; 1) != 0) || atomic_compare_exchange_weak_relaxed(cond-&gt;__data.__g_signals + g, &amp;s, s + 2))&#123; // 优先唤醒其他等待者 futex_wake (cond-&gt;__data.__g_signals + g, 1, private); break; &#125; &#125; &#125; &#125;done: // 【用户锁，加锁】 err = __pthread_mutex_cond_lock (mutex); return (err != 0) ? err : result;&#125; 上面的代码把异常处理、group的处理等都给省去了，即使如此，阅读这个代码可能依然有困难。建议去glibc阅读源码（里面的注释很详细），搞清楚pthread_cond_t的每个字段的含义之后，阅读就轻松多了。其实我们简化成以下伪代码就好理解了： 1234567891011pthread_cond_wait(cond_t* t, mutex_t* m)&#123; unlock(m); if(atomic_load(t-&gt;futex_signal) == 0)&#123; //如果signal为0，则进入等待队列 futex_wait(t-&gt;futex_signal, 0); &#125; lock(m);&#125;pthread_cond_signal(cond_t* t)&#123; atmoic_ftech_and_add(t-&gt;futex_signal，1); // signal 加1 futex_wake(t-&gt;futex_var, 1); // 唤醒一个等待者&#125; 信号量nptl中的实现1234567891011121314int __new_sem_post (sem_t *sem)&#123; unsigned int v = atomic_load_relaxed (&amp;isem-&gt;value); do&#123; // 溢出 if ((v &gt;&gt; SEM_VALUE_SHIFT) == SEM_VALUE_MAX)&#123; __set_errno (EOVERFLOW); return -1; &#125; &#125;/// 原子+1，如果有其他post导致value变换，则循环尝试 while (!atomic_compare_exchange_weak_release(&amp;isem-&gt;value, &amp;v, v + (1 &lt;&lt; SEM_VALUE_SHIFT))); // 如果有等待的线程，则唤醒一个线程 if ((v &amp; SEM_NWAITERS_MASK) != 0) futex_wake (&amp;isem-&gt;value, 1, private);&#125; 信号量的源码比读写锁、条件变量好理解多了。将这些代码当作lock-free编程去学习，你再去网上的其他lock-free的数据结构也会轻松不少。 并发问题Non-Deadlock在实际软件项目中，非死锁导致的问题可能比死锁导致的问题更多，下面我们看看常见的两种非死锁并发问题： 违背原子性：简单来说就是对于临界数据没有加锁 违背执行顺序：在多线程中由于执行顺序不正确导致的问题，通过条件变量、信号量 来保证同步就可以解决 这类问题看起来很简单，但如果项目工程很大，在处理这些问题时，你需要对代码有较深入的理解才能解决。 DeadLock死锁产生的条件与解决方案： 互斥：资源是独占的且排他使用解决（实现复杂）：不使用互斥锁，而采用wait-free的方案。 请求和保持：进程每次申请它所需要的一部分资源，在申请新的资源的同时，继续占用已分配到的资源。解决（会导致性能差）：在线程获取多个锁之前，先加一把大范围的锁。 不可剥夺：进程所获得的资源在未使用完毕之前，不被其他进程强行剥夺，而只能由获得该资源的进程资源释放。解决（可读性差，异常处理复杂）：使用trylock，尝试获取锁，如果获取锁失败，则释放已经占用的锁，从而让其他进程能获取锁，但释放锁的时候需要考虑资源释放与重新申请的问题。 循环等待：比方A进程占用a锁，同时请求b锁，B进程占用b锁，请求a锁，导致AB进程互相等待解决（最常用的方法）：保持获取锁的顺序一致。 看完死锁的原因以及解决方案之后，并不能杜绝死锁的产生，究其原因，还是软件的复杂度导致的。一般在软件设计中，组件之间的互相依赖、接口的封装 才是导致死锁的根本原因。因此适当的接口使用说明、代码评审、测试覆盖以及代码漏洞检测，在提升软件质量上尤为关键 线程模型最后，我们简单看下进程与线程的区别：进程是资源分配的基本单位，线程是CPU调度的基本单位。线程有独立的线程栈、寄存器。 在《Modern Operating Systems》中提到的线程模型：在linux中pthread库中采用的是1对1的线程模型，即一个用户对应一个内核线程，内核负责每个线程的调度。但这种一对一的模型存在用户态、内核态切换频繁的问题。因此为提升效率，由用户实现支持多对一的定时器模型，能提高一定的效率，但这种模型调度的任务不能阻塞，否则会导致其他任务也不能执行。（之前在某公司做嵌入式开发时，就遇到过这个问题） 资料书籍：《Operating Systems: Three Easy Pieces》(线上书籍)《Modern Operating Systems》（第四版：有介绍futex,线程模型）glibc源码地址：http://ftp.gnu.org/gnu/glibc/","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"OS-虚拟memory","slug":"operatingSystem/os-menoryVirtual","date":"2021-06-19T16:42:07.000Z","updated":"2021-06-19T16:42:07.000Z","comments":true,"path":"2021/06/19/operatingSystem/os-menoryVirtual/","link":"","permalink":"https://liji53.github.io/2021/06/19/operatingSystem/os-menoryVirtual/","excerpt":"","text":"虚拟memory我们知道每个进程都有自己的连续内存空间，比方在64位系统中进程的内存布局：让进程误以为自己拥有完整的内存空间，这就是虚拟内存。而实现虚拟内存技术主要从以下几个角度考虑： 透明，不应该让用户进程感知到物理内存（基本功能） 高效，每一条指令都会跟内存打交道，效率是最重要的指标之一 保护，不光是进程间的保护，还包括内部数据的保护比方代码段只读属性 类似虚拟cpu的实现，虚拟内存也需要一些底层机制与上层策略 分页分页是实现虚拟内存的基本机制，简单来说就是把虚拟地址及物理地址分成诺干个固定大小的页(一般4K)，每个页会被OS(或MMU)映射到实际的物理内存，被映射的物理内存页称为页框(page frame)。 1. 页表和页表项承载这个映射关系的数据结构叫做页表(page Table)(数组)，页表的每一项数据即页表项(page table entry)它的结构如下：其中PFN代表page frame number(页框号) 即实际物理地址的页号其他位的含义这里简单介绍下：present bit(P)：表示这个页是否在物理内存中，如果为0表示在硬盘中（缺页用到）accessed bit(A)：表示这个页是否最近被访问（缺页用到）dirty bit(D)：表示这个页是否写入过数据，如果为1则需要定时写入硬盘read/write bit(R/W)：表示这个页是否可写user/supervisor bit(U/S)：表示这个页属于用户模式还是内核模式能访问PWT,PCD,PAT,G：跟硬件缓存相关 2. 如何映射虚拟地址由2部分(后面讲多级页表时再更新)组成： VPN：virtual page number 即虚拟页号 offset：页内偏移 将虚拟地址转为物理地址，如下图(这里假设6位的地址空间，16byte的页大小)：图中Address Translation就是从页表中获取数据得到PFN再进行转换，但这里有2个问题需要搞清楚： Address Translation由谁来完成 页表到底在哪里 现代的操作系统Address Translation一般由MMU这个硬件来完成，我们先来看地址转化的伪代码（这段伪代码后面还会继续完善）： 123456789101112131415161718// 从虚拟地址中提取VPNVPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT// PTBR指的是页表的基地址，PTE指页表项// 从页表中找到当前虚拟地址的页表项的地址PTEAddr = PTBR + (VPN * sizeof(PTE))// 获取当前页表项（注意：这里需要访问内存）PTE = AccessMemory(PTEAddr)// 检查访问的虚拟地址是否合法if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT)else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT)else // 转化成物理地址 offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (PTE.PFN &lt;&lt; PFN_SHIFT) | offset // 访问实际的物理内存 Register = AccessMemory(PhysAddr) 如果Address Translation这个动作由操作系统来完成，意味着每次访问内存都需要2次，性能直接下降了一半以上。而通过MMU则可以缓存常用的页表项，因此大部分时候只需访问一次内存。页表位于内存中，只需要告诉MMU页表的基地址，MMU就可以自动根据VPN计算出页表的偏移从而取到PTE。页表不需要通过虚拟地址映射，由OS告诉硬件页表的物理地址。(在进程切换时，通过设置CR3寄存器来告诉页表地址) 3.遗留问题根据上面的算法，我们的内存管理存在两个严重的问题： 正如前面所说，地址转化的时候需要访问2次内次，效率低下 页表如果采用1维数组的方式实现，在32位系统中1个进程的虚表就占据了4M，而如果是64位系统，则。。。 TLB第一个问题是如何如何让mmu的转化更快，这就需要缓存(TLB)进行帮助. 1.什么时候用缓存我们再来看下上面的伪代码：PTE = AccessMemory(PTEAddr) 如果这次的内存访问，能提前通过硬件缓存起来，这样就能减少一次内存访问了，这就是TLB的作用。缓存作为一种常用技术，它的有效性常常依赖局部性原理： 时间局部性：最近使用的数据大概率再次使用 空间局部性：数据附近的数据很可能被使用 TLB正是基于这2个局部性原理，从而加快页表的查询 2.更新算法现在基于TLB，来更新地址转化的算法： 12345678910111213141516171819202122VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT// 从TLB中查找页表项(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // 缓存命中 if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &lt;&lt; SHIFT) | Offset AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT)else // TLB 没找到 PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else // 更新TLB TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) // 重新执行指令 RetryInstruction() 这个算法中，如果TLB miss，则通过页表查找页表项，找到之后再更新TLB，并重新执行指令。TLB miss的过程其实即可以由MMU完成也可以由OS来完成，比方RISC指令集的MIPS就是通过OS完成的，而像X86这些CISC指令集的架构则通过硬件完成TLB miss因此，如果由OS完成TLB miss，则是以下算法： 12345678910111213VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT// 从TLB中查找页表项(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // 缓存命中 if (CanAccess(TlbEntry.ProtectBits) == True) Offset = VirtualAddress &amp; OFFSET_MASK PhysAddr = (TlbEntry.PFN &lt;&lt; SHIFT) | Offset AccessMemory(PhysAddr) else RaiseException(PROTECTION_FAULT)else // TLB 没找到 // 通过产生中断，让OS来查找页表项，并更新TLB RaiseException(TLB_MISS) 3.TLB项TLB其实也是一个数组，一般有32、64或者128项，它的每一项内容如下：VPN：虚拟页号,这里只有19位，因为操作系统的虚拟地址占了一半(MIPS架构)PFN：物理页号，有24位，因此最高可以支持64G的物理内存G：全局共享位，如果为1表示这个虚拟地址被所有进程共享（可以用于共享库）ASID：用于区分哪个进程，OS在进程切换时通过上下文切换，设置ASID的寄存器，这样MMU就能区分进程了。C：内存页是如何被缓存的(跟硬件相关)D：这个内存页是否被写入过V：表示这个页的转化是否合法(PTE的V表示的这个页OS有没有分配) 看到这里，其实我自己有几个未解之谜： 硬件是如何根据VPN来查找TLB entry的？从它的数据结构来看，它需要一项一项的比较才行 ASID只有8位，如果进程超过256个，怎么表示？ 不管如何，TLB作为底层机制，它的核心作用就是缓存部分PTE，从而加快MMU的地址转化 多级页表多级页表用于解决一维线性页表占用内存大的问题。 1.新的数据结构这部分内容个人觉得存粹就是数据结构的知识了，通过增加一层页目录，从而让大部分无用的虚拟地址不在占用页表空间。这里仅仅展示了2级的页表，在实际linux内核中，为了支持64位地址空间，会有4级页表。 2.新的转化由于页表的数据结构改变，因此映射的方式也需要做细微调整。内核在设计时一个页表、页目录的大小应该要刚好等于页大小。这里我们以2级页表、4K页大小、32位地址空间做示例，如果页表项的大小为4byte，则页目录刚好占10位。 它的虚拟地址结构如下：它的MMU地址转化伪代码： 12345678910111213141516171819202122232425VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // TLB Hit ... //参考上一节的代码else // TLB Miss // 页目录的索引 PDIndex = (VPN &amp; PD_MASK) &gt;&gt; PD_SHIFT // 找到对应页目录项 PDEAddr = PDBR + (PDIndex * sizeof(PDE)) PDE = AccessMemory(PDEAddr) if (PDE.Valid == False) RaiseException(SEGMENTATION_FAULT) else // 页表的索引 PTIndex = (VPN &amp; PT_MASK) &gt;&gt; PT_SHIFT // 从页目录项中找到页表的基地址，在加上页内偏移地址，得到页表项的地址 PTEAddr = (PDE.PFN &lt;&lt; SHIFT) + (PTIndex * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() 缺页从前面的分页机制中，我们已经实现了虚拟内存的功能，让用户感知不到物理内存，但物理内存空间毕竟是有限的，如果进程，把物理空间用完了，这怎么办呢？这就需要再制造一个假象，让进程误以为有无穷大的物理内存。内核通过将物理内存的页置换到硬盘，实现这个假象。 缺页处理如果发生TLB miss，并且虚拟地址映射的物理页不存在时(或物理页满)，则需要缺页处理，新的伪代码如下： 123456789101112131415161718VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT(Success, TlbEntry) = TLB_Lookup(VPN)if (Success == True) // TLB Hit ... //参考前面的代码else // TLB Miss PTEAddr = PTBR + (VPN * sizeof(PTE)) PTE = AccessMemory(PTEAddr) if (PTE.Valid == False) RaiseException(SEGMENTATION_FAULT) else if (CanAccess(PTE.ProtectBits) == False) RaiseException(PROTECTION_FAULT) else if (PTE.Present == True) TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits) RetryInstruction() else if (PTE.Present == False) // 触发缺页中断，由OS处理中断 RaiseException(PAGE_FAULT) 一旦没有找到物理页，硬件就会触发page fault，于是OS就去处理缺页中断，它的伪代码如下： 12345678// 找一个空闲的物理页。PFN = FindFreePhysicalPage()if (PFN == -1) // no free page found PFN = EvictPage() // 通过页置换算法，淘汰页 DiskRead(PTE.DiskAddr, pfn) // 从硬盘中读取代码、数据 PTE.present = True // 表示在物理内存中了 PTE.PFN = PFN // RetryInstruction() // 从新执行指令 前面PTE中提到的present bit在这里终于有用武之地了 页置换策略前面讲了缺页的处理，但哪个内存页置换出去呢？这关乎到进程的内存访问效率，因此页置换算法至关重要。 LRU算法如果OS能知道进程未来需要访问哪个内存页，就可以根据哪个内存页最后使用就把这个页置换出去，这种算法无疑是最好的，但这就跟进程调度算法一样，OS并不知道未来是怎么样的。虽然未来不可知，但我们可以通过历史来推断未来，经典的算法LRU和LFU就是基于历史的使用情况来推断未来的，其实它的思想跟前面讲TLB缓存的局部性思想是一致的。 由于要实现精准的LRU算法，效率往往比较低下，因此一种近似LRU的算法在OS中更加常见：这种算法需要硬件和OS配合，当访问内存页时，由MMU硬件设置页表项的access bit(reference bit)为1，表示这个页最近被访问了。当OS在处理缺页中断时，会遍历环形链表，如果reference bit位为0，则说明最近没有使用，因此可以置换，如上图所示。进一步完善这个算法：如果页面写入过数据，则最好不要置换，因为OS后面会再次把页写入到磁盘，如果加上dirty bit，有以下优先级： reference bit为0，且dirty bit为0。优先级最高 reference btt为0，且dirty bit为1 reference btt为1，且dirty bit为1。优先级最低，需要经过一轮循环之后 参考资料书籍：《Operating Systems: Three Easy Pieces》 线上书籍","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"OS-虚拟CPU","slug":"operatingSystem/os-virtualization","date":"2021-06-15T21:54:20.000Z","updated":"2021-06-15T21:54:20.000Z","comments":true,"path":"2021/06/15/operatingSystem/os-virtualization/","link":"","permalink":"https://liji53.github.io/2021/06/15/operatingSystem/os-virtualization/","excerpt":"","text":"虚拟CPU今天我们的主角是进程，通过任务管理器即可以看到当前运行着的进程，不知道你有没有疑惑过为什么可以有这么多的进程同时运行。迷惑我们让我们产生多进程同时在做事情的假象的核心技术(之一)就是’虚拟cpu’，即把CPU共享给每个进程，以至于让进程误认为自己拥有全部的cpu。而实现虚拟cpu的技术，主要通过几种底层机制(时钟中断、软中断、上下文切换)以及1种上层策略(进程调度策略)来实现。首先我们看下进程的状态转化图(实际不止3种)：这张图包含了我们本次要讲的重点 进程切换看到进程切换，大家可能会想到通过OS来管理进程资源，由OS来切换进程，这不是很简单嘛？但如果进程一直占有cpu，也就意味着无法进入到内核，这还怎么切换进程呢，同时如果这个进程要访问没有权限的资源时应该怎么办呢？ 1.软中断(trap)为了能够顺利进入到内核，主要有2种方式(软中断和硬中断)，我们先介绍主动进入内核的办法-系统调用(通过各种异常也能进入)，通过系统调用也解决了上面权限的问题。 之前在《c/c++反汇编》已经对应用层的系统调用汇编代码做过一波分析了。现在我们再简单讲下后面的流程：通过syscall指令使执行逻辑从用户态切换到内核态，在进入到内核态之后，cpu会从指定的寄存器中读取内核代码的入口地址，进入内核代码之后，自然就可以通过rax读取系统调用号，再从system call table转到对应的处理函数中。 到这里我们就会产生一些困惑，因为从用户态到内核态，硬件到底做了什么呢？在《Operating Systems: Three Easy Pieces》写道：硬件会把cpu的模式从用户模式切换到内核模式，同时会保存寄存器到内核栈，但实际呢？其实最好的答案还是亲自到官方上找相应cpu架构的指令集。比方intel，从Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 2B: Instruction Set Reference, M-U这一章节就有syscall的描述 最后我们再来理解下这个流程： 2.时钟中断而另一种被动的进入内核的方法就是时钟中断，一旦时钟中断产生，cpu就会自动运行到内核态，怎么知道去哪里运行内核呢，跟前面的做法一样，在启动时给硬件设置对应的处理时钟中断地址。依靠这个中断，我们就能把进程按照时间段进行切分(进程运行的基本时间单位)，一个进程运行一段时间，然后硬件定时器发生一个时钟中断，于是进程就被动的进入内核，内核再根据调度策略决定下面运行哪个程序，如此反复。简单看下来自xv6的源码： 1234567891011121314151617181920212223timerinit()&#123; ... // prepare information in scratch[] for timervec. // scratch[0..2] : space for timervec to save registers. // scratch[3] : address of CLINT MTIMECMP register. // scratch[4] : desired interval (in cycles) between timer interrupts. uint64 *scratch = &amp;timer_scratch[id][0]; scratch[3] = CLINT_MTIMECMP(id); scratch[4] = interval; // 把定时器的参数写入到mscratch寄存器，timervec中需要读取对应的参数，并设置定时器。 w_mscratch((uint64)scratch); // set the machine-mode trap handler. //在启动时给硬件设置对应的处理时钟中断的地址。 w_mtvec((uint64)timervec); // enable machine-mode interrupts. w_mstatus(r_mstatus() | MSTATUS_MIE); // enable machine-mode timer interrupts. w_mie(r_mie() | MIE_MTIE);&#125; 进程的切换主要靠时钟中断、系统调用，流程图： 上下文切换从上面的进程切换中，我们已经了解底层实现的机制，但我们知道寄存器只有这么一些，切换后进程如何回到一开始的状态呢？上下文切换主要分为2部分(其实还应该包括页表的切换等)： 硬件自动保存的寄存器 当OS决定切换时，手动保存的寄存器 其中通过软件保存的寄存器，我们看下xv6的代码： 123456789101112131415161718192021222324252627.globl swtchswtch: /// a0寄存器保存了c-&gt;context的地址 sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) ... /// a1寄存器保存了p-&gt;context的地址 ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ... ret// Saved registers for kernel context switches.// 上下文的结构体struct context &#123; uint64 ra; uint64 sp; // callee-saved uint64 s0; uint64 s1; ...&#125;;/// 参数1: 当前进程的上下文/// 参数2: 切换进程的上下文swtch(&amp;c-&gt;context, &amp;p-&gt;context); 进程调度策略(MLFQ)在讲调度策略之前，我们需要先了解下OS进行进程切换时根据什么来选择哪个进程： 周转时间： Tturnaround = Tcompletion − Tarrival 响应时间： Tresponse = Tfirstrun − Tarrival 2种基本算法最短作业优先(Shortest Job First):这是一种周转时间最好的算法，它的策略就是根据程序运行时间(最短优先)来决定运行哪个程序，但这种算法有几个问题： OS并不知道进程的运行时长是多少 响应时间长，需要等最短作业的程序运行完，才响应，可能存在饿死现象 轮询调度算法(Round Robin):这种算法就是通过定时器进行时间切片，轮换的切换进程，进程都是平等的。这种算法拥有最好的响应时间与公平性。但它最大的问题就是周转时间太长，每个进程都是最长运行时间 多级反馈队列(现代OS的主流)这种算法就是结合了SJF和RR算法的优点，使程序有较好的周转时间和响应时间。 首先看下这个算法怎么结合SJF算法的：通过对进程进行优先级分类，把进程放到不同的优先级的队列中。再看它怎么结合RR算法的：对于同一优先级的程序，使用RR算法，轮换运行进程，就可保证它们的响应时间因此它的快照长这样：根据这张图，我们得到MLFQ的2条基本规则：一. 如果Ａ的优先级大于Ｂ的优先级，运行Ａ，不运行Ｂ二. 如果Ａ的优先级等于Ｂ的优先级，论转运行Ａ和Ｂ 但之前在讲SJF算法时，它还存在一个问题即OS并不知道进程的运行时间是多长,如果不知道他的运行时间，我们怎么对进程进行分类呢？其实OS会根据观察进程的行为，来动态调整它的优先级．比方如果进程一直占用CPU，OS就认为它的优先级低，而如果一个进程在用完时间片之前就放弃cpu则认为它是高优先级。 因此我们再得到MLFQ的2条基本规则：三. 进程第一次加载，把该进程放在最高优先级四. 如果进程用完时间片则降低优先级；如果没用完就放弃cpu则保持当前优先级 再优化下MLFQ基于上面的MLFQ算法，我们思考下MLFQ这个算法还存在什么问题？ 存在饥饿现象，即如果有很多的高优先级进程，那么低优先级的进程很可能长时间得不到运行 用户可以操控调度器，简单来说就是进程可以在时间片结束之前，假装放弃cpu，从而让进程一直保持在高优先级 我们先来看怎么解决第一个问题，即MLFQ的又一条规则：五. 一段时间之后，将所有进程都放到最高优先级（重置） 例子如图所示： 下面我们再看如何解决第二个问题，这个问题的根源是时间片是固定的，因此进程只要计算出计算片的时长就能利用了，解决办法就是优化第四条规则：四. 给进程分配不固定的时间，一旦进程用完时间，就降低优先级。例子如图所示： MLFQ的进阶如何让MLFQ工作更高效，更公平，这就需要根据环境调整它的参数，主要涉及到以下的参数： 优先级队列的个数 每个队列，分到的时间片长度 多久时间重置进程优先级 这里给出书中提到的solaris系统的参数 60个队列 高先级的进程分到的时间最短20ms，低优先级的进程时间片最长几百毫秒 每隔1秒重置一次进程优先级 参考资料书籍：《Operating Systems: Three Easy Pieces》线上书籍《Modern Operating Systems》（第四版）xv6代码：https://github.com/mit-pdos/xv6-riscv.gitPS：对于新手特别推荐阅读《Operating Systems: Three Easy Pieces》英文原版","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"c/c++反汇编","slug":"compileAssemblyLink/disassembly","date":"2021-06-10T19:51:03.000Z","updated":"2021-06-10T19:51:03.000Z","comments":true,"path":"2021/06/10/compileAssemblyLink/disassembly/","link":"","permalink":"https://liji53.github.io/2021/06/10/compileAssemblyLink/disassembly/","excerpt":"","text":"c/c++反汇编有人说编程的最高境界是人机合一，为了达到这个境界，我们开始学习反汇编，做到写一段代码，脑中就自动反射出相应的汇编代码本文我们分析c/c++常用的语句，看它的汇编代码是怎样的，下面例子都是linux上编译的（对新手来说，直接用vs看反汇编，缺少了思考的过程） 基本语句反汇编编译器不同、优化选项不同会导致生成的汇编代码不一致，接下来的汇编代码是gcc在没有优化的情况下编译出来的。 1.全局变量与局部变量123456789101112131415// 没有指令，编译器会把这个全局变量放到.data段/*Hex dump of section &#x27;.data&#x27;: 0x00601020 00000000 11000000 ........*/int g = 0x11;int main()&#123; // 计算过程：0x4004d1 + 0xa(指令长度) + 0x200b49 = 0x601024（g的地址） /* 指令： 4004d1: c7 05 49 0b 20 00 88 mov DWORD PTR [rip+0x200b49],0x88 # 601024 &lt;g&gt; 4004d8: 00 00 00 */ g = 0x88; // mov DWORD PTR [rbp-0x4],0x1 int a = 1;&#125; 全局变量放在数据段中，在链接时修改引用它的指令的地址，可参考《静态链接》局部变量放在栈中。 2.引用与指针12345678// mov DWORD PTR [rbp-0x14],0x1int a = 1;// lea rax,[rbp-0x14]// mov QWORD PTR [rbp-0x8],raxint* p = &amp;a;// lea rax,[rbp-0x14]// mov QWORD PTR [rbp-0x10],raxint&amp; r = a; 从底层实现来看，引用和指针完全没有区别，引用也占用栈空间。 3.const变量12345678910// mov DWORD PTR [rbp-0x10],0x88const int c = 0x88;// lea rax,[rbp-0x10]// mov QWORD PTR [rbp-0x8],raxint* a= (int*)&amp;c;// mov rax,QWORD PTR [rbp-0x8]// mov DWORD PTR [rax],0x22*a = 0x22;// mov DWORD PTR [rbp-0xc],0x88int b = c; 被const修饰之后的变量其实与普通变量没有任何区别，只不过编译器在遇到const修饰的变量时会直接优化成常量值。 4.if和switch1234567// cmp DWORD PTR [rbp-0x4],0x0// jne 4004e7 &lt;main+0x1a&gt; ; else的地址if(a == 0)&#123;...;&#125;// cmp DWORD PTR [rbp-0x4],0x1// jne 4004f6 &lt;main+0x29&gt; ; else的地址else if(a == 1)&#123;...;&#125;else&#123;...;&#125; 有多少个if分支，就有多少个cmp指令 12345678910111213/*cmp DWORD PTR [rbp-0x4],0x5 ja 400518 &lt;main+0x4b&gt; mov eax,DWORD PTR [rbp-0x4] mov rax,QWORD PTR [rax*8+0x4005b0]*/switch(i)&#123; case 1: ...;break; case 2: ...;break; case 3: ...;break; case 4: ...;break; case 5: ...;break; default: break;&#125; switch 不管case分支多少(根据我的测试要5个分支及以上)，采用数组索引的方式，直接跳转，相比if语句不仅占用空间小，而且耗时上是O(1)的算法。如果case 不连续怎么办？按照《老码识途》所说，自己多动手思考下吧。 5.数组与结构体12345678// mov QWORD PTR [rbp-0x20],0x0// mov QWORD PTR [rbp-0x18],0x0// mov DWORD PTR [rbp-0x10],0x0int a[5] = &#123;0&#125;;// mov DWORD PTR [rbp-0x30],0x1// mov DWORD PTR [rbp-0x2c],0x2typedef struct cStruct&#123;int a; int b;&#125;cStruct;cStruct c = &#123;1,2&#125;; 数组和结构体的内存布局一样，无非就是编译器给我们提供了一个自动求取偏移量的方法。 函数的反汇编每个函数的开头和结尾大部分都有这么一段code（它的含义就不介绍了),应该做到看到类似代码本能的就想到这是一个函数： 123456789101112 push rbp mov rbp,rsp ... pop rbp ret # 或者 push rbp mov rbp,rsp sub rsp,0x10 ... leave ret 1.函数调用1234567891011121314151617181920// 调用方// mov esi,0x4// mov edi,0x2// call 4004cd &lt;add&gt;// mov DWORD PTR [rbp-0x4],eaxint s = add(2, 4);// 被调用函数/* push rbp mov rbp,rsp mov DWORD PTR [rbp-0x4],edi mov DWORD PTR [rbp-0x8],esi mov eax,DWORD PTR [rbp-0x8] mov edx,DWORD PTR [rbp-0x4] add eax,edx pop rbp ret */int add(int a, int b)&#123;return a+b;&#125; 没有亲自动手反汇编之前，或者仅从老的书本了解，你可能以为是通过栈传递参数的。但x86-64通过寄存器传递参数(参数个数小于等于6，超过6个的通过栈传递)。你可能知道这跟fastcall一样，但其实x86-64中只有一种调用约定：调用方清理堆栈。一般你可能要记住： e[r]di 是第一个参数，e[r]si 是第二个参数，剩下的参数用到的时候百度 看到rbp-xxx 的时候，你要知道这是参数，遇到rbp+xxx的时候，知道这是函数内部变量 2.系统调用我们拿mmap做为例子： 1234567891011/* 4005d0: 41 b9 00 00 00 00 mov r9d,0x0 4005d6: 41 b8 ff ff ff ff mov r8d,0xffffffff 4005dc: b9 22 00 00 00 mov ecx,0x22 4005e1: ba 03 00 00 00 mov edx,0x3 4005e6: be 00 00 02 00 mov esi,0x20000 4005eb: bf 00 00 00 00 mov edi,0x0 4005f0: e8 9b fe ff ff call 400490 &lt;mmap@plt&gt; 4005f5: 48 89 45 f8 mov QWORD PTR [rbp-0x8],rax*/char* p=(char*)mmap(0, 128*1024, PROT_READ|PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); 其中&lt;mmap@plt&gt;是什么，可以看我之前写的《动态链接》nmmap的用户层入口在glibc中，通过符号表，找到mmap的地址,并反汇编： 1234567891011121314151617181920[liji@null disassembly]$ readelf -s /usr/lib64/libc.so.6 | grep &quot;mmap&quot; 321: 00000000000f8d10 183 FUNC WEAK DEFAULT 13 mmap64@@GLIBC_2.2.5 661: 00000000000f8d10 183 FUNC WEAK DEFAULT 13 mmap@@GLIBC_2.2.5 874: 00000000000751b0 320 FUNC LOCAL DEFAULT 13 _IO_wfile_underflow_mmap ...[liji@null disassembly]$ objdump -d --start-address=0xf8d10 --stop-address=0xf8e00 /usr/lib64/libc.so.6 -M intel00000000000f8d10 &lt;mmap&gt;: ... # 系统调用号，在unistd.h中定义 f8d43: b8 09 00 00 00 mov eax,0x9 # 系统调用中断，在i386中是 int 80 f8d48: 0f 05 syscall f8d4a: 48 3d 00 f0 ff ff cmp rax,0xfffffffffffff000 f8d50: 77 52 ja f8da4 &lt;mmap+0x94&gt; ... # 设置errno，在多线程中errno是线程局部变量 f8da4: 48 8b 15 a5 e0 2c 00 mov rdx,QWORD PTR [rip+0x2ce0a5] # 3c6e50 &lt;.got+0x100&gt; f8dab: f7 d8 neg eax f8dad: 64 89 02 mov DWORD PTR fs:[rdx],eax ... 系统调用号(mmap的系统调用号是9)放在eax中，其他参数放在其他通用寄存器中(可以百度)，返回值通过rax。关于系统调用的原理，参考这张流程图：《Operating_Systems_Three_Easy_Pieces》 3.类成员函数123456789101112131415struct A&#123; int a; // mov QWORD PTR [rbp-0x8],rdi ; this指针 // mov rax,QWORD PTR [rbp-0x8] ; rax = this // mov DWORD PTR [rax],0x1 ; *this = 1 void func()&#123;a=1;&#125;&#125;;int main()&#123; // mov DWORD PTR [rbp-0x10],0x0 A a = A(); // lea rax,[rbp-0x10] ; rax = &amp;a // mov rdi,rax ; 传参 // call 400520 &lt;_ZN1A4funcEv&gt; a.func();&#125; 从这段汇编代码可以看出：1.编译器不一定给每个类都生成默认构造函数和析构函数；2.类成员函数会隐藏参数this，通过把对象的首地址传进去，从而实现访问对象的数据进一步：类成员函数放在代码段，也就是说每个对象共享这个代码段，对象拥有的是数据的副本 4.虚函数虚函数的反汇编就不在这里分析了，可看《静态链接》对虚表反汇编的分析 c++11新特性的反汇编我们选择比较简单的进行分析，而像std:function、智能指针的反汇编限于篇幅不在本次分析中。反汇编的基础学完之后，大家可以好好利用vs和IDA，因为到目前为止，所有的分析都是静态的，而实际中动态的分析更加实用。 1.右值引用和移动语义记得编译时加上-fno-elide-constructors，强制生成对应的构造函数，否则编译器很可能优化掉无用的构造函数 1234567891011121314151617181920212223242526272829struct A&#123; int* a; A():a(new int(1))&#123;&#125; ~A()&#123;delete a;&#125;/* 400910: mov QWORD PTR [rbp-0x8],rdi # this指针 400914: mov QWORD PTR [rbp-0x10],rsi # right对象的地址 400918: mov edi,0x4 # new的参数 40091d: call 400690 &lt;_Znwm@plt&gt; # operateor new 400922: mov rdx,QWORD PTR [rbp-0x10] 400926: mov rdx,QWORD PTR [rdx] # rdx = *right 400929: mov edx,DWORD PTR [rdx] # edx = right.a 40092b: mov DWORD PTR [rax],edx # new出来的空间 = right.a 40092d: mov rdx,QWORD PTR [rbp-0x8] # 400931: mov QWORD PTR [rdx],rax # this.a = new返回的地址*/ A(const A&amp; right):a(new int(*right.a))&#123;&#125;/* 40093a: mov QWORD PTR [rbp-0x8],rdi # this 40093e: mov QWORD PTR [rbp-0x10],rsi # right 400942: mov rax,QWORD PTR [rbp-0x10] 400946: mov rdx,QWORD PTR [rax] 400949: mov rax,QWORD PTR [rbp-0x8] 40094d: mov QWORD PTR [rax],rdx # a(right.a) 400950: mov rax,QWORD PTR [rbp-0x10] 400954: mov QWORD PTR [rax],0x0 # right.a = nullptr*/ A(A&amp;&amp; right):a(right.a)&#123;right.a = nullptr;&#125;&#125;; 从汇编来看，右值引用与普通引用是一回事，进一步来说如果引动构造函数和拷贝构造函数的实现一样，两者的汇编也一样。 2.lambda匿名函数12345678910111213141516171819/* 400540: mov DWORD PTR [rbp-0x4],0x1 400547: mov eax,DWORD PTR [rbp-0x4] 40054a: mov DWORD PTR [rbp-0x10],eax 40054d: lea rdx,[rbp-0x10] ; 变量s的地址 400551: lea rax,[rbp-0x20] ; lambda对象的地址 400555: mov rsi,rdx 400558: mov rdi,rax 40055b: call 40051e &lt;`_ZZ4mainENUliiE_C1EOS_`&gt; ; 构造函数 400560: lea rax,[rbp-0x20] 400564: mov edx,0x3 400569: mov esi,0x2 40056e: mov rdi,rax 400571: call 4004fe &lt;_ZZ4mainENKUliiE_clEii&gt; ; 仿函数 400576: mov DWORD PTR [rbp-0x8],eax*/int s = 1;auto f = [=](int a, int b)-&gt;int &#123;return s + a + b; &#125;;int c = f(2, 3); 这里调用了2个函数：_ZZ4mainENUliiE_C1EOS_ 和_ZZ4mainENKUliiE_clEii我们用c++filt来看下他们到底是什么？ 1234_ZZ4mainENUliiE_C1EOS_main::&#123;lambda(int, int)#1&#125;::main(&#123;lambda(int, int)#1&#125;&amp;&amp;)_ZZ4mainENKUliiE_clEiimain::&#123;lambda(int, int)#1&#125;::operator()(int, int) const 第一个是构造函数？还是移动构造函数？，第二个是仿函数，下面分别看下它们的实现： 12345678910111213141516171819202100000000004004fe &lt;_ZZ4mainENKUliiE_clEii&gt;: ... 400502: mov QWORD PTR [rbp-0x8],rdi ; this 400506: mov DWORD PTR [rbp-0xc],esi ; 2 400509: mov DWORD PTR [rbp-0x10],edx ; 3 40050c: mov rax,QWORD PTR [rbp-0x8] ; 400510: mov edx,DWORD PTR [rax] ; 捕获的变量s 400512: mov eax,DWORD PTR [rbp-0xc] ; 400515: add edx,eax ; edx=s+2 400517: mov eax,DWORD PTR [rbp-0x10] 40051a: add eax,edx ; eax = edx+3 ...000000000040051e &lt;_ZZ4mainENUliiE_C1EOS_&gt;: ... 400522: mov QWORD PTR [rbp-0x8],rdi ; this 400526: mov QWORD PTR [rbp-0x10],rsi ; 变量s的地址 40052a: mov rax,QWORD PTR [rbp-0x8] 40052e: mov rdx,QWORD PTR [rbp-0x10] 400532: mov edx,DWORD PTR [rdx] ; 值传递捕获变量s 400534: mov DWORD PTR [rax],edx ; 捕获到的变量值放lamdba对象的第一项 ... 看完反汇编，让我们来反推下它的数据结构与实现代码(这部分仅个人猜测的代码，并无验证)： 1234567891011namespace main&#123; class lambdaIntInt&#123; private: int s; public: lambdaIntInt(int cap):s(cap)&#123;&#125; int operator()(int a, int b) const&#123; return s + a + b; &#125; &#125;;&#125; 看到这里，大家应该对编译器实现的lambda已经了然于心，至于lambda的其他用法的原理，大家自己反汇编即可。 3.初始化列表看到现在，我们应该对反汇编已经有点感觉了，因此找了初始化列表做例子(够简单)，通过仅阅读汇编代码，看看能不能猜出对应的数据结构与实现算法 12345678910111213141516171819202122template&lt;class _E&gt;class initializer_list&#123; // 40072e: mov QWORD PTR [rbp-0x8],rdi // 400732: mov rax,QWORD PTR [rbp-0x8] // 400736: mov rax,QWORD PTR [rax+0x8] size_t size(); // 400740: mov QWORD PTR [rbp-0x8],rdi // 400744: mov rax,QWORD PTR [rbp-0x8] // 400748: mov rax,QWORD PTR [rax] const_iterator begin(); //400757: mov QWORD PTR [rbp-0x18],rdi //40075b: mov rax,QWORD PTR [rbp-0x18] //40075f: mov rdi,rax //400762: call 40073c &lt;_ZNKSt16initializer_listIiE5beginEv&gt; //400767: mov rbx,rax //40076a: mov rax,QWORD PTR [rbp-0x18] //40076e: mov rdi,rax //400771: call 40072a &lt;_ZNKSt16initializer_listIiE4sizeEv&gt; //400776: shl rax,0x2 //40077a: add rax,rbx const_iterator end();&#125;; 函数原型已经给出，函数开头和结尾的汇编代码去掉了。看完反汇编代码，可以自己去linux上找源码，注意：vs的实现跟gnu的实现并不一致。 参考资料书籍：《老码识途 从机器码到框架的系统观逆向修炼之路》《C++反汇编与逆向分析技术揭秘》《汇编语言》《程序员的自我修养》","categories":[{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]},{"title":"定制docker镜像","slug":"pythonOther/dockerBuild","date":"2021-06-10T02:38:06.000Z","updated":"2021-06-10T02:38:06.000Z","comments":true,"path":"2021/06/10/pythonOther/dockerBuild/","link":"","permalink":"https://liji53.github.io/2021/06/10/pythonOther/dockerBuild/","excerpt":"","text":"定制docker镜像如果你写出来的应用，领导要求要考虑部署简单、可维护，这时候你应该想到docker，以我工作中的环境为例，部署需要用到httpd、mongodb、svn、python3等。但去hub docker上找相应的镜像，往往只能找到基础镜像，因此需要我们定制自己的镜像 。 准备工作1. 下载docker首先需要下载docker，我的环境是centos 7.6 由于是公司服务器环境，使用curl会连接失败，但好在yum能用 123456sudo yum install -y yum-utils device-mapper-persistent-data lvm2# 更新源地址sudo yum-config-manager --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 安装Docker Engine-Communitysudo yum install docker-ce docker-ce-cli containerd.io 安装完成之后，启动docker 1sudo systemctl start docker 2. 准备基础镜像我选的基础镜像是centos/httpd 1docker pull centos/httpd 但由于环境问题，会出现连接失败，因此需要手动打包镜像 先从能上网的地方下载镜像，比方先在windows上下载镜像，并打包 1234567C:\\Users\\liji&gt;docker pull centos/httpdC:\\Users\\liji&gt;docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 300e315adb2f 6 months ago 209MBliji1211/hexo V1 f03e20ea2889 11 months ago 289MBspurin/hexo latest f03e20ea2889 11 months ago 289MBcentos/httpd latest 2cc07fbb5000 2 years ago 258MB 12# 打包镜像C:\\Users\\liji&gt;docker save -o centos_httpd.tar 2cc07fbb5000 把本地打包的centos_httpd.tar 上传到服务器，并加载镜像 12# 加载镜像docker load -i centos_httpd.tar 定制镜像定制镜像，有2种方法: 第一种是基于基础镜像，在容器中直接修改下载各种软件，然后再把容器保存成镜像即可。另一种是通过Dockerfile来定制镜像，有点像写makefile，最后通过docker build来创建镜像。下面分别介绍： 使用Dockerfile定制 从网上下载mongodb的安装包，放在与Dockerfile同一级目录下 下载地址：https://www.mongodb.com/try/download/community?jmp=nav 新建Dockerfile，文件内容如下： 123456789101112131415161718FROM centos/httpdENV LANG en_US.UTF-8COPY mongodb-org-* /home/RUN mkdir /root/.pip/COPY pip.conf /root/.pip/RUN cd /etc/yum.repos.d/ \\ &amp;&amp; curl -O http://mirrors.aliyun.com/repo/Centos-7.repo \\ &amp;&amp; rm CentOS-Base.repo; mv Centos-7.repo CentOS-Base.repo \\ &amp;&amp; yum makecache; yum clean all; yum makecache; yum -y update \\ &amp;&amp; yum install -y openssl \\ &amp;&amp; yum install -y openssl-devel \\ &amp;&amp; yum install -y python36 \\ &amp;&amp; pip3 install lxml \\ &amp;&amp; yum install -y subversion \\ &amp;&amp; cd /home/ \\ &amp;&amp; rpm -ivh mongodb-org-server-4.0.24-1.el6.x86_64.rpm \\ &amp;&amp; rpm -ivh mongodb-org-shell-4.0.24-1.el6.x86_64.rpm \\ &amp;&amp; mkdir /home/data; mkdir /home/log; touch /home/log/mongod.log Dockerfile命令解释： FROM：指定基础镜像，会先从本地镜像仓库搜索，如果本地没有，则会网上搜索 ENV：设置系统环境变量 RUN：执行在系统里的命令，注意：有多条命令时，尽量写成一条命令 COPY：把本地文件拷贝到镜像里，这里pip.config内容如下 123[global]trusted-host=mirrors.aliyun.comindex-url=http://mirrors.aliyun.com/pypi/simple/ 构建镜像 1docker build -t test:v1 . 至此，一个安装了httpd、python3.6、mongodb、Svn的镜像就完成 手动修改容器镜像 基于前面的准备工作，我们先启动、进入容器 1docker run -it centos/httpd /bin/bash 进入容器之后，首先更新yum源 1234cd /etc/yum.repos.d/ curl -O http://mirrors.aliyun.com/repo/Centos-7.repo rm CentOS-Base.repo -f; mv Centos-7.repo CentOS-Base.repoyum makecache;yum clean all;yum makecache;yum -y update 下载openssl、python3.6、svn 1234yum install -y opensslyum install -y openssl-devel yum install -y python36yum install -y subversion 更新pip源 123456mkdir /root/.pip/cat &gt; /root/.pip/pip.conf &lt;&lt; EOF[global]trusted-host=mirrors.aliyun.comindex-url=http://mirrors.aliyun.com/pypi/simple/EOF 退出容器，按Ctrl+P，再按Ctrl+Q；然后把mongodb的安装包拷贝到容器中 123# 356e587e2f04是容器iddocker cp mongodb-org-server-4.0.24-1.el6.x86_64.rpm 356e587e2f04:/homedocker cp mongodb-org-shell-4.0.24-1.el6.x86_64.rpm 356e587e2f04:/home 再次进入容器，安装mongodb，并启动mongodb 123456789# 进入容器docker exec -it 356e587e2f04 /bin/bash# 安装mongodbcd /home/ rpm -ivh mongodb-org-server-4.0.24-1.el6.x86_64.rpm rpm -ivh mongodb-org-shell-4.0.24-1.el6.x86_64.rpm mkdir /home/data; mkdir /home/log; touch /home/log/mongod.log# 启动mongodb，但一旦重启容器、新建容器，mongodb需要重新启动mongod --dbpath /home/data/ --logpath /home/log/mongod.log --fork 退出容器，并制作镜像 1docker commit 356e587e2f04 test:v2 至此，镜像制作完成 比较2种方式1234[root@null mongo]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest v2 3cd3fd149fd0 45 seconds ago 1.17GBtest v1 150221daf971 4 hours ago 934MB dockerfile的优势： 镜像的体积会更小 可复用","categories":[],"tags":[]},{"title":"动态链接","slug":"compileAssemblyLink/dynamicLd","date":"2021-05-26T20:04:45.000Z","updated":"2021-05-26T20:04:45.000Z","comments":true,"path":"2021/05/26/compileAssemblyLink/dynamicLd/","link":"","permalink":"https://liji53.github.io/2021/05/26/compileAssemblyLink/dynamicLd/","excerpt":"","text":"动态链接静态链接存在2个主要问题：1.内存、磁盘空间浪费严重，每个进程都有自己的独立内存空间，需要对每个共享库都分配内存空间2.更新、发布需要重新编译，假如软件中其中一个库是第三方提供的，一旦更新这个库需要将整个程序重新编译链接。 动态库为了解决上面的两个问题，它的核心思想就是将链接过程推迟到运行时，并且将指令共享给多个进程。 动态库的文件格式首先回看下前文静态链接中给出的一张elf格式图： 1.program header table只有可执行文件和动态库才有这个table，链接时会把相同属性的section合并在一起，合并后就叫segment，这么做的好处是减少内存页的碎片。通过readelf -l [目标文件] 即可查看program header table，如下图：绿色指的是会映射到虚拟内存中 2.interp section 和 INTERP segment首先看下.interp section 是什么？ – 动态链接器的路径 123456789[liji@null dynamic]$ readelf -S a......[ 1] .interp PROGBITS 0000000000400238 00000238 000000000000001c 0000000000000000 A 0 0 1......[liji@null dynamic]$ readelf -x .interp aHex dump of section &#x27;.interp&#x27;: 0x00400238 2f6c6962 36342f6c 642d6c69 6e75782d /lib64/ld-linux- 0x00400248 7838362d 36342e73 6f2e3200 x86-64.so.2. 动态链接器用于程序运行时的重定位，与静态链接器(ld)不是一个东西。动态链接器的位置并不是环境变量决定的，而是由ELF文件决定的，在加载动态链接器时首先会寻找.interp指向的路径。理解了.interp section之后，INTERP segment 其实就是 .interp section。 3.dynamic section通过readelf -d [可执行文件] 即可查看.dynamic段，如下图：dynamic段描述了动态链接时相关的内容，比方动态链接器就是通过该段寻找动态符号表、依赖的动态库通过ldd命令还可以获取到更全的依赖库信息 12345[liji@null dynamic]$ ldd a linux-vdso.so.1 =&gt; (0x00007ffc3751e000) libmy.so =&gt; not found libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fb64b20d000) /lib64/ld-linux-x86-64.so.2 (0x00007fb64b5db000) 4.dynsym 动态符号表 &amp; .dynstr &amp; .rela.xxx这三种section 在静态链接时我们已经讲过类似的了，他们的功能其实差不多。但动态符号表只保存了动态链接相关的符号，而静态符号表则保存了所有的符号与静态符号表一样，动态符号表也需要dynstr(动态符号字符串表辅助)，即符号表只保存符号的索引，实际的内容保存在字符串表。.rela.plt和.rela.dyn重定位表分别用于函数引用的修正和数据引用的修正，如下图：重定位的实现与静态重定位类似，都是从全局符号表中去查找，找到之后，直接修改.got表中的地址(关于got后面再讲) 5.动态库相关的段下面我们梳理下跟动态库相关的section： 名称 属性 含义 .dynamic 动态库的整体信息 .dynstr alloc 用于辅助动态符号表，保存符号的字符串 .dynsym alloc 动态符号表 .got alloc+write 全局偏移表(后面讲) .got.plt alloc+write 全局偏移表，用于plt .interp 记录动态编译器的位置 .plt alloc procedure linkage table(后面讲) .rela.plt 对函数引用的修正，修正.got.plt .rela.dyn 对数据引用的修正，主要修正.got 动态链接的过程文章开头我们提到了静态链接的问题，那么动态链接是如何解决多进程内存共享的呢？ – PIC 1.PIC技术-地址无关代码在生成so的时候，需要加上-fPIC，就是为了生成地址无关代码。它的核心思想是把指令分成需要被修改的，和不需要被修改的，进程间共享的是不需要修改的指令，而需要修改的指令(其实是需要重定位的地址)则放到数据段，并且每个进程都有一个数据段的副本。接下来的问题就是如何进行地址访问，原理看下图：当需要访问外部模块的变量、函数时，通过数据段里的全局偏移表(got)进行间接访问。而got全局偏移表在静态链接时使用-fPIC的时候生成，同时静态链接器会修改引用的全局数据(函数)的地址（修改成引用got表的地址）got存储了需要重定位的地址列表，这个地址列表需要等程序运行由动态链接器进行修正got section以及动态重定位表的内容如下：再次强调下，静态链接中.rela直接修改的是指令和数据段引用的地址，而在动态链接中.rela修改的是got表中的地址列表。这里还有.got.plt 也属于全局偏移表，具体有什么区别等会讲。got表的数据结构类似于c++的虚函数表，只不过c++的虚表在静态链接期间就确定了。 2.PLT技术-延迟绑定动态库也存在缺点，主要是对性能的影响: PIC技术，每次对函数、数据的访问都需要先经过got表，再寻址，相当于中间加了一层 当程序启动时需要动态链接器进行链接，这过程需要装载用到的动态库，然后进行符号查找，并进行重定位。 而PLT技术用于优化第二项，加快启动的速度 ：它的核心思想是当函数第一次被调用的时候才绑定它有专门的section用于实现它的技术，也就是.plt，我们先看它的内存布局图：plt叫过程连接表，你也可以把它理解成一个函数指针数组，每个需要调用的动态库函数都会有自己的plt条目，如上面的printf就叫printf@plt每个plt项它的长度都固定16字节，它靠汇编来实现。汇编代码： 123456789101112131415161718Disassembly of section .plt:0000000000000550 &lt;.plt&gt;: 550: ff 35 b2 0a 20 00 push QWORD PTR [rip+0x200ab2] # .got.plt 的第二项，即moduleid，参数2 556: ff 25 b4 0a 20 00 jmp QWORD PTR [rip+0x200ab4] # .got.plt 的第三项，即_dl_runtime_resolve() 55c: 0f 1f 40 00 nop DWORD PTR [rax+0x0]# printf的入口,第一次调用时printf地址还没确定，需要_dl_runtime_resolve()进行绑定0000000000000560 &lt;printf@plt&gt;: 560: ff 25 b2 0a 20 00 jmp QWORD PTR [rip+0x200ab2] # &lt;printf@GLIBC_2.2.5&gt; 566: 68 00 00 00 00 push 0x0 # 需要决议的函数下标，即.rela.plt的下标，参数1 56b: e9 e0 ff ff ff jmp 550 &lt;.plt&gt;Disassembly of section .plt.got:0000000000000570 &lt;.plt.got&gt;: 570: ff 25 6a 0a 20 00 jmpq *0x200a6a(%rip) # 200fe0 &lt;__gmon_start__&gt; 576: 66 90 xchg %ax,%ax 578: ff 25 7a 0a 20 00 jmpq *0x200a7a(%rip) # 200ff8 &lt;__cxa_finalize@GLIBC_2.2.5&gt; 57e: 66 90 xchg %ax,%ax 来看下它的地址计算过程：560(printf@plt) + 6(指令大小) + rip(当前地址) + 0x200ab2 = 0x201018 + rip(当前地址)550 + 6(指令大小) + rip(当前地址) + 0x200ab2 = 0x201008 + rip(当前地址)556 + 6(指令大小) + rip(当前地址) + 0x200ab4 = 0x201010 + rip(当前地址).got.plt的地址为： 1234[22] .got PROGBITS 0000000000200fd8 00000fd8 0000000000000028 0000000000000008 WA 0 0 8[23] .got.plt PROGBITS 0000000000201000 00001000 0000000000000020 0000000000000008 WA 0 0 8 正好是.got.plt的2，3，4项，而第一项保存了.dynamic段的地址。rela.plt用于修正.got.plt的地址：可以看到它的地址指向.got.plt的第四项 总结现在我们再来看.got 和 .got.plt 的区别：.got 用来保存全局变量的地址以及不需要用plt技术的函数，如__gmon_start__.got.plt 用来保存函数引用的地址对于全局数据的引用，参考这张图： 对于全局函数的引用，参考这张动态图：这个过程比全局数据的引用要复杂的多，因此需要再简单聊下它的过程： 代码段中调用类似printf的动态库函数，汇编：callq 590 &lt;printf@plt&gt; &lt;printf@plt&gt;会跳转到.got.plt的对应项，汇编：jmp QWORD PTR [rip+0x200ab2] 由于第一次运行.got.plt的项为空，因此，&lt;printf@plt&gt;继续执行后面的语句，汇编：jmp 550 &lt;.plt&gt; &lt;.plt&gt; 是.plt的第一项，用于调用_dl_runtime_resolve()，汇编：jmp QWORD PTR [rip+0x200ab4] &lt;_dl_runtime_resolve&gt; _dl_runtime_resolve的实现在ld-xx.so库中，这个函数作用就是根据需要重定位哪个函数(参数)、moduleid(参数)查找全局的动态符号表，查到之后就把函数地址填到.got.plt对应项中。 第二次调用的时候，只需执行1，2步骤即可，后面的无需再执行 内核装载elf的过程1.静态链接程序的装载 2.动态链接程序的装载动态链接器的运行过程： 命令&amp;资料 readelf -l [可执行文件] 查看program header table readelf -d [可执行文件] 查看.dynamic section参考资料书籍：《程序员的自我修养》博客: https://luomuxiaoxiao.com/?p=578","categories":[{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]},{"title":"静态链接","slug":"compileAssemblyLink/staticLd","date":"2021-05-20T14:44:02.000Z","updated":"2021-05-20T14:44:02.000Z","comments":true,"path":"2021/05/20/compileAssemblyLink/staticLd/","link":"","permalink":"https://liji53.github.io/2021/05/20/compileAssemblyLink/staticLd/","excerpt":"","text":"静态链接当程序编译成可执行文件，需要经历4个步骤，预处理，编译，汇编，链接。本文我们来看看静态链接的原理。 elf文件格式elf文件可以分4种，包括可执行文件、可重定位文件(.o .a)、共享目标文件(.so)、核心转储文件(core dump) 1.文件结构一个elf文件由4部分组成，文件头(elf header)、程序头部表(program header table)、节(section)或段(segment)、节区头部表(section header table),如下图：下图描绘了可重定位文件的格式，也是本次讲的重点: 2.elf header通过readelf -h [目标文件] 就可以查看elf文件头，它描绘了整个文件的基本属性。entry point address对于可重定位文件为0；对于可执行文件指向C库中的_start由于可重定位文件没有program header，因此相关的参数都为0 3.section header table通过readelf -S [目标文件] 可以查看完整的信息（通过objdump -h 只能看到重要信息）。它描绘了elf各个section的信息。每个section的name字段，需要通过.shstrtable来获取。同时也可以看到可重定位文件的虚拟地址还没有分配，等链接之后才能确定。 4.sectionsection的数目比较多，也可以自定义section，这里列举了系统保留的重要section，还有其他的section在动态链接的时候再讲 name 属性 含义 .text alloc+exec 代码段 .init alloc+exec 调用mian函数之前执行的代码段，如c++中全局对象的构造函数 .data alloc+write 数据段-初始化的全局数据 .bss alloc+write bss段-未初始化的全局数据，在装载时分配空间，不占文件空间 .rodata alloc 只读数据段 .symtab 符号表 .strtab 字符串表，保存了符号表用到的符号名，如函数名、变量名 .shstrtab section header table的字符串表，保存了section名 .rel.xxx 重定位表，对代码段或数据段需要重定位才有 .line 行号信息，描述了源程序与机器指令之间的对应关系 .note 注释信息 5.符号表符号表作为一项section，在开发中会经常用到，符号的收集一般发生在编译的词法、语法分析阶段。通过readelf -s [目标文件] 即可以查看符号表，如下图：WEAK表示弱符号，指的是那些通过__attribute__((weak))定义的弱符号，未初始化的全局变量也属于弱符号，但显示的是GLOBAL和COM。弱符号可以被定义多次，因此可以用来hook，比方可以hook malloc、new来定位内存问题。COM用于重定位，当存在多个相同名字的弱符号，重定位时以占用空间最大的那个为准。这也可以说明为什么未初始化的全局变量不放在BSS段，因为大小还没有确定，在重定位完成之后，该变量最终还是放到BSS段 静态链接的过程从原理上来讲，链接器的工作就是：1.确定虚拟地址，2.把一些指令对其他符号地址的引用加以修正。 测试的源文件如下: 1234567extern int shared;extern void swap(int* a, int* b);int c = 1;int main()&#123; int a = 100; swap(&amp;a, &amp;shared);&#125; 编译后链接前读取section header table可以看到虚拟地址都是0读取汇编代码之后，可以看到对外部引用的函数与变量地址都为0再次重申编译的工作就是修改上面2张图的地址而编译器也为地址分配做出了贡献，比方确定了定义在源文件中的函数、数据、指令的相对地址(即本文件中的地址) 修正相对地址(地址分配)首先会对属性相同的段进行合并，比方.init和.text进行合并，这里以数据段为例，如下图:在合并的过程中会计算大小、位置，再根据程序的入口地址，以及偏移地址、相对地址就可以确定虚拟地址同时根据已经确定下来的虚拟地址更新符号表(上面符号表一节，我们可以看到符号的地址大部分为0) 引用符号的重定位经过上一步的修正，函数、变量的虚拟地址已经更新到全局符号表了，剩下的就是将引用这些全局变量、函数的地址修正。但链接器怎么知道哪些函数、变量需要修正呢？– 靠重定位表通过objdump -r [目标文件] 我们看下.rel.text重定位表(如果数据段需要修正,则是.rel.data)的内容其中R_X86_64_32 表示通过绝对寻址修正R_X86_64_PC32 通过相对寻址修正 修改之后，结果如下： 流程图最后把自己绘制的流程图献上 实验：c++虚表的内存布局利用上面学的知识，我们现学现用，看下c++虚表比方，有下面源文件： 1234567891011121314151617struct t_base&#123; int a; virtual void f_call()&#123;&#125; virtual void f_show()&#123;&#125;&#125;;struct t_derive:public t_base&#123; void f_call()&#123;a=1;&#125; void f_show()&#123;a=2;&#125;&#125;;int main()&#123; t_base* a = new t_derive(); a-&gt;f_call(); a-&gt;f_show(); t_base* b = new t_base(); b-&gt;f_call(); b-&gt;f_show();&#125; 符号表找函数地址通过符号表，我们看下相关的地址 123456789101112131451: 000000000040074a 37 FUNC WEAK DEFAULT 14 _ZN8t_deriveC2Ev58: 0000000000400870 24 OBJECT WEAK DEFAULT 16 _ZTI8t_derive64: 000000000040071e 21 FUNC WEAK DEFAULT 14 _ZN8t_derive6f_showEv66: 0000000000400820 32 OBJECT WEAK DEFAULT 16 _ZTV8t_derive67: 0000000000400860 10 OBJECT WEAK DEFAULT 16 _ZTS8t_derive68: 0000000000400708 21 FUNC WEAK DEFAULT 14 _ZN8t_derive6f_callEv71: 000000000040074a 37 FUNC WEAK DEFAULT 14 _ZN8t_deriveC1Ev48: 0000000000400890 16 OBJECT WEAK DEFAULT 16 _ZTI6t_base53: 00000000004006fe 10 FUNC WEAK DEFAULT 14 _ZN6t_base6f_showEv60: 0000000000400840 32 OBJECT WEAK DEFAULT 16 _ZTV6t_base61: 0000000000400734 21 FUNC WEAK DEFAULT 14 _ZN6t_baseC2Ev72: 0000000000400888 8 OBJECT WEAK DEFAULT 16 _ZTS6t_base74: 0000000000400734 21 FUNC WEAK DEFAULT 14 _ZN6t_baseC1Ev77: 00000000004006f4 10 FUNC WEAK DEFAULT 14 _ZN6t_base6f_callEv 上面只截取了跟2个类相关的符号表，如果对c++的符号有疑问，可以通过c++filt直接查看源名 123456[liji@null test]$ c++filt _ZTI8t_derivetypeinfo for t_derive[liji@null test]$ c++filt _ZTV8t_derivevtable for t_derive[liji@null test]$ c++filt _ZTS8t_derivetypeinfo name for t_derive 查看数据段内容我们知道虚表是放在数据段的，而虚表在编译期间就已经确定而且只有一份，实际虚表放在.rodata数据段 1234[16] .rodata PROGBITS 0000000000400800 00000800 00000000000000a0 0000000000000000 A 0 0 32[26] .bss NOBITS 0000000000601040 0000102c 00000000000000c0 0000000000000000 WA 0 0 32 通过查看section header table，可以知道.rodata 的起始虚拟地址是0x400800，同时在可执行文件中的偏移位置是0x800，下面我们就从文件的.rodata段中找下有没有虚表通过命令 readelf -x .rodata [目标文件]，也可以通过hexdump 来查看比对符号表中的地址与rodata中数据，可以得出虚表的内存布局。也可以看到在linux上typeinfo位于虚表的第二项（看前面符号表_ZTI8t_derive的地址正是第二项）而且还能看出typeinfo的内存布局(除了第一项指向了bss段不知道以外，后面分别指向类名，父类的typeinfo地址) 反汇编验证最后看下通过汇编c++是如何实现多态的 123456789101112131415161718192021222324252627282930313233...... 400646: mov edi,0x10 ; 给new传参 40064b: call 400530 &lt;_Znwm@plt&gt; ; 调用 operator new 400650: mov rbx,rax ; new的返回值赋值给rbx 400653: mov QWORD PTR [rbx],0x0 ; 给虚函数指针赋值0，构造时才初始化 40065a: mov DWORD PTR [rbx+0x8],0x0 ; 给成员变量a赋值0 400661: mov rdi,rbx ; 给t_derive构造函数传参 400664: call 40074a &lt;_ZN8t_deriveC1Ev&gt; ; 调用t_derive构造函数 400669: mov QWORD PTR [rbp-0x18],rbx ; 对象地址(也是虚表的地址)放入栈中 40066d: mov rax,QWORD PTR [rbp-0x18] ; rax指向对象的首地址 400671: mov rax,QWORD PTR [rax] ; rax指向虚函数表 400674: mov rax,QWORD PTR [rax] ; rax指向虚函数 400677: mov rdx,QWORD PTR [rbp-0x18] ; 40067b: mov rdi,rdx ; 传参this 40067e: call rax ; 调用f_call() 400680: mov rax,QWORD PTR [rbp-0x18] ; rax指向对象的首地址 400684: mov rax,QWORD PTR [rax] ; rax指向虚函数表 400687: add rax,0x8 ; 虚函数表的第二项 40068b: mov rax,QWORD PTR [rax] ; rax指向虚函数 40068e: mov rdx,QWORD PTR [rbp-0x18] 400692: mov rdi,rdx ; 传参this 400695: call rax ; 调用f_show()......000000000040074a &lt;_ZN8t_deriveC1Ev&gt;: ... 400752: mov QWORD PTR [rbp-0x8],rdi ; 参数，即this指针 400756: mov rax,QWORD PTR [rbp-0x8] ; 对象地址赋值给rax 40075a: mov rdi,rax ; 父类构造传参数 40075d: call 400734 &lt;_ZN6t_baseC1Ev&gt; ; 调用父类的构造函数 400762: mov rax,QWORD PTR [rbp-0x8] ; 400766: mov QWORD PTR [rax],0x400830 ; 关键：给虚函数指针赋值， ; 这里的0x400830正是我们之前看到的地址 ... 写的注释已经够详细了，直接下结论：1.虚函数指针指向的是对应类的虚函数表第一项2.虚函数指针由构造函数初始化 命令&amp;参考资料用到的命令 hexdump [目标文件] 查看二进制内容 readelf -h [目标文件] 查看 elf header readelf -S [目标文件] 查看 section header table objdump -d [目标文件] -M intel 查看 .text 的汇编代码 readelf -s [目标文件] 查看符号表 objdump -r [目标文件] 查看重定位表 readelf -x [section名,如.data] [目标文件] 查看指定段的二进制内容参考资料书籍：《程序员的自我修养》博客：https://blog.csdn.net/mergerly/article/details/94585901","categories":[{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]},{"title":"史上最详细-用docker部署博客","slug":"pythonOther/deployBlog","date":"2021-04-27T11:00:44.000Z","updated":"2021-04-27T11:00:44.000Z","comments":true,"path":"2021/04/27/pythonOther/deployBlog/","link":"","permalink":"https://liji53.github.io/2021/04/27/pythonOther/deployBlog/","excerpt":"","text":"用docker，hexo，github部署博客hexo+github的部署教程，网上详细教程一堆。如果你觉得安装node.js、npm以及再用npm安装各种模块(安装后还会有大量的安装残余)不爽，那欢迎参考本次教程。我们将使用docker来封装运行hexo，hexo镜像非自己制作，我们网上下载 预备知识通过本次教程，虽然可以完成搭建，但还是建议多储备点知识，这样在遇到环境差异时，能快速排查问题。 了解docker，会用常用命令；参考：https://www.runoob.com/docker/docker-tutorial.html 了解hexo，会用常用命令；参考：https://hexo.io/zh-cn/docs/ 了解git、github、markdown docker安装这里只讲win10安装docker，其他环境，请参考其他博客，网上资料很多，不怕搞不定 启用Hyper，Hyper是win10自带的虚拟化技术，docker会在Hyper虚拟出来的环境上运行 安装docker，下载地址：https://docs.docker.com/docker-for-windows/install/ 一路next即可 安装完成之后，cmd下执行docker version，如下所示，说明安装成功 1234567891011C:\\Users\\hspcadmin&gt;docker versionClient: Docker Engine - Community Cloud integration: 1.0.12 Version: 20.10.5 API version: 1.41 Go version: go1.13.15 Git commit: 55c4c88 Built: Tue Mar 2 20:14:53 2021 OS/Arch: windows/amd64 Context: default Experimental: true 修改镜像仓库的配置，最好自己申请一个阿里云的镜像，速度最快 docker启动hexohexo的镜像，从Docker官方的公共仓库找，网址：https://hub.docker.com/search?q=hexo 我选的是spurin/hexo (100K+下载量，说明用的人挺多的) 下载spurin/hexo镜像(我已经提前下载，所以打印提示已经是最新版本) 123456C:\\Users\\hspcadmin&gt;docker pull spurin/hexoUsing default tag: latestlatest: Pulling from spurin/hexoDigest: sha256:4f8a4d8133d5b29d60b86782237673511b3c3b2081b767064d2b922b53bc2ef5Status: Image is up to date for spurin/hexo:latestdocker.io/spurin/hexo:latest 创建容器，命令如图所示 12C:\\Users\\hspcadmin&gt;docker create --name=liji53.github.com -e HEXO_SERVER_PORT=4001 -e GIT_USER=&quot;liji53&quot; -e GIT_EMAIL=&quot;liji_1211@163.com&quot; -v E:/blog:/app -p 4001:4001 spurin/hexo666891af8d09cdc0443cfe157c3fcf10ab3f9739e72673cdf201a030c66d4c75 详细参数说明： –name 给容器指定名称，方便多个博客的管理(非必须) -e HEXO_SERVER_PORT 指定hexo server的端口(注意这个是容器内部的hexo server端口) -e GIT_USER github账户的账户名称(必须与github上的账号保持一致，还没有的赶紧注册) -e GIT_EMAIL github的注册email -v 路径映射，把hexo的app文件夹映射到本地 -p 将容器内部使用的网络端口随机映射到我们使用的主机上 启动容器，需要一段时间。会自动初始化hexo、下载依赖的插件、创建SSH密钥等。(启动的打印很多，我这里仅展示部分) 123456789101112C:\\Users\\hspcadmin&gt;docker start liji53.github.com &amp;&amp; docker logs --follow liji53.github.comliji53.github.com***** App directory exists and has content, continuing ********** App directory contains a requirements.txt file, installing npm requirements ********** App .ssh directory exists and has content, continuing ********** Running git config, user = liji53, email = liji_1211@163.com ********** Copying .ssh from App directory and setting permissions ********** Contents of public ssh key (for deploy) - ********** Starting server on port 4001 *****INFO Validating configINFO Start processingINFO Hexo is running at http://localhost:4001 . Press Ctrl+C to stop. 检查–本地预览效果，出现以下图片说明部署成功了 ，网址：http://localhost:4001/ 替换hexo主题hexo的主题，我们用的是hueman，地址：https://github.com/ppoffice/hexo-theme-hueman 进入容器（也可以不进入容器，后续步骤可直接在windows的映射路径上操作） 12C:\\Users\\hspcadmin&gt;docker exec -it liji53.github.com bashroot@666891af8d09:/app# 下载主题 123456789root@666891af8d09:/app/themes# git clone https://github.com/ppoffice/hexo-theme-hueman.git themes/huemanCloning into &#x27;themes/hueman&#x27;...remote: Enumerating objects: 2272, done.remote: Counting objects: 100% (11/11), done.remote: Compressing objects: 100% (11/11), done.remote: Total 2272 (delta 1), reused 2 (delta 0), pack-reused 2261Receiving objects: 100% (2272/2272), 5.77 MiB | 37.00 KiB/s, done.Resolving deltas: 100% (1216/1216), done.Checking out files: 100% (241/241), done. 如果出现下面这个问题(fatal: unable to access ‘https://github.com/ppoffice/hexo-theme-hueman.git/&#39;: gnutls_handshake() failed: The TLS connection was non-properly terminated.) 则该改成 1git clone git://github.com/ppoffice/hexo-theme-hueman.git themes/hueman 修改hueman的默认配置名称 1root@666891af8d09:/app# mv themes/hueman/_config.yml.example themes/hueman/_config.yml 修改hexo的全局配置，使用hueman的主题，在windows上修改，本例的文件路径是E:\\blog\\_config.yml（在容器中修改，没有vim，需要下载，下载命令 apt update &amp;&amp; apt -y install vim） 打开_config.yml，找到theme这一行，改成hueman，其他_config.yml的用法参考官网 https://hexo.io/zh-cn/docs/configuration 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: hueman 检查–本地预览效果，出现以下图片说明部署成功了，网址：http://localhost:4001/ 如果效果不对，试试重启容器，命令： 1docker restart liji53.github.com &amp;&amp; docker logs --follow liji53.github.com 搭建github博客首先，要注册一个github的账号，注册的邮箱必须要验证，这步就不贴图了 创建仓库 仓库的名字必须是username.github.io，其中username是你的用户名 配置SSH Key当你本地写完博客，提交代码时，必须有github权限才可以，直接使用用户名和密码每次都要输入，很不方便。因此我们使用ssh key来解决这个问题 前面搭建docker+hexo的过程中，已经提到hexo容器帮我们生成了ssh密钥，不需要调用ssh-keygen 密钥的路径在本地映射路径下，参考： 记事本打开.ssh\\id_rsa.pub文件，复制里面的内容，打开你的github主页，进入个人设置-&gt;SSH and GPG keys -&gt; New SSH key, 将刚复制的内容粘贴到key哪里，title随便填 用hexo写博客并上传到这一步，环境已经搭建完成了，只剩考虑该写啥了。。。接下来我们简单验证下 在容器环境下，用命令生成文件；在到windows环境下，打开test.md随便写几句 123root@666891af8d09:/app# hexo new testINFO Validating configINFO Created: /app/source/_posts/test.md 进入容器，用hexo生成博客静态网页(会生成public目录，里面就是生成的网页) 1234567891011root@666891af8d09:/app# hexo gINFO Validating configINFO Start processingDeprecated as of 10.7.0. highlight(lang, code, ...args) has been deprecated.Deprecated as of 10.7.0. Please use highlight(code, options) instead.https://github.com/highlightjs/highlight.js/issues/2277INFO Files loaded in 2.6 sINFO Generated: content.jsonINFO Generated: archives/index.htmlINFO Generated: archives/2021/index.htmlINFO Generated: index.html 上传博客(用hexo d命令只会上传public目录，其他不会上传) 123456789root@666891af8d09:/app# hexo dINFO Validating configINFO Start processingDeprecated as of 10.7.0. highlight(lang, code, ...args) has been deprecated.Deprecated as of 10.7.0. Please use highlight(code, options) instead.https://github.com/highlightjs/highlight.js/issues/2277INFO Files loaded in 2.48 sINFO Generated: content.jsonINFO Generated: archives/index.html 检查–网站预览效果 常见问题及参考 github访问慢、访问失败 参考：https://zhuanlan.zhihu.com/p/15893854 博客图片路径加载失败 参考：https://blog.csdn.net/xjm850552586/article/details/84101345 其他参考 https://spurin.com/2020/01/04/Creating-a-Blog-Website-with-Docker-Hexo-Github-Free-Hosting-and-HTTPS/ https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html","categories":[],"tags":[]}],"categories":[{"name":"C++基础","slug":"C-基础","permalink":"https://liji53.github.io/categories/C-%E5%9F%BA%E7%A1%80/"},{"name":"python杂项","slug":"python杂项","permalink":"https://liji53.github.io/categories/python%E6%9D%82%E9%A1%B9/"},{"name":"操作系统","slug":"操作系统","permalink":"https://liji53.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"编译、汇编、链接","slug":"编译、汇编、链接","permalink":"https://liji53.github.io/categories/%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E3%80%81%E9%93%BE%E6%8E%A5/"}],"tags":[]}